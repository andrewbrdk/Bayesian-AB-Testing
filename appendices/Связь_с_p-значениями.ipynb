{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059d7c01",
   "metadata": {},
   "source": [
    "# Байесовские А/Б-тесты: связь с $p$-значениями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b4a7a6",
   "metadata": {},
   "source": [
    "*Показана численная близость $p$-значений $t$-теста, $\\chi^2$-теста и $U$-критерия Манна-Уитни в А/Б-тестах  вероятностям лучшей группы байесовских моделей. Соотношения выполняются несмотря на различия в определениях.*\n",
    "\n",
    "*- [$P$-значения](#$P$-значения)*  \n",
    "*- [$T$-тест](#$T$-тест)*  \n",
    "*- [Тест $\\chi^2$](#Тест-$\\chi^2$)*  \n",
    "*- [$U$-критерий Манна-Уитни](#$U$-критерий-Манна-Уитни)*  \n",
    "*- [Ссылки](#Ссылки)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6b5af",
   "metadata": {},
   "source": [
    "## $P$-значения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a519a4",
   "metadata": {},
   "source": [
    "$P$-значения используют в проверках нулевых гипотез. В этом методе формулируют гипотезу $H_0$ об изучаемом процессе и выбирают статистический тест $T$ - случайную величину с известным распределением $P_{T}(x | H_0)$ в предположении $H_0$. Считают реализацию величины $T$ в данных - тестовую статистику $x_{0}$ [[TestStat](https://en.wikipedia.org/wiki/Test_statistic)]. Вероятность получить фактическое или более экстремальное значение тестовой статистики называют односторонним $p$-значением $p = P_{T}(x \\ge x_{0} | H_0)$ [[PVal](https://en.wikipedia.org/wiki/P-value), [TailedTests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests)]. Если вероятность достаточно мала, гипотезу $H_0$ отвергают, если нет - оставляют."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d41335",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../figs/null_hypothesis.png\" alt=\"null_hypothesis\" width=\"800\"/>\n",
    "<em> В предположении гипотезы $H_0$ распределение тестовой статистики $P_{T}(x | H_0)$. Вероятность получить фактическое $x_0$ или более экстремальное значение тестовой статистики называют $p$-значением $p = P_{T}(x \\ge x_{0} | H_0)$. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46499a53",
   "metadata": {},
   "source": [
    "Решение о гипотезе $H_0$ принимают по $p$-значению $p = P_{T}(x \\ge x_{0} | H_0)$, тогда как вероятность гипотезы с учетом собранных данных оценивается величиной $P(H_0 | x_0)$. По соотношению Байеса $P(H_0 | x_0) \\propto P_{T}(x = x_{0} | H_0) P(H_0)$. Т.е. для выбора гипотезы нужно считать вероятности получить данные в рамках конкурирующих гипотез и сравнивать друг с другом с учетом априорных вероятностей. \n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "p = P_{T}(x \\ge x_{0} | H_0)\n",
    "\\\\\n",
    "\\,\n",
    "\\\\\n",
    "P(H_0 | x_0) = \\frac{P_{T}(x = x_{0} | H_0) P(H_0)}{P_{T}(x = x_{0} | H_0) P(H_0) + P_{T}(x = x_{0} | {\\sim}H_0) P({\\sim}H_0)}\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97cba49",
   "metadata": {},
   "source": [
    "В А/Б-тестах распространены $t$-тест средних, $\\chi^2$-тест пропорций и $U$-критерий Манна-Уитни. Далее показано как при определенных условиях $p$-значения этих тестов численно близки байесовским вероятностям параметров одной группы больше другой. Соотношения выполняются несмотря на различия в определениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e63c00",
   "metadata": {},
   "source": [
    "## $T$-тест"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a120f",
   "metadata": {},
   "source": [
    "Средние сравнивают $t$-тестами [[TTest](https://en.wikipedia.org/wiki/Student%27s_t-test)]. Пусть есть выборки размера $N_A, N_B$ из двух случайных величин $A, B$. В предположении одинаковых точных средних $H_0: E[A] = E[B]$ для отношения разности выборочных средних к стандартной ошибке разности средних $X = \\overline{\\Delta}/s_{\\Delta}$ ожидают $t$-распределение [[WelchT](https://en.wikipedia.org/wiki/Welch%27s_t-test)]. При достаточно большом количестве данных оно близко стандартному нормальному $\\text{Norm}(0, 1)$ [[TDist](https://en.wikipedia.org/wiki/Student%27s_t-distribution)]. По выборкам считают фактическое отношение $x_0 = \\overline{\\Delta}/s_{\\Delta}$. Вычисляют вероятность получить $x_0$ или большее значение - одностороннее $p$-значение $P_{X}(x \\ge x_0 | H_0)$. Если оно меньше заданного уровня значимости, средние в группах считают неравными.\n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "\\overline{A} = \\frac{1}{N_{A}} \\sum_{i=1}^{N_{A}} A_i,\n",
    "\\quad\n",
    "s_A^2 = \\frac{1}{N_A} \\sum_{i=1}^{N_A} (A_i - \\overline{A})^2,\n",
    "\\quad\n",
    "\\text{так же для } B\n",
    "\\\\\n",
    "X = \\frac{\\overline{\\Delta}}{s_{\\Delta}},\n",
    "\\quad\n",
    "\\overline{\\Delta} = \\overline{B} - \\overline{A},\n",
    "\\quad\n",
    "s^2_{\\Delta} = \\frac{s_A^2}{N_A} + \\frac{s_B^2}{N_B}\n",
    "\\\\\n",
    "H_0: E[A] = E[B],\n",
    "\\quad\n",
    "P_{X}(x | H_0) \\approx \\text{Norm}(x; 0, 1)\n",
    "\\\\\n",
    "x_0 - \\text{реализация } X, \\quad\n",
    "p = P_{X}(x \\ge x_0 | H_0)\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e3130",
   "metadata": {},
   "source": [
    "В А/Б-тесте нужно выбрать группу с большим средним. Вместо $p$-значения $P_{X}(x \\ge x_0 | H_0)$ интересна вероятность среднего $B$ больше $A$ при условии собранных данных $P(\\mu_B > \\mu_A | A_i, B_j ) = P(\\mu_{\\Delta} > 0 | A_i, B_j )$, где $\\mu_A, \\mu_B, \\mu_{\\Delta}$ - оценки точных средних соответствующих распределений. Эту вероятность можно оценить байесовским моделированием. Будет строиться оценка среднего разности $\\mu_{\\Delta}$. По центральной предельной теореме распределение выборочных средних близко нормальному. Поэтому в качестве правдоподобия выбирается нормальное распределение $P(\\overline{\\Delta} | \\mu_{\\Delta}) = \\text{Norm}(\\overline{\\Delta} | \\mu_{\\Delta}, s_{\\Delta}^2)$. Используется модель с одним случайным параметром - средним $\\mu_{\\Delta}$, дисперсия выбирается $s_{\\Delta}^2$ на основе данных. Моделирование применяется к выборочным средним, а не исходным выборкам, поэтому для обновления параметров используется только одна точка $\\overline{\\Delta}$. Для сопряженности априорное распределение также выбирается нормальным  $P(\\mu_{\\Delta}) = \\text{Norm}(\\mu_{\\Delta} | \\mu_0, \\sigma_0^2)$. Апостериорное распределение будет нормальным с обновленными средним и дисперсией $P(\\mu_{\\Delta} | \\overline{\\Delta}) = \\text{Norm}(\\mu_{\\Delta} | \\mu_{N}, \\sigma_{N}^2)$ [[ConjPrior](https://en.wikipedia.org/wiki/Conjugate_prior#When_likelihood_function_is_a_continuous_distribution)]. При достаточно широком априорном распределении с центром в нуле $\\mu_0 = 0, \\sigma_{0}^2 \\gg s^2_{\\Delta}$ апостериорное распределение приближенно $P(\\mu_{\\Delta} | \\overline{\\Delta}) \\approx \n",
    "\\text{Norm}(\\mu_{\\Delta} | \\overline{\\Delta}, s^2_{\\Delta})$. Вероятность среднего одной группы больше другой можно записать как положительную область нормального распределения с центром в точке $x_0 = \\overline{\\Delta}/s_{\\Delta}$ и единичной дисперсией $P(\\mu_B > \\mu_A | A_i, B_j ) = P(\\mu_{\\Delta} > 0 | \\overline{\\Delta})  \\approx P(\\text{Norm}(x > 0 | x_0, 1))$.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(\\overline{\\Delta} | \\mu_{\\Delta}) & =\n",
    "\\text{Norm}(\\overline{\\Delta} | \\mu_{\\Delta}, s_{\\Delta}^2),\n",
    "\\quad\n",
    "P(\\mu_{\\Delta}) =\n",
    "\\text{Norm}(\\mu_{\\Delta} | \\mu_0, \\sigma_0^2) \n",
    "\\\\\n",
    "P(\\mu_{\\Delta} | \\overline{\\Delta}) \n",
    "& = \\text{Norm}(\\mu_{\\Delta} | \\mu_{N}, \\sigma_{N}^2),\n",
    "\\quad\n",
    "\\sigma_{N}^2 = \\frac{\\sigma_{0}^2 s_{\\Delta}^2}{s_{\\Delta}^2 + \\sigma_{0}^2},\n",
    "\\quad\n",
    "\\mu_{N} = \\mu_{0} \\frac{\\sigma_{N}^2}{\\sigma_{0}^2} + \\frac{\\sigma_{N}^2}{s_{\\Delta}^2} \\overline{\\Delta}\n",
    "\\\\\n",
    "\\mu_0 = 0, & \\, \\sigma_{0}^2 \\gg s^2_{\\Delta}: \n",
    "\\, \n",
    "\\sigma_N^2 \\approx s^2_{\\Delta}, \\, \\mu_N \\approx \\overline{\\Delta}, \n",
    "\\\\\n",
    "P(\\mu_{\\Delta} | \\overline{\\Delta}) & \\approx \n",
    "\\text{Norm}(\\mu_{\\Delta} | \\overline{\\Delta}, s^2_{\\Delta})\n",
    "\\\\\n",
    "P(\\mu_B > \\mu_A | A_i, B_j ) &= P(\\mu_{\\Delta} > 0 | \\overline{\\Delta})  \\approx P(\\text{Norm}(\\mu_{\\Delta} > 0 | \\overline{\\Delta}, s^2_{\\Delta})) = P(\\text{Norm}(x > 0 | x_0, 1))\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04425d",
   "metadata": {},
   "source": [
    "По симметрии нормального распределения $P(\\text{Norm}(x > x_0 | 0, 1)) =  P(\\text{Norm}(x < 0 | x_0, 1))$. Поэтому $p$-значение одностороннего $t$-теста близко вероятности среднего одной группы больше другой.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "p = P_{X}(x > x_0 | H_0)\n",
    "& = P \\left( \\text{Norm}(x > x_0| 0, 1) \\right)\n",
    "\\\\\n",
    "& =  P \\left( \\text{Norm}(x < 0 | x_0, 1) \\right)\n",
    "\\\\\n",
    "& = 1 - P \\left( \\text{Norm}(x > 0 | x_0, 1) \\right)\n",
    "\\approx 1 - P(\\mu_B > \\mu_A | A_i, B_j )\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d8603",
   "metadata": {},
   "source": [
    "Для демонстрации ниже заданы два нормальных распределения с разными средними. По выборке байесовская оценка вероятности $P(\\mu_B > \\mu_A | A_i, B_j)$ сравнивается с $p$-значением $t$-теста. Используется односторонний $t$-тест с разными дисперсиями групп (`equal_var=False`, `alternative`) [[ScipyTTestInd](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)]. Вероятность \n",
    "$p = P(x > x_0 | H_0) = P \\left( \\text{Norm}(x > x_0| 0, 1) \\right)$ закрашена темным, $P(\\text{Norm}(x < 0 | x_0, 1)) \\approx 1 - P(\\mu_B > \\mu_A | A_i, B_j)$ закрашена светлым. По свойствам нормального распределения площади этих областей совпадают. Таким образом $p$-значение численно близко байесовской оценке вероятности. Стоит помнить, что они не эквивалентны - у них разные определения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_diff_scaled(sampA, sampB, mu0=None, s20=None):\n",
    "    delta = sampB.mean() - sampA.mean()\n",
    "    s2delta = sampA.var() / sampA.size + sampB.var() / sampB.size\n",
    "    mu0 = mu0 or 0\n",
    "    s20 = s20 or 30 * s2delta\n",
    "    s2n = s2delta * s20 / (s2delta + s20)\n",
    "    mun = mu0 * s2n / s20 + delta * s2n / s2delta\n",
    "    return stats.norm(loc=mun/np.sqrt(s2n), scale=1)\n",
    "\n",
    "muA = 0.1\n",
    "muB = 0.115\n",
    "sigma = 1.3\n",
    "\n",
    "exactA = stats.norm(muA, sigma)\n",
    "exactB = stats.norm(muB, sigma)\n",
    "\n",
    "N = 30000\n",
    "sampA = exactA.rvs(size=N)\n",
    "sampB = exactB.rvs(size=N)\n",
    "\n",
    "a = 'greater' if np.mean(sampA) > np.mean(sampB) else 'less'\n",
    "t_stat, p_value = stats.ttest_ind(sampA, sampB, equal_var=False, alternative=a)\n",
    "t_stat = np.abs(t_stat)\n",
    "\n",
    "post_dist = posterior_diff_scaled(sampA, sampB)\n",
    "mean_b_gt_a = 1 - post_dist.cdf(0)\n",
    "\n",
    "xaxis_min = -7\n",
    "xaxis_max = 8\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=1), \n",
    "                         line_color='black', opacity=0.8, name='$\\mathrm{Norm}(0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=x[x>t_stat], y=stats.norm.pdf(x[x>t_stat], loc=0, scale=1), \n",
    "                         line_color=\"rgba(0, 0, 0, 0.7)\", name='$P(x>x_0 | H_0)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist.pdf(x), \n",
    "                         line_color='black', opacity=0.2, name='$\\mathrm{Norm}(x_0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=post_dist.pdf(x[x<0]), \n",
    "                         line_color=\"rgba(128, 128, 128, 0.2)\", name='$P(\\mu_{\\Delta} < 0 | \\overline{\\Delta})$', fill=\"tozeroy\", fillcolor=\"rgba(128, 128, 128, 0.2)\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(stats.norm.pdf(x, loc=0, scale=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '0'], textposition=\"top center\", \n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=[t_stat, t_stat], y=[0, max(stats.norm.pdf(x, loc=0, scale=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$x_0$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.update_layout(title=r'$T\\text{-распределение и апостериорное среднего разности}$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"../figs/apx_pval_ttest.png\", scale=2)\n",
    "#Темная линия - t-распределение, темная закрашенная область - p-значение. \n",
    "#Светлая линия - апостериорное распределение среднего разности, светлая закрашенная область - вероятность среднего A меньше B. \n",
    "#Площади закрашенных областей совпадают.\n",
    "\n",
    "print(f'p-value P(x>x0 | H0): {p_value:.4f}')\n",
    "print(f'1 - p: {1 - p_value:.4f}')\n",
    "print(f'Bayes P(mu_delta > 0): {mean_b_gt_a:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c419d18",
   "metadata": {},
   "source": [
    "Численную близость $p$-значения и байесовской вероятности $P(\\mu_{\\Delta} > 0 | \\overline{\\Delta})$ можно проверить по количеству правильно угаданных вариантов в серии экспериментов. В каждом эксперименте задается два нормальных распределения. В группе $A$ среднее фиксировано `mu=0.1`, в $B$ выбирается случайно в диапазоне $\\pm 5\\%$ от `mu`. В группы добавляются данные по `n_samp_step` точек за шаг. На каждом шаге считается $t$-тест. Эксперимент останавливается, если  $1 - p$ достигает `prob_stop=0.95` или использовано максимальное количество точек `n_samp_max`. Длительность эксперимента не фиксируется заранее. Миниальный размер выборки `n_samp_min + n_samp_step`. При остановке эксперимента для сравнения с $p$-значением считается байесовское апострериорное распределение и вероятность $P(\\mu_{\\Delta} > 0 | \\overline{\\Delta})$. Процедура повторяется `nexps` раз, считается доля правильно угаданных групп во всех экспериментах. Из `nexps = 1000` завершено 880, в них правильно угадано 818 вариантов. Точность 0.93 близка `prob_stop = 0.95`. $P$-значения в каждом эксперименте близки байесовским вероятностям. При недостаточном `n_samp_min` доля угаданных вариантов будет меньше `prob_stop`. Для байесовской модели вместо минимального количества точек можно задать меньшее значение $\\sigma_0^2$ - эффект будет близок заданию минимального размера выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', '1-pval'])\n",
    "\n",
    "mu = 0.1\n",
    "nexps = 1000\n",
    "cmp['A'] = [mu] * nexps\n",
    "cmp['B'] = mu * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 3_000_000\n",
    "n_samp_step = 10_000\n",
    "n_samp_min = 100_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    muA = cmp.at[i, 'A']\n",
    "    muB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.norm(loc=muA, scale=1)\n",
    "    exact_dist_B = stats.norm(loc=muB, scale=1)\n",
    "    n_samp_current = n_samp_min\n",
    "    sampA = exact_dist_A.rvs(n_samp_max)\n",
    "    sampB = exact_dist_B.rvs(n_samp_max)\n",
    "    post_dist = None\n",
    "    mean_b_gt_a_bayes = np.nan\n",
    "    while n_samp_current < n_samp_max:\n",
    "        n_samp_current += n_samp_step\n",
    "        a = 'greater' if np.mean(sampA[:n_samp_current]) > np.mean(sampB[:n_samp_current]) else 'less'\n",
    "        t_stat, p_value = stats.ttest_ind(sampA[:n_samp_current], sampB[:n_samp_current], equal_var=False, alternative=a)\n",
    "        p_best_t = 1 - p_value\n",
    "        best_gr = 'A' if p_best_t >= prob_stop and a == 'greater' else 'B' if p_best_t >= prob_stop and a == 'less' else None\n",
    "        if best_gr:\n",
    "            post_dist = posterior_diff_scaled(sampA[:n_samp_current], sampB[:n_samp_current])\n",
    "            mean_b_gt_a_bayes = 1 - post_dist.cdf(0)\n",
    "            cmp.at[i, 'A_exp'] = sampA[:n_samp_current].mean()\n",
    "            cmp.at[i, 'B_exp'] = sampB[:n_samp_current].mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_current\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(mean_b_gt_a_bayes, 1 - mean_b_gt_a_bayes)\n",
    "            cmp.at[i, '1-pval'] = 1 - p_value\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_current}, best_gr {best_gr}, Bayes P(b>a) {mean_b_gt_a_bayes:.4f}, T-test p-val {p_value:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "finished = np.sum(cmp['best_exp'].notna())\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Finished: {finished}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / finished}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3ec00",
   "metadata": {},
   "source": [
    "## Тест $\\chi^2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06de92d",
   "metadata": {},
   "source": [
    "Конверсии могут сравнивать $\\chi^2$-тестом [[Chi2Test](https://en.wikipedia.org/wiki/Chi-squared_test)]. Статистика $\\chi^2$ Пирсона [[Chi2Pearson](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)] для мультиномиальных распределений определена $\\chi^2 = \\sum_{i=1}^k (S_i - Np_i)^2/Np_i$, где $N$ - общее количество наблюдений, $S_i$ и $N p_i$ - фактическое и ожидаемое количество наблюдений $i$-категории при доле $i$-категории $p_i$. Для биномиального распределения $\\chi^2=(S - Np)^2/N p (1-p)$. По центральной предельной теореме $(S - Np)/\\sqrt{N p (1-p)}$ стремится к стандартному нормальному распределению, квадрат этой величины совпадает с $\\chi^2$. Распределение суммы квадратов $k$ нормальных случайных величин называют $\\chi^2$-распределением с $k$ степенями свободы $\\chi^2_k = \\sum_{i=1}^{k} X_i^2,\\, X_i \\sim \\text{Norm}(0,1)$ [[Chi2Dist](https://en.wikipedia.org/wiki/Chi-squared_distribution)]. Поэтому статистика $\\chi^2$ стремится к $\\chi_1^2$-распределению.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\chi^2 & = \n",
    "\\sum_{i=1}^k \\frac{(S_i - Np_i)^2}{N p_i}\n",
    "\\\\\n",
    "& =\n",
    "\\frac{(S - N p)^2}{N p}\n",
    "+\n",
    "\\frac{((N - S) - N (1-p))^2}{N (1-p)}\n",
    "\\\\\n",
    "& =\n",
    "\\frac{(S - Np)^2}{N p (1-p)} \n",
    "\\to \\chi_1^2, \\quad N \\to \\infty\n",
    "\\\\\n",
    "\\chi^2_k & = \\sum_{i=1}^{k} X_i^2,\\, X_i \\sim \\text{Norm}(0,1)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b9d00",
   "metadata": {},
   "source": [
    "Для А/Б-теста конверсий с двумя группами в предположении одинаковых ожидаемых конверсий $p=(S_A + S_B)/(N_A + N_B)$ тестовую статистику можно привести к виду $\\chi^2 = \\Delta p^2/s_{\\Delta}^2$, $\\Delta p = S_B/N_B - S_A/N_A$, $s_{\\Delta}^2 = p(1-p) (1 / N_A + 1 / N_B)$. При большом количестве точек распределение $\\chi^2$ близко $\\chi_1^2$. Т.к. распределение $\\chi^2_1$ получается возведением в квадрат стандартного нормального распределения, область $p$-значения $p = P_{\\chi_1^2}(x > \\chi^2 | H_0)$ соответствует областям $P\\left(\\text{Norm}(x > \\chi \\cup x < -\\chi | 0, 1)\\right)$. По симметрии нормального распределения площади $x > \\chi$ и $x < -\\chi$ одинаковы. \n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "A \\sim \\mathrm{Bernoulli}(p_A), \n",
    "\\,\n",
    "S_A = \\sum_{i=1}^{N_A} A_i,\n",
    "\\quad\n",
    "B \\sim \\mathrm{Bernoulli}(p_B), \n",
    "\\,\n",
    "S_B = \\sum_{i=1}^{N_B} B_i,\n",
    "\\\\\n",
    "p = \\frac{S_A + S_B}{N_A + N_B},\n",
    "\\quad\n",
    "\\Delta p = \\frac{S_B}{N_B} - \\frac{S_A}{N_A},\n",
    "\\quad\n",
    "s_{\\Delta}^2 = \\frac{p(1-p)}{N_A} + \\frac{p(1-p)}{N_B}\n",
    "\\\\\n",
    "\\begin{split}\n",
    "H_0: E[A] = E[B], \\quad \\chi^2 & = \\frac{(S_A - N_A p)^2}{N_A p (1-p)} + \\frac{(S_B - N_B p)^2}{N_B p (1-p)} \n",
    "\\\\\n",
    "& = \\frac{N_A N_B \\Delta p^2}{(N_A + N_B) p (1-p)}\n",
    "\\\\\n",
    "& = \\frac{\\Delta p^2}{s_{\\Delta}^2} \\to \\chi_1^2, \\, n \\to \\infty\n",
    "\\end{split}\n",
    "\\\\\n",
    "\\,\n",
    "\\\\\n",
    "\\begin{split}\n",
    "\\text{p-val} & = P_{\\chi_1^2}(x > \\chi^2 | H_0)\n",
    "\\\\\n",
    "& = P \\left( \\text{Norm}(x > \\chi \\cup x < -\\chi; 0, 1) \\right) \n",
    "\\\\\n",
    "& = 2 P\\left( \\text{Norm}(x > \\chi; 0, 1) \\right)\n",
    "\\end{split}\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beaa6ef",
   "metadata": {},
   "source": [
    "Для байесовской оценки вероятности конверсии одной группы больше другой $P(\\theta_B > \\theta_A | A_i, B_j)$ правдоподобие в каждой группе задается биномиальным распределением $P(S | \\theta, N)  = \\mbox{Binom}(S | \\theta, N)$, априорное - бета-распределением $P(\\theta) = \\mbox{Beta}(\\theta; \\alpha, \\beta)$. Апостериорное будет бета-распределением с обовленными параметрами $P(\\theta | S, N) = \\mbox{Beta}(\\theta; \\alpha + S, \\beta + N - S)$. При типичных значениях $N, S$ бета-распределение близко нормальному. Распределение разности конверсий также будет нормальным. При равномерных априорных распределениях и слабой разнице между группами $P_{\\Delta \\theta}(x) \\approx \\mbox{Norm}\\left(x; \\Delta p, s_{\\Delta}^2 \\right)$ с параметрами $\\Delta p$, $s_{\\Delta}^2$ как в $\\chi^2$-тесте. Вероятность конверсии одной группы больше другой будет площадью этого распределения в положительной области $P(\\theta_B > \\theta_A | A_i, B_j) = P(\\Delta \\theta > 0 | A_i, B_j) \\approx P\\left(\\text{Norm}(x > 0; \\chi, 1) \\right)$. \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(S | \\theta, N) & = \\mbox{Binom}(S | \\theta, N)\n",
    "\\\\ \n",
    "P(\\theta) & = \\mbox{Beta}(\\theta; \\alpha, \\beta)\n",
    "\\\\\n",
    "P(\\theta | S, N) & = \\mbox{Beta}(\\theta; \\alpha + S, \\beta + N - S)\n",
    "\\\\\n",
    "& \\approx \\mbox{Norm}(\\theta; \\mu, \\sigma^2),\n",
    "\\quad\n",
    "\\mu = S / N, \n",
    "\\quad\n",
    "\\sigma^2 = \\mu (1 - \\mu) / N,\n",
    "\\quad \n",
    "S, N \\gg \\alpha, \\beta \\gg 1\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P_{\\theta_A}(x) & = \\mbox{Beta}(x; \\alpha_A + S_A, \\beta_A + N_A - S_A)\n",
    "\\approx \\mbox{Norm}(x; \\mu_A, \\sigma^2_A),\n",
    "\\\\\n",
    "P_{\\theta_B}(x) & = \\mbox{Beta}(x; \\alpha_B + S_B, \\beta_B + N_B - S_B)\n",
    "\\approx \\mbox{Norm}(x; \\mu_B, \\sigma^2_B)\n",
    "\\\\\n",
    "P_{\\Delta \\theta}(x) & \\approx \\mbox{Norm}\\left(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2\\right)\n",
    "\\approx \\mbox{Norm}\\left(x; \\Delta p, s_{\\Delta}^2 \\right),\n",
    "\\quad \\text{при } p \\approx S_A/N_A \\approx S_B/N_B\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\theta_B > \\theta_A | A_i, B_j) \n",
    "= P(\\Delta \\theta > 0 | A_i, B_j) \n",
    "\\approx P\\left(\\text{Norm}(x > 0; \\Delta p, s_{\\Delta}^2) \\right)\n",
    "= P\\left(\\text{Norm}(x > 0; \\chi, 1) \\right), \\quad \\chi = \\Delta p / s_{\\Delta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4bfc3",
   "metadata": {},
   "source": [
    "По симметрии $P\\left( \\text{Norm}(x > \\chi | 0, 1) \\right) = P\\left(\\text{Norm}(x < 0; \\chi, 1) \\right)$. Поэтому $P(\\theta_B > \\theta_A | A_i, B_j) \\approx 1 - \\mbox{p-val}/2$.\n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "\\begin{split}\n",
    "\\text{p-val} & = P_{\\chi_1^2}(x > \\chi^2 | H_0)\n",
    "\\\\\n",
    "& = 2 P\\left( \\text{Norm}(x > \\chi; 0, 1) \\right)\n",
    "\\\\\n",
    "& = 2 P\\left(\\text{Norm}(x < 0; \\chi, 1) \\right)\n",
    "\\\\\n",
    "& \\approx 2 \\left( 1 - P(\\theta_B > \\theta_A | A_i, B_j) \\right)\n",
    "\\end{split}\n",
    "\\\\\n",
    "\\,\n",
    "\\\\\n",
    "P(\\theta_B > \\theta_A | A_i, B_j) \\approx 1 - \\frac{\\text{p-val}}{2}\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6110e2",
   "metadata": {},
   "source": [
    "Соотношение $P(\\theta_B > \\theta_A | A_i, B_j) \\approx 1 - \\mbox{p-val}/2$ проверяется по выборке из двух распределений Бернулли с конверсиями $p_A = 0.1$ и $p_B = 0.103$. Данные для $\\chi^2$-теста задаются в виде таблицы со строками $S_A, N_A-S_A$ и $S_B, N_B - S_B$ [[ScipyChi2Con](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html)]. $P$-значение $\\chi^2$-теста не позволяет выбрать между $p_A > p_B$ и $p_B > p_A$, поэтому дополнительно сравниваются средние в выборках. Распределение $\\chi^2_1$ на первом графике ниже. Закрашенная область соответствует $p$-значению $\\mbox{p-val} = P_{\\chi_1^2}(x > \\chi^2 | H_0)$. На втором графике закрашенные темные области $x > \\chi$ и $x < - \\chi$  соответствуют области $p$-значения при возведении в квадрат. Серый график - нормальное распределение $\\text{Norm}(\\chi, 1)$. Закрашенная область серого графика приближенно равна $1 - P(\\theta_B > \\theta_A | A_i, B_j)$. Площади закрашенной серой и каждой из темных областей совпадают. Связь $p$-значения и байесовской оценки вероятности численно выполняется. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(27)\n",
    "\n",
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def diff_ba_scaled(post_dist_A, post_dist_B):\n",
    "    m = post_dist_B.mean() - post_dist_A.mean()\n",
    "    v = post_dist_A.var() + post_dist_B.var()\n",
    "    return stats.norm(loc=m/np.sqrt(v), scale=1)\n",
    "\n",
    "\n",
    "pA = 0.1\n",
    "pB = pA * 1.03\n",
    "\n",
    "exactA = stats.bernoulli(pA)\n",
    "exactB = stats.bernoulli(pB)\n",
    "\n",
    "N = 10000\n",
    "sampA = exactA.rvs(size=N)\n",
    "sampB = exactB.rvs(size=N)\n",
    "SA = np.sum(sampA)\n",
    "SB = np.sum(sampB)\n",
    "\n",
    "t = np.array([\n",
    "    [SA,     N - SA],\n",
    "    [SB,     N - SB]\n",
    "])\n",
    "chi2_stat, p_value_chi2, dof, expected = stats.chi2_contingency(t, correction=False)\n",
    "chi = np.sqrt(chi2_stat)\n",
    "p_A_samp = SA / N\n",
    "p_B_samp = SB / N\n",
    "pb_gt_pa_chi = 1 - p_value_chi2 / 2\n",
    "pb_gt_pa_chi = pb_gt_pa_chi if p_B_samp > p_A_samp  else 1 - pb_gt_pa_chi\n",
    "\n",
    "post_dist_A = posterior_dist_binom(ns=SA, ntotal=N)\n",
    "post_dist_B = posterior_dist_binom(ns=SB, ntotal=N)\n",
    "diff_dist_scaled = diff_ba_scaled(post_dist_A, post_dist_B)\n",
    "pb_gt_pa_bayes = 1 - diff_dist_scaled.cdf(0)\n",
    "\n",
    "xaxis_min = 0\n",
    "xaxis_max = 5\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.chi.pdf(x, df=1), \n",
    "                         line_color='black', opacity=0.8, name=f'$\\chi^2_1$'))\n",
    "fig.add_trace(go.Scatter(x=[chi2_stat, chi2_stat], y=[0, max(stats.chi.pdf(x, df=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$\\chi^2$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>chi2_stat], y=stats.chi.pdf(x[x>chi2_stat], df=1), \n",
    "                         line_color='black', opacity=0.8, name='$P_{\\chi_1^2}(x > \\chi^2)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.update_layout(title='Хи-квадрат',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"../figs/apx_pval_cxi2.png\", scale=2)\n",
    "#Распределение \\chi^2, закрашенная область соответствует p-значению.\n",
    "\n",
    "xaxis_min = -5\n",
    "xaxis_max = 5\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=1), \n",
    "                         line_color='black', opacity=0.8, name='$\\mathrm{Norm}(0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(stats.norm.pdf(x, loc=0, scale=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '0'], textposition=\"top center\", \n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=[chi, chi], y=[0, max(stats.norm.pdf(x, loc=0, scale=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$\\chi$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=[-chi, -chi], y=[0, max(stats.norm.pdf(x, loc=0, scale=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$-\\chi$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>chi], y=stats.norm.pdf(x[x>chi], loc=0, scale=1), \n",
    "                         line_color='black', opacity=0.8, name='$P(\\mathrm{Norm}(x > \\chi \\cup x < -\\chi | 0, 1)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x[x<-chi], y=stats.norm.pdf(x[x<-chi], loc=0, scale=1), \n",
    "                         line_color='black', opacity=0.8, name='$P(\\mathrm{Norm}(x > \\chi | 0, 1)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\",\n",
    "                         showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x, y=diff_dist_scaled.pdf(x), \n",
    "                         line_color='black', opacity=0.2, name=r'$\\mathrm{Norm}(\\chi, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=diff_dist_scaled.pdf(x[x<0]), \n",
    "                         line_color=\"rgba(128, 128, 128, 0.2)\", name=r'$P(\\mathrm{Norm}(x < 0 | \\chi, 1))$', fill=\"tozeroy\", fillcolor=\"rgba(128, 128, 128, 0.2)\"))\n",
    "fig.update_layout(title=r'$P\\text{-значение и байесовская модель}$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"../figs/apx_pval_cxinorm.png\", scale=2)\n",
    "#Темная линия - стандартное нормальное распределение, при возведении в квадрат получится -распределение. \n",
    "#Темные закрашенные области соответствуют p-значению -распределения. Светлая линия - апостериорное байесовское распределение разности конверсий. \n",
    "#Серая область - вероятность конверсии группы А больше Б. Площадь серой закрашенной области совпадает с темными закрашенными областями. \n",
    "\n",
    "print(f'Bayes P(theta_b > theta_a): {pb_gt_pa_bayes:.4f}')\n",
    "print(f\"Chi2: 1-pval/2:   {pb_gt_pa_chi:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a081f",
   "metadata": {},
   "source": [
    "$P$-значение $\\chi^2$-теста используется для выбора вариантов с большей конверсией в серии экспериментов. В каждом эксперименте 2 группы, конверсия $p_A=0.1$ фиксирована, $p_B$ выбирается случайно в диапазоне $\\pm5\\%$ от $p_A$. В каждой группе добавляются данные по `n_samp_step` точек за шаг. На каждом шаге вычисляется $p$-значение $\\chi^2$-теста и $P(\\theta_B > \\theta_A | A_i, B_j)$. Эксперимент останавливается, если оценка вероятности конверсии одной группы больше другой превышает `prob_stop` или набрано максимальное количество точек `n_samp_max`. Всего из `nexps=1000` завершено 986, верно угадано 940 варианта. Доля 0.953 близка `prob_stop = 0.95`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a849f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_chi'])\n",
    "\n",
    "p = 0.1\n",
    "nexps = 1000\n",
    "cmp['A'] = [p] * nexps\n",
    "cmp['B'] = p * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 5_000_000\n",
    "n_samp_step = 10_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    pA = cmp.at[i, 'A']\n",
    "    pB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.bernoulli(p=pA)\n",
    "    exact_dist_B = stats.bernoulli(p=pB)\n",
    "    n_samp_total = 0\n",
    "    ns_A = 0\n",
    "    ns_B = 0\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA = exact_dist_A.rvs(n_samp_step)\n",
    "        dB = exact_dist_B.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        ns_A = ns_A + np.sum(dA)\n",
    "        ns_B = ns_B + np.sum(dB)\n",
    "        p_A_samp = ns_A / n_samp_total\n",
    "        p_B_samp = ns_B / n_samp_total\n",
    "        t = np.array([\n",
    "            [ns_A,     n_samp_total - ns_A],\n",
    "            [ns_B,     n_samp_total - ns_B]\n",
    "        ])\n",
    "        chi2_stat, p_value_chi, dof, expected = stats.chi2_contingency(t, correction=False)\n",
    "        pb_gt_pa_chi = 1 - p_value_chi / 2\n",
    "        pb_gt_pa_chi = pb_gt_pa_chi if p_B_samp > p_A_samp  else 1 - pb_gt_pa_chi\n",
    "        best_gr = 'B' if pb_gt_pa_chi >= prob_stop else 'A' if 1 - pb_gt_pa_chi >= prob_stop else None\n",
    "        if best_gr:\n",
    "            post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "            post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "            pb_gt_pa_bayes = 1 - diff_ba_scaled(post_dist_A, post_dist_B).cdf(0)\n",
    "            cmp.at[i, 'A_exp'] = p_A_samp\n",
    "            cmp.at[i, 'B_exp'] = p_B_samp\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p_best_chi'] = max(pb_gt_pa_chi, 1 - pb_gt_pa_chi)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P_best Bayes {max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes):.4f}, Chi (1-pval/2): {1 - p_value_chi/2:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "finished = np.sum(cmp['best_exp'].notna())\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Finished: {finished}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / finished}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f9f73",
   "metadata": {},
   "source": [
    "## $U$-критерий Манна-Уитни"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607868a8",
   "metadata": {},
   "source": [
    "Для выборок размера $N_A, N_B$ из двух случайных величин $A, B$ статистика Манна-Уитни [[MannWhitneyU](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)] определена попарным сравнением элементов. Для непрерывных распределений вероятность совпадения элементов в выборках нулевая. В этом случае $U$-статистика определена как количество пар $(A_i, B_j)$, где элемент $A_i$ больше $B_j$: $U_A = \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(A_i > B_j)$, $I$ - индикаторная функция. Статистику также можно записать в виде $U_A = R_A - N_A (N_A + 1)/2$, где $R_A$ - сумма рангов элементов $A$ в объединенной выборке. Эквивалентность определений можно увидеть следующим образом: слагаемое $N_A (N_A + 1)/2$ соответствует минимальной сумме рангов если все элементы $A_i$ меньше $B_j$ и считается как сумма арифметической прогрессии. Если наибольший элемент $A_i$ больше $n$ элементов $B_j$, то $U_A = n$ и $R_A = N_A (N_A + 1)/2 + n$. При большом количестве точек отношение $U_A$ к общему количеству пар $U_A / N_A N_B$ стремится к вероятности точки из распределения $A$ больше $B$.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "A, B & - \\text{непрерывные распределения}\n",
    "\\\\\n",
    "U_A & = \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(A_i > B_j),\n",
    "\\quad\n",
    "I(\\cdot) = 1 \\text{ если условие выполнено, иначе } 0 \n",
    "\\\\\n",
    "U_A & = R_A - N_A (N_A + 1)/2, \\quad R_A \\text{- сумма рангов элементов A в объединенной выборке } A_i, B_j\n",
    "\\\\\n",
    "\\frac{U_A}{N_A N_B} & \\to P(A > B),\n",
    "\\quad\n",
    "N_A, N_B \\to \\infty\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6f75f",
   "metadata": {},
   "source": [
    "В предположении одинаковых распределений $A = B$ можно посчитать среднее $E[U_A]$ и дисперсию $\\text{Var}(U_A)$ $U$-статистики. Величина $(U_A - E[U_A])/\\sqrt{\\text{Var}(U_A)}$ будет стремиться к нормальному распределению. От количества пар удобно перейти к вероятности $u_A = U_A / N_A N_B$.  $P$-значение вычисляется как $p = P \\left( \\mbox{Norm}\\left(x < u_A; 1/2, \\text{Var}(U_A)/(N_A N_B)^2 \\right) \\right)$ при $u_A < 0.5$ или как площадь области $x > u_A$ при $u_A > 0.5$.\n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "H_0: A = B, \n",
    "\\quad\n",
    "E[U_A] = \\frac{N_A N_B}{2}, \\quad\n",
    "\\text{Var}(U_A) = \\frac{N_A N_B (N_A + N_B + 1)}{12}\n",
    "\\\\\n",
    "\\frac{U_A - E[U_A]}{\\sqrt{\\text{Var}(U_A)}} \\to \\text{Norm}(0,1), \\quad N_A, N_B \\to \\infty\n",
    "\\\\\n",
    "u_A = \\frac{U_A}{N_A N_B},\n",
    "\\quad\n",
    "\\frac{u_A - 1/2}{\\sqrt{\\text{Var}(U_A)/(N_A N_B)^2}} \\to \\text{Norm}(0,1), \\quad N_A, N_B \\to \\infty\n",
    "\\\\\n",
    "p = P( x > u_A | H_0 ) = P \\left( \\mbox{Norm}\\left(x < u_A; 1/2, \\text{Var}(U_A)/(N_A N_B)^2 \\right) \\right),\n",
    "\\quad u_A < 0.5\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a827a",
   "metadata": {},
   "source": [
    "В байесовском подходе вероятность $P(B>A)$ можно оценить сравнением апостериорных предиктивных распределений. Для этого нужно задать модели исходных распределений, построить апостериорные распределения параметров, апостериорные предиктивные распределения и по ним оценить $P(B>A)$. Другой вариант, не требующий предположений о распределениях - моделировать вероятность $\\theta = P(B > A)$ точки $B$ больше $A$. Данными будут пары $(A_i, B_j)$, в каждой паре точка $B_j$ больше $A_i$ с вероятностью $\\theta$, по общему количеству пар $N$ и количеству пар $S$ с $B_j$ больше $A_i$ нужно оценить $\\theta$. Такая задача похожа на моделирование конверсий. Если при формировании пар из исходных выборок каждую точку $A$ сравнивать с каждой точкой $B$, пары с одинаковыми $A_i$ или $B_j$ будут зависимы. Для независимости каждая точка $A_i$ сравнивается только с одной точкой $B_j$. Аналогично конверсиям правдоподобие задается биномиальным распределением $P(S | \\theta) = \\text{Binom}(S | \\theta, N)$, априорное - бета-распределением. Апостериорное также будет бета-распределением. Вероятность точки одной группы больше другой равна области $\\theta$ больше 0.5: $P(B > A) \\approx P(\\theta  > 0.5 | S, N)$.\n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "\\theta = P(B > A),\n",
    "\\quad\n",
    "S = \\sum_{i=1}^N I(B_i > A_i),\n",
    "\\quad N_A = N_B = N\n",
    "\\\\\n",
    "\\begin{split}\n",
    "P(S | \\theta) & = \\text{Binom}(S; \\theta, N)\n",
    "\\\\\n",
    "P(\\theta) & = \\text{Beta}(\\theta; \\alpha, \\beta)\n",
    "\\\\\n",
    "P(\\theta | S) & = \\text{Beta}(\\theta; S + \\alpha, N - S + \\beta)\n",
    "\\\\\n",
    "& \\approx \\text{Norm}(\\theta; \\mu, \\sigma^2),\n",
    "\\quad\n",
    "\\mu = (S + \\alpha ) / (N + \\alpha + \\beta), \n",
    "\\quad\n",
    "\\sigma^2 = \\mu (1 - \\mu) / N,\n",
    "\\quad\n",
    "N, S \\gg \\alpha, \\beta \\gg 1\n",
    "\\end{split}\n",
    "\\\\\n",
    "\\,\n",
    "\\\\\n",
    "\\begin{split}\n",
    "P(B > A) \\approx P(\\theta  > 0.5 | S, N) & = P(\\text{Norm}(x > 0.5; \\mu, \\sigma^2))\n",
    "\\end{split}\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d883796",
   "metadata": {},
   "source": [
    "В $U$-статистике каждая точка $A_i$ сравнивается с каждой $B_j$, в байесовской модели точки $A_i, B_j$ участвуют только в одном сравнении. Из-за меньшего использования данных дисперсия байесовской модели шире $U$-статистики. $P$-значение не будет близко совпадать с байесовской вероятностью $P(\\theta > 0.5 | S, N)$. При большом количестве точек $\\text{Var}(U_A)/(N_A N_B)^2 \\to 1/6N, N_A=N_B=N \\to \\infty$. В байесовской модели при слабом отличии между группами $\\mu \\approx 0.5$, $\\sigma^2 \\approx 1/4N $. Поэтому $p \\lesssim 1 - P(B > A)$. \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "p & \\approx P \\left( \\mbox{Norm}\\left(x < u_A; 0.5, 1/6N \\right) \\right)\n",
    "\\\\\n",
    "& \\lesssim P(\\text{Norm}(x < 0.5; \\mu, 1/4N))\n",
    "\\\\\n",
    "& = P(A > B)\n",
    "\\\\\n",
    "& \\approx 1 - P(B > A)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef141e",
   "metadata": {},
   "source": [
    "Проверка связи $p$-значения с байесовской вероятностью сделана на примере нормальных распределений. Вероятность точки из распределения $B$ больше $A$ равна вероятности разности $B-A$ больше нуля $P(B > A) = P(B - A > 0)$.  Разность нормальных распределений также нормальное распределение со средним, равным разности исходных средних, и дисперсией, равной сумме дисперсий [[NormalSum](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables)].\n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "A \\sim \\text{Norm}(\\mu_A, \\sigma_A^2),\n",
    "\\quad\n",
    "B \\sim \\text{Norm}(\\mu_B, \\sigma_B^2)\n",
    "\\\\\n",
    "B - A \\sim \\text{Norm}(\\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2)\n",
    "\\\\\n",
    "P(B > A) = P(B - A > 0) = 1 - F_{B-A}(0)\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d74d305",
   "metadata": {},
   "source": [
    "На первом графике ниже показаны исходные нормальные распределения со средними `mu1=0, mu2=0.1` и единичной дисперсией. Темная линия на втором графике - $U/N_A N_B$ в предположении эквивалентности распределений. Темная закрашенная область соответствует $p$-значению [[ScipyMannWhitneyU](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)]. Светлая линия показывает байесовскую модель, светлая закрашенная область - байесовскую вероятность $P(A>B)$. Байесовская модель шире $U/N_A N_B$ из-за большей дисперсии. Площадь светлой области обычно больше темной, что соответствует $p \\lesssim P(A>B)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34)\n",
    "\n",
    "mu1, sigma1 = 0.0, 1\n",
    "mu2, sigma2 = 0.1, 1\n",
    "exactA = stats.norm(loc=mu1, scale=sigma1)\n",
    "exactB = stats.norm(loc=mu2, scale=sigma2)\n",
    "p_b_gt_a_exact = 1 - stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "\n",
    "nA = nB = 1000\n",
    "sampA = exactA.rvs(nA)\n",
    "sampB = exactB.rvs(nB)\n",
    "\n",
    "U, pval = stats.mannwhitneyu(sampA, sampB, alternative='greater')\n",
    "pval = pval if U / (nA * nB) > 0.5 else 1 - pval\n",
    "varu = nA * nB * (nA + nB + 1) / 12\n",
    "p_u = stats.norm(loc=0.5, scale=np.sqrt(varu/(nA*nA*nB*nB)))\n",
    "ua = U / (nA*nB)\n",
    "\n",
    "a0 = 1\n",
    "b0 = 1\n",
    "S = np.sum(sampB > sampA)\n",
    "post_theta = stats.beta(a0 + S, b0 + nB - S)\n",
    "\n",
    "\n",
    "x = np.linspace(-7, 7, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactA.pdf(x),\n",
    "    mode='lines', name='A', line_color='black'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactB.pdf(x),\n",
    "    mode='lines', name='B', line_color='blue', opacity=0.7))\n",
    "fig.update_layout(\n",
    "    title=\"A, B\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()\n",
    "#fig.write_image(\"../figs/apx_pval_u_originaldists.png\", scale=2)\n",
    "#Исходные распределения.\n",
    "\n",
    "xaxis_min = 0.4\n",
    "xaxis_max = 0.6\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=p_u.pdf(x), \n",
    "                         line_color='black', opacity=0.8, name=f'$U_A/N_A N_B$'))\n",
    "fig.add_trace(go.Scatter(x=x[x<ua], y=p_u.pdf(x[x<ua]), \n",
    "                         line_color='black', opacity=0.8, name=r'$p = P(x < u_A | H_0)$', \n",
    "                         fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_theta.pdf(x),\n",
    "                         line_color='black', opacity=0.3, name=r'$P(\\theta | S, N)$'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0.5], y=post_theta.pdf(x[x<0.5]), \n",
    "                         name=r'$P(\\theta < 0.5 | S, N)$',\n",
    "                         line_color=\"rgba(128, 128, 128, 0.3)\",\n",
    "                         fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.3)\"))\n",
    "fig.add_trace(go.Scatter(x=[1-ua, 1-ua], y=[0, max(p_u.pdf(x))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$1-u_A$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=[ua, ua], y=[0, max(p_u.pdf(x))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$u_A$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=[0.5, 0.5], y=[0, max(p_u.pdf(x))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$0.5$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.update_layout(\n",
    "    title=r'$U\\text{-статистика и байесовская модель}$',\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()\n",
    "#fig.write_image(\"../figs/apx_pval_utest.png\", scale=2)\n",
    "#Темная линия соответствует распределению , закрашенная темная область - p-значению U-теста. \n",
    "#Светлая линия - байесовская модель, закрашенная светлая область - оценка вероятности точки из А больше Б. \n",
    "#При большом количестве точек p-значение будет меньше байесовской вероятности выбранной модели.\n",
    "\n",
    "print(f'CDF(u_a): {p_u.cdf(ua):.5f}')\n",
    "print(f'scipy min(pval, 1-pval): {min(pval, 1-pval):.5f}')\n",
    "print(f'Bayes P(theta < 0.5) {post_theta.cdf(0.5):.5f}')\n",
    "print()\n",
    "print(f'P(B>A) exact: {p_b_gt_a_exact:.5f}')\n",
    "print(f'1 - U/(NA NB): {1-ua:.5f}')\n",
    "print(f'Bayes E[theta] {post_theta.mean():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bc75e",
   "metadata": {},
   "source": [
    "Для байесовской модели и $U$-статистики проверяется доля правильно угаданных вариантов с большей вероятностью $P(B>A)$ в серии экспериментов. В каждом эксперименте задается два нормальных распределения. Среднее $A$ фиксировано `mua = 0.1`, среднее $B$ выбирается случайно в пределах $\\pm 5\\%$ от $A$. Вначале проверяется байесовская модель. Всего проводится `nexp` экспериментов, в группы добавляются данные по `n_samp_step` точек за раз. На каждом шаге считается байесовсая вероятность $P(B > A) = P(\\theta  > 0.5 | S)$. Эксперимент останавливается, если $P(B > A)$ или $P(A > B)$ превышает `prob_stop`. В обоих подходах - байесовском и $U$-тесте - нужно задавать минимальный размер выборки для выполнения заданного уровня точности. В байесовской модели вместо минимальной выборки задаются априорные параметры `a0 = 100000, b0 = 100000`. Из 1000 экспериментов завершено 860, корректно угадано 827. Точность 0.96 близка заданной `prob_stop = 0.95`. При остановке в каждом эксперименте считается $U$-статистика, она как правило превышает байесовскую вероятность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9388cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_u'])\n",
    "\n",
    "mua = 0.1\n",
    "nexps = 1000\n",
    "cmp['A'] = [mua] * nexps\n",
    "cmp['B'] = mua * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 5_000_000\n",
    "n_samp_step = 10000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    mua = cmp.at[i, 'A']\n",
    "    mub = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.norm(loc=mua)\n",
    "    exact_dist_B = stats.norm(loc=mub)\n",
    "    n_samp_total = 0\n",
    "    sampA = exact_dist_A.rvs(n_samp_max)\n",
    "    sampB = exact_dist_B.rvs(n_samp_max)\n",
    "    while n_samp_total < n_samp_max:\n",
    "        n_samp_total += n_samp_step\n",
    "        a0 = 100000\n",
    "        b0 = 100000\n",
    "        Ub = np.sum(sampB[:n_samp_total] > sampA[:n_samp_total])\n",
    "        post_u_ewise = stats.beta(a0 + Ub, b0 + n_samp_total - Ub)\n",
    "        pb_gt_pa_bayes = 1 - post_u_ewise.cdf(0.5)\n",
    "        best_gr = 'B' if pb_gt_pa_bayes >= prob_stop else 'A' if 1 - pb_gt_pa_bayes >= prob_stop else None\n",
    "        if best_gr:\n",
    "            U, pval = stats.mannwhitneyu(sampA[:n_samp_total], sampB[:n_samp_total], alternative='greater')\n",
    "            cmp.at[i, 'A_exp'] = sampA[:n_samp_total].mean()\n",
    "            cmp.at[i, 'B_exp'] = sampB[:n_samp_total].mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p_best_u'] = max(pval, 1 - pval)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P_best Bayes {pb_gt_pa_bayes:.4f}, U p-val: {pval:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "finished = np.sum(cmp['best_exp'].notna())\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Finished: {finished}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / finished}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca0a86",
   "metadata": {},
   "source": [
    "Для проверки правильно угаданных вариантов по $U$-статистике выставлен больший шаг - добавляется по `n_samp_step = 200_000` точек в каждой группе. Такой шаг также учитывает минимальный размер выборки. Из 300 экспериментов завершено 262, верно угадано 249 групп. Доля верно угаданных вариантов `0.95` совпала с `prob_stop=0.95`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_u'])\n",
    "\n",
    "mua = 0.1\n",
    "nexps = 300\n",
    "cmp['A'] = [mua] * nexps\n",
    "cmp['B'] = mua * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 5_000_000\n",
    "n_samp_step = 200_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    mua = cmp.at[i, 'A']\n",
    "    mub = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.norm(loc=mua)\n",
    "    exact_dist_B = stats.norm(loc=mub)\n",
    "    n_samp_total = 0\n",
    "    sampA = exact_dist_A.rvs(n_samp_max)\n",
    "    sampB = exact_dist_B.rvs(n_samp_max)\n",
    "    while n_samp_total < n_samp_max:\n",
    "        n_samp_total += n_samp_step\n",
    "        U, pval = stats.mannwhitneyu(sampA[:n_samp_total], sampB[:n_samp_total], alternative='greater')\n",
    "        pb_gt_pa_u = 1 - U / n_samp_total / n_samp_total\n",
    "        best_gr = 'B' if pval >= prob_stop else 'A' if 1 - pval >= prob_stop else None        \n",
    "        if best_gr:\n",
    "            a0 = 100000\n",
    "            b0 = 100000\n",
    "            Ub = np.sum(sampB[:n_samp_total] > sampA[:n_samp_total])\n",
    "            post_u_ewise = stats.beta(a0 + Ub, b0 + n_samp_total - Ub)\n",
    "            pb_gt_pa_bayes = 1 - post_u_ewise.cdf(0.5)\n",
    "            cmp.at[i, 'A_exp'] = sampA[:n_samp_total].mean()\n",
    "            cmp.at[i, 'B_exp'] = sampB[:n_samp_total].mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p_best_u'] = max(pval, 1 - pval)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P_best Bayes {pb_gt_pa_bayes:.4f}, U p-val: {pval:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "finished = np.sum(cmp['best_exp'].notna())\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Finished: {finished}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / finished}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be6378",
   "metadata": {},
   "source": [
    "Для $t$-теста, $\\chi^2$-теста и $U$-критерия Манна-Уитни показаны байесовские модели с вероятностью лучшей группы численно близкой $p$-значениям. Соотношения выполняются несмотря на различия в определениях $p$-значений и байесовских вероятностей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247790d6",
   "metadata": {},
   "source": [
    "## Ссылки\n",
    "\n",
    "[Chi2Dist] - [Chi-squared Distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution), *Wikipedia.*  \n",
    "[Chi2Pearson] - [Pearson’s Chi-squared Test](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test), *Wikipedia.*  \n",
    "[Chi2Test] - [Chi-squared Test](https://en.wikipedia.org/wiki/Chi-squared_test), *Wikipedia.*  \n",
    "[ConjPrior] - [Conjugate Prior](https://en.wikipedia.org/wiki/Conjugate_prior#When_likelihood_function_is_a_continuous_distribution), *Wikipedia.*   \n",
    "[MannWhitneyU] - [Mann–Whitney U Test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test), *Wikipedia.*  \n",
    "[NormalSum] - [Sum of Normally Distributed Random Variables](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables), *Wikipedia.*  \n",
    "[PVal] - [P-value](https://en.wikipedia.org/wiki/P-value), *Wikipedia.*  \n",
    "[ScipyChi2Con] - [scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html), *SciPy Reference.*  \n",
    "[ScipyMannWhitneyU] - [scipy.stats.mannwhitneyu](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html), *SciPy Reference.*  \n",
    "[ScipyTTestInd] - [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html), *SciPy Reference.*  \n",
    "[TailedTests] - [One- and Two-tailed Tests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests), *Wikipedia.*  \n",
    "[TDist] - [Student’s t-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution), *Wikipedia.*  \n",
    "[TestStat] - [Test Statistic](https://en.wikipedia.org/wiki/Test_statistic), *Wikipedia.*  \n",
    "[TTest] - [Student’s t-test](https://en.wikipedia.org/wiki/Student%27s_t-test), *Wikipedia.*  \n",
    "[WelchT] - [Welch’s t-test](https://en.wikipedia.org/wiki/Welch%27s_t-test), *Wikipedia.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
