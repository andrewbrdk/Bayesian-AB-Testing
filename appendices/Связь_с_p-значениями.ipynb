{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059d7c01",
   "metadata": {},
   "source": [
    "# Байесовские А/Б-тесты: связь с $p$-значениями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b4a7a6",
   "metadata": {},
   "source": [
    "*Показана связь $p$-значений $t$-теста, $\\chi^2$-теста и $U$-критерия Манна-Уитни в А/Б-тестах со сравнением параметров байесовских моделей. При определенных условиях $p$-значения численно близки байесовским вероятностям несмотря на различия в определениях.*\n",
    "\n",
    "*- [$P$-значения](#$P$-значения)*  \n",
    "*- [$T$-тест](#$T$-тест)*  \n",
    "*- [Тест $\\chi^2$](#Тест-$\\chi^2$)*  \n",
    "*- [U-критерий Манна-Уитни](#U-критерий-Манна-Уитни)*  \n",
    "*- [Ссылки](#Ссылки)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6b5af",
   "metadata": {},
   "source": [
    "## $P$-значения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a519a4",
   "metadata": {},
   "source": [
    "$P$-значения используют в проверках нулевых гипотез. В этом методе формулируют гипотезу $H_0$ об изучаемом процессе и выбирают статистический тест $T$ - случайную величину с известным распределением $P_{T}(x | H_0)$ в предположении $H_0$. Считают реализацию величины $T$ в данных - тестовую статистику $x_{0}$ [[TestStat](https://en.wikipedia.org/wiki/Test_statistic)]. Вероятность получить фактическое или более экстремальное значение тестовой статистики называют односторонним $p$-значением $p = P_{T}(x \\ge x_{0} | H_0)$ [[PVal](https://en.wikipedia.org/wiki/P-value), [TailedTests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests)]. Если вероятность достаточно мала, гипотезу $H_0$ отвергают, если нет - оставляют."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d41335",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../figs/null_hypothesis.png\" alt=\"null_hypothesis\" width=\"800\"/>\n",
    "<em> В предположении гипотезы $H_0$ распределение тестовой статистики $P_{T}(x | H_0)$. Вероятность получить фактическое $x_0$ или более экстремальное значение тестовой статистики называют $p$-значением $p = P_{T}(x \\ge x_{0} | H_0)$. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46499a53",
   "metadata": {},
   "source": [
    "Проблема метода - решение о гипотезе $H_0$ принимают по $p$-значению $p = P_{T}(x \\ge x_{0} | H_0)$, тогда как вероятность гипотезы с учетом собранных данных оценивается величиной $P(H_0 | x_0)$. По соотношению Байеса $P(H_0 | x_0) \\propto P_{T}(x = x_{0} | H_0) P(H_0)$. Т.е. для выбора гипотезы нужно посчитать вероятности получить данные в рамках конкурирующих гипотез и сравнить друг с другом с учетом априорных вероятностей.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97cba49",
   "metadata": {},
   "source": [
    "В А/Б-тестах распространены $t$-тест средних, $\\chi^2$-тест пропорций и $U$-критерий Манна-Уитни. Далее показано как при определенных условиях $p$-значения этих тестов численно близки байесовским вероятностям параметров одной группы больше другой. Соотношения выполняются несмотря на различия в определениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e63c00",
   "metadata": {},
   "source": [
    "## $T$-тест"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a120f",
   "metadata": {},
   "source": [
    "Средние сравнивают $t$-тестами [[TTest](https://en.wikipedia.org/wiki/Student%27s_t-test)]. Пусть есть выборки размера $N_A, N_B$ из двух случайных величин $A, B$. В предположении одинаковых точных средних $H_0: E[A] = E[B]$ для отношения разности выборочных средних к стандартной ошибке разности средних $X = \\overline{\\Delta}/s_{\\Delta}$ ожидают $t$-распределение [[WelchT](https://en.wikipedia.org/wiki/Welch%27s_t-test)]. При достаточно большом количестве данных оно близко стандартному нормальному $\\text{Norm}(0, 1)$ [[TDist](https://en.wikipedia.org/wiki/Student%27s_t-distribution)]. По выборкам считают фактическое отношение $x_0 = \\overline{\\Delta}/s_{\\Delta}$. Вычисляют вероятность получить $x_0$ или более экстремальное отношение - одностороннее $p$-значение $P_{X}(x \\ge x_0 | H_0)$. Если оно меньше заданного уровня значимости, средние в группах считают неравными.\n",
    "\n",
    "$$\n",
    "\\overline{A} = \\frac{1}{N_{A}} \\sum_{i=1}^{N_{A}} A_i,\n",
    "\\quad\n",
    "s_A^2 = \\frac{1}{N_A} \\sum_{i=1}^{N_A} (A_i - \\overline{A})^2,\n",
    "\\quad\n",
    "\\text{так же для } B\n",
    "\\\\\n",
    "X = \\frac{\\overline{\\Delta}}{s_{\\Delta}},\n",
    "\\quad\n",
    "\\overline{\\Delta} = \\overline{B} - \\overline{A},\n",
    "\\quad\n",
    "s^2_{\\Delta} = \\frac{s_A^2}{N_A} + \\frac{s_B^2}{N_B}\n",
    "\\\\\n",
    "H_0: E[A] = E[B],\n",
    "\\quad\n",
    "P_{X}(x | H_0) \\approx \\text{Norm}(x; 0, 1)\n",
    "\\\\\n",
    "x_0 - \\text{реализация } X, \\quad\n",
    "p = P_{X}(x \\ge x_0 | H_0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e3130",
   "metadata": {},
   "source": [
    "В А/Б-тесте нужно выбрать группу с большим средним. Поэтому вместо $p$-значения $P_{X}(x \\ge x_0 | H_0)$ интересна вероятность среднего $B$ больше $A$ при условии собранных данных $P(\\mu_B > \\mu_A | A_i, B_j ) = P(\\mu_{\\Delta} > 0 | A_i, B_j )$, где $\\mu_A, \\mu_B, \\mu_{\\Delta}$ - оценки точных средних соответствующих распределений. Эту вероятность можно оценить байесовским моделированием. Оценка точного среднего строится с помощью центральной предельной теоремы - распределение выборочных средних предполагается нормальным. Вместо оценки средних в каждом распределении строится оценка средней разности. В качестве правдоподобия выбирается нормальное распределение $P(\\overline{\\Delta} | \\mu_{\\Delta}) = \\text{Norm}(\\overline{\\Delta} | \\mu_{\\Delta}, s_{\\Delta}^2)$ с одним случайным параметром - средним $\\mu_{\\Delta}$ . Дисперсия выбирается равной $s_{\\Delta}^2$ на основе данных. Априорное распределение также выбирается нормальным для сопряженности $P(\\mu_{\\Delta}) = \\text{Norm}(\\mu_{\\Delta} | \\mu_0, \\sigma_0^2)$. Апостериорное распределение будет нормальным с обновленными средним и дисперсией $P(\\mu_{\\Delta} | \\overline{\\Delta}) = \\text{Norm}(\\mu_{\\Delta} | \\mu_{N}, \\sigma_{N}^2)$. Моделирование применяется к выборочным средним, а не к исходным выборкам. Выборочное среднее считается по всем точкам распределений разности, поэтому для обновления параметров есть только одна точка $\\overline{\\Delta}$. При достаточно широком априорном распределении $\\sigma_{0}^2 \\gg s^2_{\\Delta}$ апостериорное распределение приближенно $P(\\mu_{\\Delta} | \\overline{\\Delta}) \\approx \n",
    "\\text{Norm}(\\mu_{\\Delta} | \\overline{\\Delta}, s^2_{\\Delta})$. Поэтому $P(\\mu_B > \\mu_A | A_i, B_j ) = P(\\mu_{\\Delta} > 0 | \\overline{\\Delta})  \\approx P(\\text{Norm}(x > 0 | x_0, 1))$.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(\\overline{\\Delta} | \\mu_{\\Delta}) & =\n",
    "\\text{Norm}(\\overline{\\Delta} | \\mu_{\\Delta}, s_{\\Delta}^2),\n",
    "\\quad\n",
    "P(\\mu_{\\Delta}) =\n",
    "\\text{Norm}(\\mu_{\\Delta} | \\mu_0, \\sigma_0^2) \n",
    "\\\\\n",
    "P(\\mu_{\\Delta} | \\overline{\\Delta}) \n",
    "& = \\text{Norm}(\\mu_{\\Delta} | \\mu_{N}, \\sigma_{N}^2),\n",
    "\\quad\n",
    "\\sigma_{N}^2 = \\frac{\\sigma_{0}^2 s_{\\Delta}^2}{s_{\\Delta}^2 + \\sigma_{0}^2},\n",
    "\\quad\n",
    "\\mu_{N} = \\mu_{0} \\frac{\\sigma_{N}^2}{\\sigma_{0}^2} + \\frac{\\sigma_{N}^2}{s_{\\Delta}^2} \\overline{\\Delta}\n",
    "\\\\\n",
    "\\mu_0 = 0, & \\, \\sigma_{0}^2 \\gg s^2_{\\Delta}: \n",
    "\\, \n",
    "\\sigma_N^2 \\approx s^2_{\\Delta}, \\, \\mu_N \\approx \\overline{\\Delta}, \n",
    "\\\\\n",
    "P(\\mu_{\\Delta} | \\overline{\\Delta}) & \\approx \n",
    "\\text{Norm}(\\mu_{\\Delta} | \\overline{\\Delta}, s^2_{\\Delta})\n",
    "\\\\\n",
    "P(\\mu_B > \\mu_A | A_i, B_j ) &= P(\\mu_{\\Delta} > 0 | \\overline{\\Delta})  \\approx P(\\text{Norm}(\\mu_{\\Delta} > 0 | \\overline{\\Delta}, s^2_{\\Delta})) = P(\\text{Norm}(x > 0 | x_0, 1))\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04425d",
   "metadata": {},
   "source": [
    "По симметрии нормального распределения $P(\\text{Norm}(x > x_0 | 0, 1)) =  P(\\text{Norm}(x < 0 | x_0, 1))$. Поэтому $p$-значение одностороннего $t$-теста близко вероятности среднего одной группы больше другой.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "p = P_{X}(x > x_0 | H_0)\n",
    "& = P(\\text{Norm}(x > x_0| 0, 1))\n",
    "\\\\\n",
    "& =  P(\\text{Norm}(x < 0 | x_0, 1)) \n",
    "\\\\\n",
    "& = 1 - P(\\text{Norm}(x > 0 | x_0, 1)) \n",
    "\\approx 1 - P(\\mu_B > \\mu_A | A_i, B_j )\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5614ef",
   "metadata": {},
   "source": [
    "На графике ниже 2 нормальных распределения. Одно с центром в точке 0, другое в точке $x_0 = 2$. Вероятность \n",
    "$p = P(x > x_0 | \\mu_A = \\mu_B)$ закрашена темным, $P(\\text{Norm}(x < 0 | x_0, 1)) \\approx 1 - P(\\mu_B > \\mu_A | x_0 )$ закрашена светлым. По свойствам нормального распределения площади этих областей совпадают. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 2\n",
    "\n",
    "xaxis_min = -7\n",
    "xaxis_max = 7\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=1), \n",
    "                         line_color='black', opacity=0.8, name='$\\mathrm{Norm}(0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[x0, x0], y=[0, max(stats.norm.pdf(x, loc=0, scale=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$x_0$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>x0], y=stats.norm.pdf(x[x>x0], loc=0, scale=1), \n",
    "                         line_color='black', opacity=0.8, name='$P(\\mathrm{Norm}(x > x_0 | 0, 1))$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=x0, scale=1), \n",
    "                         line_color='black', line_dash='solid', opacity=0.2, name='$\\mathrm{Norm}(x_0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(stats.norm.pdf(x, loc=0, scale=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '0'], textposition=\"top center\", \n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=stats.norm.pdf(x[x<0], loc=x0, scale=1), \n",
    "                         line_color=\"rgba(128, 128, 128, 0.2)\", name='$P(\\mathrm{Norm}(x < 0 | x_0, 1))$', fill=\"tozeroy\", fillcolor=\"rgba(128, 128, 128, 0.2)\"))\n",
    "fig.update_layout(title='P-значение и вероятность среднего одной группы больше другой',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d8603",
   "metadata": {},
   "source": [
    "Таким образом $p$-значение одностороннего $t$-теста близко байесовской оценке вероятности среднего одной группы больше другой. Для демонстрации ниже заданы два нормальных распределения с разными средними. По выборке байесовская оценка вероятности $P(\\mu_B > \\mu_A)$ сравнивается с $p$-значением $t$-теста. Используется односторонний $t$-тест с разными дисперсиями групп (`equal_var=False`, `alternative`) [[ScipyTTestInd](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)]. Видно, что $p$-значение численно близко байесовской оценке вероятности. Стоит помнить, что они не эквивалентны - у них разные определения. На графике показано апостериорное байесовское распределение среднего разности и масштабированное нормальное распределение для $p$-значения. Вместо $x_0$ показано точное среднее $E[B] - E[A]$. Видно, что байесовская модель угадывает положение точного среднего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_diff_norm(sampA, sampB, mu0=None, s20=None):\n",
    "    delta = sampB.mean() - sampA.mean()\n",
    "    s2delta = sampA.var() / sampA.size + sampB.var() / sampB.size\n",
    "    mu0 = mu0 or 0\n",
    "    s20 = s20 or 30 * s2delta\n",
    "    s2n = s2delta * s20 / (s2delta + s20)\n",
    "    mun = mu0 * s2n / s20 + delta * s2n / s2delta\n",
    "    return stats.norm(loc=mun, scale=np.sqrt(s2n))\n",
    "\n",
    "muA = 0.1\n",
    "muB = 0.115\n",
    "sigma = 1.0\n",
    "\n",
    "exactA = stats.norm(muA, sigma)\n",
    "exactB = stats.norm(muB, sigma)\n",
    "mean_diff_exact = muB - muA\n",
    "\n",
    "N = 30000\n",
    "sampA = exactA.rvs(size=N)\n",
    "sampB = exactB.rvs(size=N)\n",
    "\n",
    "post_dist_diff = posterior_dist_diff_norm(sampA, sampB)\n",
    "mean_b_gt_a = 1 - post_dist_diff.cdf(0)\n",
    "\n",
    "a = 'greater' if np.mean(sampA) > np.mean(sampB) else 'less'\n",
    "t_stat, p_value = stats.ttest_ind(sampA, sampB, equal_var=False, alternative=a)\n",
    "s2delta = sampA.var() / sampA.size + sampB.var() / sampB.size\n",
    "t_scaled = t_stat * np.sqrt(s2delta) if np.mean(sampA) > np.mean(sampB) else -t_stat * np.sqrt(s2delta)\n",
    "\n",
    "xaxis_min = -0.1\n",
    "xaxis_max = 0.1\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=np.sqrt(s2delta)), \n",
    "                         line_color='black', opacity=0.8, name='$\\mathrm{Norm}(0, s^2_{\\Delta})$'))\n",
    "fig.add_trace(go.Scatter(x=x[x>t_scaled], y=stats.norm.pdf(x[x>t_scaled], loc=0, scale=np.sqrt(s2delta)), \n",
    "                         line_color=\"rgba(0, 0, 0, 0.7)\", name='$P(x>x_0 | H_0)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist_diff.pdf(x), \n",
    "                         line_color='black', opacity=0.2, name='$\\mathrm{Norm}(\\mu_{\\Delta} | \\mu_N, \\sigma_N^2)$'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=post_dist_diff.pdf(x[x<0]), \n",
    "                         line_color=\"rgba(128, 128, 128, 0.2)\", name='$P(\\mu_{\\Delta} < 0)$', fill=\"tozeroy\", fillcolor=\"rgba(128, 128, 128, 0.2)\"))\n",
    "# fig.add_trace(go.Scatter(x=[t_scaled, t_scaled], y=[0, max(post_dist_diff.pdf(x))*1.1], \n",
    "#                          line_color='black', \n",
    "#                          mode='lines',\n",
    "#                          line_dash='dash', name='$t \\cdot s_{\\Delta}$'))\n",
    "fig.add_trace(go.Scatter(x=[mean_diff_exact, mean_diff_exact], y=[0, max(post_dist_diff.pdf(x))*1.1], \n",
    "                         line_color='black', \n",
    "                         #mode='lines',\n",
    "                         mode='lines+text', text=['', '$E[B] - E[A]$'], textposition=\"top center\",\n",
    "                         line_dash='dash',\n",
    "                         showlegend=False,\n",
    "                         name='$E[B]-E[A]$'))\n",
    "fig.update_layout(title='Апостериорное распределение среднего разности',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "print(f'p-value P(x>x0 | pa=pb): {p_value}')\n",
    "print(f'1 - p: {1 - p_value}')\n",
    "print(f'Bayes P(pb > pa): {pb_gt_pa}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c419d18",
   "metadata": {},
   "source": [
    "Численную близость $p$-значения вероятности среднего одной группы больше другой можно проверить по количеству правильно угаданных вариантов с большим значением конверсии в серии экспериментов. В группе А задается фиксированная конверсия `p=0.1`, в Б - случайная в диапазоне $\\pm 5\\%$ от `p`. В группах генерируются данные с шагом `n_samp_step`. На каждом шаге считается $t$-тест. Эксперимент останавливается, если  $p$ или $1-p$ достигает `prob_stop=0.95` или сгенерировано максимальное количество точек `n_samp_max`. Длительность эксперимента не фиксируется заранее. При остановке эксперимента для сравнения с $p$-значением считаются байесовские апострериорные распределения и вероятность $P(p_B > p_A)$. Процедура повторяется `nexps` раз, считается доля правильно угаданных групп во всех экспериментах. Байесовские вероятности близки $p$-значениям. В `nexps = 1000` правильно угадано 927 вариантов. Точность 0.927 близка `prob_stop = 0.95`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p-val'])\n",
    "\n",
    "mu = 0.1\n",
    "nexps = 300\n",
    "cmp['A'] = [mu] * nexps\n",
    "cmp['B'] = mu * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 3_000_000\n",
    "n_samp_step = 10_000\n",
    "n_samp_min = 50_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    muA = cmp.at[i, 'A']\n",
    "    muB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.norm(loc=muA, scale=1)\n",
    "    exact_dist_B = stats.norm(loc=muB, scale=1)\n",
    "    n_samp_current = n_samp_min\n",
    "    sampA = exact_dist_A.rvs(n_samp_max)\n",
    "    sampB = exact_dist_B.rvs(n_samp_max)\n",
    "    while n_samp_current < n_samp_max:\n",
    "        n_samp_current += n_samp_step\n",
    "        a = 'greater' if np.mean(sampA[:n_samp_current]) > np.mean(sampB[:n_samp_current]) else 'less'\n",
    "        t_stat, p_value = stats.ttest_ind(sampA[:n_samp_current], sampB[:n_samp_current], equal_var=False, alternative=a)\n",
    "        p_best_t = 1 - p_value\n",
    "        best_gr = 'A' if p_best_t >= prob_stop and a == 'greater' else 'B' if p_best_t >= prob_stop and a == 'less' else None\n",
    "        if best_gr:\n",
    "            post_dist_diff = posterior_dist_diff_norm(sampA[:n_samp_current], sampB[:n_samp_current])\n",
    "            mean_b_gt_a_bayes = 1 - post_dist_diff.cdf(0)\n",
    "            cmp.at[i, 'A_exp'] = sampA[:n_samp_current].mean()\n",
    "            cmp.at[i, 'B_exp'] = sampB[:n_samp_current].mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_current\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(mean_b_gt_a_bayes, 1 - mean_b_gt_a_bayes)\n",
    "            cmp.at[i, 'p-val'] = max(p_value, 1 - p_value)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_current}, best_gr {best_gr}, Bayes P(b>a) {mean_b_gt_a_bayes:.4f}, T-test p-val {p_value:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "finished = np.sum(cmp['best_exp'].notna())\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Finished: {finished}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / finished}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3ec00",
   "metadata": {},
   "source": [
    "## Тест $\\chi^2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06de92d",
   "metadata": {},
   "source": [
    "Конверсии могут сравнивать $\\chi^2$-тестом [[Chi2Test](https://en.wikipedia.org/wiki/Chi-squared_test)]. Статистика $\\chi^2$ Пирсона [[Chi2Pearson](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)] для мультиномиальных распределений определена $\\chi^2 = \\sum_{i=1}^k (S_i - Np_i)^2/(Np_i)$, где $N$ - общее количество наблюдений, $S_i$ и $N p_i$ - фактическое и ожидаемое количество наблюдений $i$-категории при доле $i$-категории $p_i$. Для биномиального распределения $\\chi^2=(S - Np)^2/N p (1-p)$. По центральной предельной теореме $(S - Np)/\\sqrt{N p (1-p)}$ стремится к стандартному нормальному распределению, квадрат величины совпадает с $\\chi^2$. Распределение суммы квадратов $k$ нормальных случайных величин называют $\\chi^2$-распределением с $k$ степенями свободы $\\chi^2_k = \\sum_{i=1}^{k} X_i^2,\\, X_i \\sim \\text{Norm}(0,1)$ [[Chi2Dist](https://en.wikipedia.org/wiki/Chi-squared_distribution)]. Поэтому статистика $\\chi^2$ стремится к $\\chi_1^2$-распределению.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\chi^2 & = \n",
    "\\sum_{i=1}^k \\frac{(S_i - Np_i)^2}{N p_i}\n",
    "\\\\\n",
    "& =\n",
    "\\frac{(S - N p)^2}{N p}\n",
    "+\n",
    "\\frac{((N - S) - N (1-p))^2}{N (1-p)}\n",
    "\\\\\n",
    "& =\n",
    "\\frac{(S - Np)^2}{N p (1-p)} \n",
    "\\to \\chi_1^2, \\quad n \\to \\infty\n",
    "\\\\\n",
    "\\chi^2_k & = \\sum_{i=1}^{k} X_i^2,\\, X_i \\sim \\text{Norm}(0,1)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b9d00",
   "metadata": {},
   "source": [
    "Для А/Б-теста конверсий с двумя группами в предположении одинаковых конверсий $p=(S_A + S_B)/(N_A + N_B)$ тестовая статистика $\\chi^2=(S_A - N_A p)^2/N_A p (1-p) + (S_B - N_B p)^2/N_B p (1-p)$. Ее можно привести к виду $\\chi^2 = (p_A - p_B)^2/(s^2 / N_A + s^2 / N_B)$, $s^2 = p (1 - p)$, $p_A = S_A / N_A$, $p_B = S_B / N_B$. При большом количестве точек распределение $\\chi^2$ можно ожидать близим $\\chi_1^2$. $p$-значение $p=P_{\\chi_1^2}(x > \\chi^2)$. Распределение $\\chi^2_1$ получается при возведении в квадрат стандартного нормального распределения. Область $P_{\\chi_1^2}(x > \\chi^2)$ соответствует областям $P_{Norm(0,1)}(x > \\chi \\cup x < -\\chi)$. По симметрии нормального распределения площади $x > \\chi$ и $x < -\\chi$ одинаковы. Байесовская оценка вероятности конверсии одной группы больше другой с учетом собранных данных при использовании априорного бета-распределения $P(\\mu_B > \\mu_A | S_A, S_B, N_A, N_B) \\approx P_{Norm(p_{\\Delta}, s_{\\Delta}^2)}(x > 0)$, $p_{\\Delta} = p_B - p_A$,  $s_{\\Delta} = s_A^2/N_A + s_B^2/N_B$. В пренебрежении априорным распределением $P(\\mu_B > \\mu_A | S_A, S_B) \\approx 1 - P_{Norm(\\chi, 1)}(x < 0)$. По симметрии $P_{Norm(\\chi, 1)}(x < 0) = P_{Norm(0, 1)}(x > \\chi)$ Поэтому $p$-значение $p \\approx 2( 1 - P(\\mu_B > \\mu_A | S_A, S_B))$. Отсюда $P(p_B > p_A | S_A, S_B) \\approx 1 - p/2$.\n",
    "\n",
    "$$\n",
    "p_A = \\frac{S_A}{N_A}, \\quad \n",
    "p_B = \\frac{S_B}{N_B}, \\quad \n",
    "p = \\frac{S_A + S_B}{N_A + N_B},\n",
    "\\quad\n",
    "s^2 = p (1 - p)\n",
    "\\\\\n",
    "\\begin{split}\n",
    "p_A = p_B: \\chi^2 & = \\frac{(S_A - N_A p)^2}{N_A p (1-p)} + \\frac{(S_B - N_B p)^2}{N_B p (1-p)} \n",
    "\\\\\n",
    "& = \\frac{N_A N_B (p_A - p_B)^2}{(N_A + N_B) p (1-p)}\n",
    "\\\\\n",
    "& = \\frac{(p_A - p_B)^2}{s^2 / N_A + s^2 / N_B} \\to \\chi_1^2, \\, n \\to \\infty\n",
    "\\end{split}\n",
    "\\\\\n",
    "\\begin{split}\n",
    "\\text{p-val} & = P_{\\chi_1^2}(x > \\chi^2 | p_A = p_B)\n",
    "\\\\\n",
    "& = P_{Norm(0,1)}(x > \\chi \\cup x < -\\chi | p_A = p_B) \n",
    "\\\\\n",
    "& = 2 P_{Norm(0,1)}(x > \\chi | p_A = p_B)\n",
    "\\\\\n",
    "& \\approx 2 \\left( 1 - P(p_B > p_A | S_A, S_B) \\right)\n",
    "\\end{split}\n",
    "\\\\\n",
    "P(p_B > p_A | S_A, S_B) \\approx 1 - \\text{p-val}/2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8e2b6",
   "metadata": {},
   "source": [
    "Распределение $\\chi^2_1$ на первом графике ниже. Закрашенная область соответствует $p$-значению $p = P_{\\chi_1^2}(x > \\chi^2)$. На втором графике - стандартное нормальное распределение. Закрашенные темные области $x > \\chi$ и $x < - \\chi$ соответствуют $P_{\\chi_1^2}(x > \\chi^2)$ при возведении в квадрат. Серый график - нормальное распределение $Norm(\\chi, 1)$. Закрашенная область серого графика приближенно равна $1 - P(p_B > p_A | S_A, S_B)$. Площади закрашенной серой и каждой из темных областей совпадают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.3\n",
    "#s = p * (1 - p)\n",
    "#todo: N = 10000\n",
    "#s = p * (1 - p) / N\n",
    "s = 1\n",
    "x0 = p / (p * (1 - p))\n",
    "\n",
    "xaxis_min = 0\n",
    "xaxis_max = 5\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.chi.pdf(x, df=1), \n",
    "                         line_color='black', opacity=0.8, name=f'$\\chi^2_1$'))\n",
    "fig.add_trace(go.Scatter(x=[x0**2, x0**2], y=[0, max(stats.chi.pdf(x, df=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$\\chi^2$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>x0**2], y=stats.chi.pdf(x[x>x0**2], df=1), \n",
    "                         line_color='black', opacity=0.8, name='$P_{\\chi_1^2}(x > \\chi^2)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.update_layout(title='Хи-квадрат',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "xaxis_min = -5\n",
    "xaxis_max = 5\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name=f'$Norm(0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '0'], textposition=\"top center\", \n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=[x0, x0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$\\chi$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=[-x0, -x0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$-\\chi$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>x0], y=stats.norm.pdf(x[x>x0], loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name='$P_{Norm(0,1)}(x > \\chi \\cup x < -\\chi | p_A = p_B)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x[x<-x0], y=stats.norm.pdf(x[x<-x0], loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name='$P_{Norm(0,1)}(x > \\chi | p_A = p_B)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\",\n",
    "                         showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=x0, scale=s), \n",
    "                         line_color='black', opacity=0.2, name='$Norm(\\chi, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=stats.norm.pdf(x[x<0], loc=x0, scale=s), \n",
    "                         line_color=\"rgba(128, 128, 128, 0.2)\", name='$P_{Norm(\\chi,1)}(x < 0)$', fill=\"tozeroy\", fillcolor=\"rgba(128, 128, 128, 0.2)\"))\n",
    "fig.update_layout(title='Нормальные распределения',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6110e2",
   "metadata": {},
   "source": [
    "Соотношение $P(p_B > p_A | S_A, S_B) \\approx 1 - p/2$ проверяется по выборке из двух распределений Бернулли с конверсиями $p_A = 0.1$ и $p_B = 0.105$. Данные для $\\chi^2$-теста задаются в виде таблицы со строками $S_A, N_A-S_A$ и $S_B, N_B - S_B$ [[ScipyChi2Con](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html)]. Только $p$-значение не позволяет выбрать между $p_A > p_B$ и $p_B > p_A$, поэтому дополнительно сравниваются конверсии $p_A$, $p_B$. Видно, что связь $p$-значения и байесовской оценки вероятности численно выполняется. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "pA = 0.1\n",
    "pB = pA * 1.05\n",
    "\n",
    "exactA = stats.bernoulli(pA)\n",
    "exactB = stats.bernoulli(pB)\n",
    "\n",
    "N = 30000\n",
    "sampA = exactA.rvs(size=N)\n",
    "sampB = exactB.rvs(size=N)\n",
    "SA = np.sum(sampA)\n",
    "SB = np.sum(sampB)\n",
    "\n",
    "post_dist_A = posterior_dist_binom(ns=SA, ntotal=N)\n",
    "post_dist_B = posterior_dist_binom(ns=SB, ntotal=N)\n",
    "pb_gt_pa_bayes = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "\n",
    "t = np.array([\n",
    "    [SA,     N - SA],\n",
    "    [SB,     N - SB]\n",
    "])\n",
    "chi2_stat, p_value_chi2, dof, expected = stats.chi2_contingency(t, correction=False)\n",
    "p_A_samp = SA / N\n",
    "p_B_samp = SB / N\n",
    "pb_gt_pa_chi = 1 - p_value_chi2 / 2\n",
    "pb_gt_pa_chi = pb_gt_pa_chi if p_B_samp > p_A_samp  else 1 - pb_gt_pa_chi\n",
    "\n",
    "print(f'Bayes P(pb > pa): {pb_gt_pa_bayes:.5g}')\n",
    "print(f\"Chi2: 1-pval/2:   {pb_gt_pa_chi:.5g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a081f",
   "metadata": {},
   "source": [
    "Ниже $p$-значение $\\chi^2$-теста используется для проверки количества правильно угаданных вариантов с большей конверсией в серии экспериментов. В каждом эксперименте 2 группы, конверсия $p_A=0.1$ фиксирована, $p_B$ выбирается случайно в диапазоне $\\pm5\\%$ от $p_A$. В каждой группе добавляются данные по 10000 точек за шаг. На каждом шаге вычисляется $p$-значение $\\chi^2$-теста и $P(p_B > p_A | S_A, S_B) \\approx 1 - p/2$ при $p_B > p_A$ или $P(p_B > p_A | S_A, S_B) \\approx p/2$ при $p_A > p_B$. Эксперимент останавливается, если оценка вероятности конверсии одной группы больше другой превышает `prop_stop` или набрано максимальное количество точек `n_samp_max`. Всего в `nexps=1000` верно угадано 932 варианта. Доля 0.932 близка `prob_stop = 0.95`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a849f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_chi'])\n",
    "\n",
    "p = 0.1\n",
    "nexps = 1000\n",
    "cmp['A'] = [p] * nexps\n",
    "cmp['B'] = p * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 5_000_000\n",
    "n_samp_step = 10_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    pA = cmp.at[i, 'A']\n",
    "    pB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.bernoulli(p=pA)\n",
    "    exact_dist_B = stats.bernoulli(p=pB)\n",
    "    n_samp_total = 0\n",
    "    ns_A = 0\n",
    "    ns_B = 0\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA = exact_dist_A.rvs(n_samp_step)\n",
    "        dB = exact_dist_B.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        ns_A = ns_A + np.sum(dA)\n",
    "        ns_B = ns_B + np.sum(dB)\n",
    "        p_A_samp = ns_A / n_samp_total\n",
    "        p_B_samp = ns_B / n_samp_total\n",
    "        t = np.array([\n",
    "            [ns_A,     n_samp_total - ns_A],\n",
    "            [ns_B,     n_samp_total - ns_B]\n",
    "        ])\n",
    "        chi2_stat, p_value_chi, dof, expected = stats.chi2_contingency(t, correction=False)\n",
    "        pb_gt_pa_chi = 1 - p_value_chi / 2\n",
    "        pb_gt_pa_chi = pb_gt_pa_chi if p_B_samp > p_A_samp  else 1 - pb_gt_pa_chi\n",
    "        best_gr = 'B' if pb_gt_pa_chi >= prob_stop else 'A' if 1 - pb_gt_pa_chi >= prob_stop else None\n",
    "        if best_gr:\n",
    "            post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "            post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "            pb_gt_pa_bayes = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "            cmp.at[i, 'A_exp'] = p_A_samp\n",
    "            cmp.at[i, 'B_exp'] = p_B_samp\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p_best_chi'] = max(pb_gt_pa_chi, 1 - pb_gt_pa_chi)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P_best Bayes {max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes):.4f}, Chi (1-pval/2): {1 - p_value_chi/2:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "finished = np.sum(cmp['best_exp'].notna())\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Finished: {finished}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / finished}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f9f73",
   "metadata": {},
   "source": [
    "## U-критерий Манна-Уитни"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607868a8",
   "metadata": {},
   "source": [
    "Для выборок размера $N_A, N_B$ из двух случайных величин $A, B$ статистика Манна-Уитни [[MannWhitneyU](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)] определена через попарное сравнение элементов. Для непрерывных распределений вероятность совпадения элементов в выборках нулевая. В этом случае $U$-статистика определена как количество пар $(A_i, B_j)$, где элемент $A_i$ больше $B_j$: $U_A = \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(A_i > B_j)$, $I$ - индикаторная функция. Cтатистику также можно записать в виде $U_A = R_A - N_A (N_A + 1)/2$, где $R_A$ - сумма рангов элементов $А$ в объединенной выборке. Эквивалентность определений можно увидеть следующим образом: слагаемое $N_A (N_A + 1)/2$ соответствует минимальной сумме рангов если все элементы $A$ меньше $B$ и считается как сумма арифметической прогрессии. Если наибольший элемент $A$ больше $n$ элементов $B$, то $U_A = n$ и $R_A = N_A (N_A + 1)/2 + n$. При большом количестве точек отношение $U_A$ к общему количеству пар $U_A / N_A N_B$ стремится к вероятности случайной точки из распределения $A$ больше $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcceca1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "A, B & - \\text{непрерывные распределения}\n",
    "\\\\\n",
    "U_A & = \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(A_i > B_j),\n",
    "\\quad\n",
    "I(\\cdot) = 1 \\text{ если условие выполнено, иначе } 0 \n",
    "\\\\\n",
    "U_A & = R_A - N_A (N_A + 1)/2, \\quad R_A \\text{- сумма рангов элементов А в объединенной выборке}\n",
    "\\\\\n",
    "\\frac{U_A}{N_A N_B} & \\to P(A > B),\n",
    "\\quad\n",
    "N_A, N_B \\to \\infty\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6f75f",
   "metadata": {},
   "source": [
    "В предположении одинаковых распределений $A, B$ можно посчитать среднее $E[U]$ и дисперсию $\\text{Var}(U)$ $U$-статистики. Величина $(U - E[U])/\\sqrt{Var(U)}$ будет стремиться к нормальному распределению [нужна ссылка]. $p$-значение определено как вероятность получить более экстремальное значение $p = P_{Norm(0,1)}(x > u_0)$, $u_0 = (U - E[U])/\\sqrt{\\text{Var}(U)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c54ba2",
   "metadata": {},
   "source": [
    "$$\n",
    "A = B: \n",
    "\\quad\n",
    "E[U] = \\frac{N_A N_B}{2}, \\quad\n",
    "\\text{Var}(U) = \\frac{N_A N_B (N_A + N_B + 1)}{12}\n",
    "\\\\\n",
    "\\frac{U - E[U]}{\\sqrt{\\text{Var}(U)}} \\to \\text{Norm}(0,1), \\quad N_A, N_B \\to \\infty\n",
    "\\\\\n",
    "p = P_{\\text{Norm}(0,1)}(x > u_0), \n",
    "\\quad\n",
    "u_0 = \\frac{U_A - E[U]}{\\sqrt{\\text{Var}(U)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a827a",
   "metadata": {},
   "source": [
    "В байесовском подходе вероятность $P(B>A)$ можно оценить сравнением апостериорных предиктивных распределений. Нужно предположить модели исходных распределений, построить апостериорные распределения параметров и апостериорные предиктивные распределения. По построенным апостериорным предиктивным распределениям можно оценить $P(B>A)$. Это будет точечная оценка, а не распеделение. Такой подход требует предположения распределений.\n",
    "\n",
    "Другой вариант - моделировать вероятность $\\theta = P(B > A)$. Сравнение каждой пары $X_{ij} = I(B_i > A_j)$. Для правдоподобия можно выбрать биномиальное распределение $P(U | \\theta) = \\text{Binom}(U | \\theta, N_A N_B)$. При сравнении каждой точки $A$ с каждой точкой $B$ результаты в парах с одинаковыми $A_i$ или $B_j$ не будут независимы. Будет использоваться упрощенная модель, в которой каждая точка из $A$ сравнивается только с одной точкой $B$. Тогда пары будут независимы. Можно ожидать более широкой дисперсии, чем в $U$. Как в конверсиях априорное распределение удобно задать бета-распределением. Апостериорное также будет бета-распределением. \n",
    "\n",
    "$$\n",
    "\\theta = P(A > B)\n",
    "\\\\\n",
    "X_{ij} = I(A_i > B_j)\n",
    "\\\\\n",
    "U = \\sum X_{ij}\n",
    "\\\\\n",
    "P(X | \\theta) = \\text{Bernoulli}(\\theta)\n",
    "\\\\\n",
    "P(U | \\theta) = \\text{Binom}(U | \\theta, \\min(N_A, N_B))\n",
    "\\\\\n",
    "P(\\theta) = \\text{Beta}(\\alpha_0, \\beta_0)\n",
    "\\\\\n",
    "P(\\theta | U) = \\text{Beta}(U + \\alpha_0, \\min(N_A, N_B) - U + \\beta_0)\n",
    "\\approx \\text{Norm}(\\mu, s)\n",
    "\\\\\n",
    "\\begin{split}\n",
    "P(A > B) = P(\\theta  > 0.5 | U) & = P(\\text{Norm}(x > 0.5; \\mu, s))\n",
    "\\end{split}\n",
    "\\\\\n",
    "P(B > A) = 1 - P(\\theta  > 0.5 | U)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef141e",
   "metadata": {},
   "source": [
    "Для нормальных распределений вероятность точки из распределения $A$ больше $B$ можно посчитать аналитически [[NormalSum](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables)]\n",
    "\n",
    "$$\n",
    "A \\sim \\text{Norm}(\\mu_A, \\sigma_A^2),\n",
    "\\quad\n",
    "B \\sim \\text{Norm}(\\mu_B, \\sigma_B^2)\n",
    "\\\\\n",
    "B - A \\sim \\text{Norm}(\\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2)\n",
    "\\\\\n",
    "P(B > A) = P_{B - A}(x > 0) = 1 - F_{B-A}(0) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d74d305",
   "metadata": {},
   "source": [
    "На графике ниже два нормальных распределения. На втором графике - распределение $U$-статистики [[ScipyMannWhitneyU](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)] в предположении эквивалентности распределений и фактическое значение. Закрашенная область соответствует $p$-значению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1, sigma1 = 0, 1\n",
    "mu2, sigma2 = -0.1, 1\n",
    "exactA = stats.norm(loc=mu1, scale=sigma1)\n",
    "exactB = stats.norm(loc=mu2, scale=sigma2)\n",
    "\n",
    "p_b_gt_a_norm = 1 - stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "p_a_gt_b_norm = stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "\n",
    "#U\n",
    "nA = nB = 1500\n",
    "sampA = exactA.rvs(nA)\n",
    "sampB = exactB.rvs(nB)\n",
    "U, p = stats.mannwhitneyu(sampA, sampB, alternative='greater')\n",
    "eu = nA * nB / 2\n",
    "varu = nA * nB * (nA + nB + 1) / 12\n",
    "u0 = (U - eu) / np.sqrt(varu)\n",
    "p_b_gt_a_u = 1 - U / (nA*nB)\n",
    "\n",
    "# Ua = sum(np.sum(a > sampB) for a in sampA)\n",
    "# print(f'Ua:{Ua}, U:{U}')\n",
    "\n",
    "\n",
    "#P(a>b)\n",
    "p_u = stats.norm(loc=eu/(nA*nB), scale=np.sqrt(varu/(nA*nA*nB*nB)))\n",
    "u0_p = U / (nA*nB)\n",
    "print(f'p: {p}, cdf(u0): {stats.norm.cdf(u0)}, cdf(u0p): {p_u.cdf(u0_p)}')\n",
    "\n",
    "\n",
    "#elementwise\n",
    "a0 = 1\n",
    "b0 = 1\n",
    "Ua = np.sum(sampA > sampB)\n",
    "post_u_ewise = stats.beta(a0 + Ua, b0 + nA - Ua)\n",
    "\n",
    "\n",
    "x = np.linspace(-7, 7, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactA.pdf(x),\n",
    "    mode='lines', name='A', line_color='black'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactB.pdf(x),\n",
    "    mode='lines', name='B', line_color='blue', opacity=0.7))\n",
    "fig.update_layout(\n",
    "    title=\"A, B\",\n",
    "    template=\"plotly_white\",\n",
    "    #yaxis_range=[0,1.1]\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "xaxis_min = 0.4\n",
    "xaxis_max = 0.6\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=p_u.pdf(x), \n",
    "                         line_color='black', opacity=0.8, name=f'$U/N_A N_B$'))\n",
    "fig.add_trace(go.Scatter(x=[u0_p, u0_p], y=[0, max(p_u.pdf(x))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$u_0$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "# fig.add_trace(go.Scatter(x=[p_a_gt_b_norm, p_a_gt_b_norm], y=[0, max(p_u.pdf(x))*1.1], \n",
    "#                          line_color='black', \n",
    "#                          mode='lines+text', \n",
    "#                          text=['', '$P(A>B)$'], textposition=\"top center\",\n",
    "#                          line_dash='solid', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>u0_p], y=p_u.pdf(x[x>u0_p]), \n",
    "                         line_color='black', opacity=0.8, name='$P(x > u_0)$', \n",
    "                         fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_u_ewise.pdf(x),\n",
    "                         line_color='black', opacity=0.3, name=f'PostUElementwise'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0.5], y=post_u_ewise.pdf(x[x<0.5]), \n",
    "                         line_color='black', opacity=0.3, name='$P(x < 0.5)$', \n",
    "                         fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.3)\"))\n",
    "fig.update_layout(\n",
    "    title='P(B>A)',\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(f'pval: {stats.norm.cdf(u0)}')\n",
    "print(f'scipy pval: {p}')\n",
    "print(f'Bayes P(A>B) {1 - post_u_ewise.cdf(0.5)}')\n",
    "print()\n",
    "print(f'P(B>A) exact: {p_b_gt_a_norm}')\n",
    "print(f'P(B>A) U: {p_b_gt_a_u}')\n",
    "print(f'Bayes Mean P(B>A) {1 - post_u_ewise.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b4171",
   "metadata": {},
   "source": [
    "На графике показано точное значение, динамика p и P(A>B) по мере набора данных. Сравниваются не средние, а все распределение. Вероятность $U/N_A N_B$ может не доходить до 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1, sigma1 = 0, 1\n",
    "mu2, sigma2 = -0.05, 1\n",
    "exactA = stats.norm(loc=mu1, scale=sigma1)\n",
    "exactB = stats.norm(loc=mu2, scale=sigma2)\n",
    "\n",
    "p_b_gt_a_norm = 1 - stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "p_a_gt_b_norm = stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "\n",
    "nA = nB = 7000\n",
    "sampA = exactA.rvs(nA)\n",
    "sampB = exactB.rvs(nB)\n",
    "nCur = 0\n",
    "step = 100\n",
    "steps = []\n",
    "pvals = []\n",
    "pb_gt_pa_u = []\n",
    "pb_gt_pa_bayes = []\n",
    "pb_gt_pa_mean = []\n",
    "while nCur < nA:\n",
    "    nCur += step\n",
    "    steps.append(nCur)\n",
    "    U, pval = stats.mannwhitneyu(sampA[:nCur], sampB[:nCur], alternative='greater')\n",
    "    pb_gt_pa_u.append(1 - U / nCur / nCur)\n",
    "    pvals.append(pval)\n",
    "    a0 = 1\n",
    "    b0 = 1\n",
    "    Ub = np.sum(sampB[:nCur] > sampA[:nCur])\n",
    "    post_u_ewise = stats.beta(a0 + Ub, b0 + nCur - Ub)\n",
    "    pb_gt_pa_bayes.append(1 - post_u_ewise.cdf(0.5))\n",
    "    pb_gt_pa_mean.append(post_u_ewise.mean())\n",
    "    \n",
    "\n",
    "#x = np.linspace(, 7, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=steps, y=[p_b_gt_a_norm]*len(steps),\n",
    "    mode='lines', name='Exact', \n",
    "    line_dash='longdash', line_color='black'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=steps, y=pb_gt_pa_u,\n",
    "    mode='lines', name='U', line_color='black', opacity=0.7))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=steps, y=pb_gt_pa_mean,\n",
    "    mode='lines', name='Bayes E[P(B>A)]', line_color='blue', opacity=0.5))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=steps, y=pvals,\n",
    "    mode='lines', line_dash='dash', name='U pval', \n",
    "    line_color='black', opacity=0.7))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=steps, y=pb_gt_pa_bayes,\n",
    "    mode='lines', line_dash='dash', name='P(P(B>A) > 0.5)', \n",
    "    line_color='blue', opacity=0.5))\n",
    "fig.update_layout(\n",
    "    title=\"P(A>B)\",\n",
    "    template=\"plotly_white\",\n",
    "    yaxis_range=[0, 1]\n",
    ")\n",
    "fig.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bc75e",
   "metadata": {},
   "source": [
    "Количество правильно угаданных вариантов. Байесовская модель: нужно задавать априорные параметры для снижения ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9388cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_u'])\n",
    "\n",
    "mua = 0.1\n",
    "nexps = 100\n",
    "cmp['A'] = [mua] * nexps\n",
    "cmp['B'] = mua * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 5_000_000\n",
    "n_samp_step = 10000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    mua = cmp.at[i, 'A']\n",
    "    mub = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.norm(loc=mua)\n",
    "    exact_dist_B = stats.norm(loc=mub)\n",
    "    n_samp_total = 0\n",
    "    sampA = exact_dist_A.rvs(n_samp_max)\n",
    "    sampB = exact_dist_B.rvs(n_samp_max)\n",
    "    while n_samp_total < n_samp_max:\n",
    "        n_samp_total += n_samp_step\n",
    "        a0 = 100000\n",
    "        b0 = 100000\n",
    "        Ub = np.sum(sampB[:n_samp_total] > sampA[:n_samp_total])\n",
    "        post_u_ewise = stats.beta(a0 + Ub, b0 + n_samp_total - Ub)\n",
    "        pb_gt_pa_bayes = 1 - post_u_ewise.cdf(0.5)\n",
    "        best_gr = 'B' if pb_gt_pa_bayes >= prob_stop else 'A' if 1 - pb_gt_pa_bayes >= prob_stop else None\n",
    "        if best_gr:\n",
    "            U, pval = stats.mannwhitneyu(sampA[:n_samp_total], sampB[:n_samp_total], alternative='greater')\n",
    "            cmp.at[i, 'A_exp'] = sampA[:n_samp_total].mean()\n",
    "            cmp.at[i, 'B_exp'] = sampB[:n_samp_total].mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p_best_u'] = max(pval, 1 - pval)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P_best Bayes {pb_gt_pa_bayes:.4f}, U p-val: {pval:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "finished = np.sum(cmp['best_exp'].notna())\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Finished: {finished}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / finished}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca0a86",
   "metadata": {},
   "source": [
    "Для U-тестов выставлен больший шаг - добавляется по 500000 точек в каждой группе. Это также учитывает минимальное количество данных. Доля верно угаданных вариантов `0.96` несколько выше `prob_stop`. Превышение связано с большим шагом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_u'])\n",
    "\n",
    "mua = 0.1\n",
    "nexps = 100\n",
    "cmp['A'] = [mua] * nexps\n",
    "cmp['B'] = mua * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 5_000_000\n",
    "n_samp_step = 200_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    mua = cmp.at[i, 'A']\n",
    "    mub = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.norm(loc=mua)\n",
    "    exact_dist_B = stats.norm(loc=mub)\n",
    "    n_samp_total = 0\n",
    "    sampA = exact_dist_A.rvs(n_samp_max)\n",
    "    sampB = exact_dist_B.rvs(n_samp_max)\n",
    "    while n_samp_total < n_samp_max:\n",
    "        n_samp_total += n_samp_step\n",
    "        U, pval = stats.mannwhitneyu(sampA[:n_samp_total], sampB[:n_samp_total], alternative='greater')\n",
    "        pb_gt_pa_u = 1 - U / n_samp_total / n_samp_total\n",
    "        best_gr = 'B' if pval >= prob_stop else 'A' if 1 - pval >= prob_stop else None        \n",
    "        if best_gr:\n",
    "            a0 = 100000\n",
    "            b0 = 100000\n",
    "            Ub = np.sum(sampB[:n_samp_total] > sampA[:n_samp_total])\n",
    "            post_u_ewise = stats.beta(a0 + Ub, b0 + n_samp_total - Ub)\n",
    "            pb_gt_pa_bayes = 1 - post_u_ewise.cdf(0.5)\n",
    "            cmp.at[i, 'A_exp'] = sampA[:n_samp_total].mean()\n",
    "            cmp.at[i, 'B_exp'] = sampB[:n_samp_total].mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p_best_u'] = max(pval, 1 - pval)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P_best Bayes {pb_gt_pa_bayes:.4f}, U p-val: {pval:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "finished = np.sum(cmp['best_exp'].notna())\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Finished: {finished}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / finished}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be6378",
   "metadata": {},
   "source": [
    "Для $p$-значений $t$-теста, $\\chi^2$-теста и $U$-критерия Манна-Уитни показана связь с байесовскими вероятностями параметров одной группы больше другой. $P$-значения численно близки байесовским вероятностям несмотря на различия в определениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247790d6",
   "metadata": {},
   "source": [
    "## Ссылки\n",
    "\n",
    "[Chi2Dist] - [Chi-squared Distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution), *Wikipedia.*  \n",
    "[Chi2Pearson] - [Pearson’s Chi-squared Test](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test), *Wikipedia.*  \n",
    "[Chi2Test] - [Chi-squared Test](https://en.wikipedia.org/wiki/Chi-squared_test), *Wikipedia.*  \n",
    "[ConjPrior] - [Conjugate Prior](https://en.wikipedia.org/wiki/Conjugate_prior#When_likelihood_function_is_a_continuous_distribution), *Wikipedia.*   \n",
    "[MannWhitneyU] - [Mann–Whitney U Test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test), *Wikipedia.*  \n",
    "[NormalSum] - [Sum of Normally Distributed Random Variables](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables), *Wikipedia.*  \n",
    "[PVal] - [P-value](https://en.wikipedia.org/wiki/P-value), *Wikipedia.*  \n",
    "[ScipyChi2Con] - [scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html), *SciPy Reference.*  \n",
    "[ScipyMannWhitneyU] - [scipy.stats.mannwhitneyu](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html), *SciPy Reference.*  \n",
    "[ScipyTTestInd] - [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html), *SciPy Reference.*  \n",
    "[TailedTests] - [One- and Two-tailed Tests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests), *Wikipedia.*  \n",
    "[TDist] - [Student’s t-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution), *Wikipedia.*  \n",
    "[TestStat] - [Test Statistic](https://en.wikipedia.org/wiki/Test_statistic), *Wikipedia.*  \n",
    "[TTest] - [Student’s t-test](https://en.wikipedia.org/wiki/Student%27s_t-test), *Wikipedia.*  \n",
    "[WelchT] - [Welch’s t-test](https://en.wikipedia.org/wiki/Welch%27s_t-test), *Wikipedia.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
