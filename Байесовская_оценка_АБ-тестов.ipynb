{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b087aaa2",
   "metadata": {},
   "source": [
    "# Байесовская оценка А/Б-тестов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c84793b",
   "metadata": {},
   "source": [
    "*Описана механика А/Б-тестов. Рассмотрены примеры байесовского моделирования. Байесовская оценка применена к сравнению конверсий, средних, транзакционной выручки на пользователя, заказов на посетителя.*\n",
    "\n",
    "&nbsp; &nbsp; *- [А/Б тесты](#А/Б-тесты)*  \n",
    "&nbsp; &nbsp; *- [Байесовское моделирование](#Байесовское-моделирование)*  \n",
    "&nbsp; &nbsp; *- [Конверсии](#Конверсии)*   \n",
    "&nbsp; &nbsp; *- [Средние](#Средние)*    \n",
    "&nbsp; &nbsp; *- [Транзакционная выручка на пользователя](#Транзакционная-выручка-на-пользователя)*  \n",
    "&nbsp; &nbsp; *- [Заказы на посетителя](#Заказы-на-посетителя)*  \n",
    "&nbsp; &nbsp; *- [Заключение](#Заключение)*  \n",
    "&nbsp; &nbsp; *- [Ссылки](#Ссылки)*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e4c34",
   "metadata": {},
   "source": [
    "# А/Б тесты  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b0098",
   "metadata": {},
   "source": [
    "В мобильные приложения и веб-сервисы вносят изменения для роста выручки, конверсий, вовлеченности и других ключевых метрик. Точный эффект непредсказуем - изменения могут ухудшить продукт. По оценкам только треть релизов приводит к положительным результатам [[MicroExp](https://www.microsoft.com/en-us/research/publication/online-experimentation-at-microsoft/)]. Поэтому необходимо измерять эффект новой функциональности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d8e59",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/experiment_versions_ru.png\" alt=\"experiment_versions\" width=\"400\"/>\n",
    "    \n",
    "<em>Повышение стоимости (справа) приведет к росту среднего чека, но падению конверсии. Изменение общей выручки непредсказуемо и требует измерения. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98fdba",
   "metadata": {},
   "source": [
    "Сравнение метрик до и после релиза не всегда позволяет оценить изменение. При \"сильном\" эффекте будет виден скачок в метрике, но \"слабый\" эффект может быть незаметен на фоне колебаний. На метрики также влияют изменения в других частях продукта, привлекаемом трафике или общей активности аудитории - например, запуск рекламной акции. Поэтому изменения метрик после релиза не всегда можно объяснять новой функциональностью. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a5468b",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/effect_size.png\" alt=\"effect_size\"  width=\"900\"/>\n",
    "<em>При оценке эффекта сильные изменения заметны в динамике метрики (см. падение на 30%), но слабые изменения могут быть незаметны на фоне колебаний (см. рост на 3%). Кроме того, изменение метрик после релиза не всегда связано с новой функциональностью. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b24bb",
   "metadata": {},
   "source": [
    "Для более точной оценки эффекта используют А/Б-тесты. В этом подходе версию без изменений и измененный вариант сервиса запускают параллельно. При попадании на сайт или в приложение пользователь случайным образом определяется в один из вариантов. В каждой группе собирают данные, вычисляют и сравнивают интересующие метрики. Эксперимент останавливают, если одна из групп лидирует или продолжать тест неоправдано. В итоге принимается решение о дальнейших действиях - как правило, о выборе одного из вариантов для всех пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b583dcb1",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/ab_test.png\" alt=\"ab_test\" width=\"800\"/>\n",
    "    \n",
    "<em>Схема А/Б эксперимента: тестируемые версии сервиса запускают параллельно, пользователи случайным образом попадают в один из вариантов. В каждой группе вычисляют интересующие метрики, по результатам сравнения определяют дальнейшие действия. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a9520",
   "metadata": {},
   "source": [
    "Причинная диаграмма [[CausalDAG](https://en.wikipedia.org/wiki/Causal_graph)] А/Б-тестов следующая. Метрики определяются действиями пользователей в сервисе. Действия зависят от версии сайта или приложения (например, доступных тарифных планов), внешних факторов (например, сезонности) и также отличаются между сегментами пользователей (новые, постоянные клиенты и др.). В А/Б-тесте версии запускают одновременно и пользователей случайно делят между вариантами. Внешние факторы сохраняются, но при сравнении за одинаковый период их влияние на группы одинаково. При случайном делении пользователей состав сегментов можно считать одинаковым. В итоге разница метрик между группами объясняется функциональностью приложения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89384924",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/causal.png\" alt=\"causal\" width=\"600\"/>\n",
    "    \n",
    "<em>Метрики определяются поведением и действиями пользователей в сервисе. Поведение зависит от текущей версии сервиса, внешних факторов и сегмента пользователей. Одновременный запуск вариантов А/Б-теста позволяет говорить об одинаковом влиянии внешних факторов на метрики, а случайное деление пользователей между вариантами - об одинаковом влиянии сегментов. В итоге разницу метрик между группами можно объяснять тестируемой функциональностью. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485de2fb",
   "metadata": {},
   "source": [
    "По итогам эксперимента нужно оценить метрики, эффект и выбрать \"лучшую\" группу. Точные значения метрик неизвестны. По собранным данным нужно построить их оценки. Оценки метрик удобнее рассматривать как случайные величины. Распределения вероятностей этих величин нужно подобрать для наибольшей совместимости с экспериментальными данными. Сравнение распределений позволяет оценить эффект. Для презентации удобна точечная оценка метрик и интервал наибольшей плотности вероятности. Например, среднее значение метрики в группе А $p_A = 7.1 \\pm 0.2$, в группе Б $p_B = 7.4 \\pm 0.3$. Эффект можно охарактеризовать относительной разностью $(p_B - p_A) / p_A = 4.2 \\pm 0.2 \\%$. Для выбора \"лучшей\" группы оценить с какой вероятностью метрика в группе Б больше метрики в группе А, например, $P(p_B > p_A) = 95\\%$. Вероятность здесь и далее понимается в субъективном смысле - как мера уверенности в определенном исходе процесса с несколькими возможными исходами [[SubjProb](https://en.wikipedia.org/wiki/Probability_interpretations#Subjectivism)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702718f8",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/ab_metric_random.png\" alt=\"ab_metric_random\" width=\"500\"/>\n",
    "<br/>   \n",
    "<em>\n",
    "В А/Б тесте нужно оценить метрики, эффект и выбрать \"лучшую\" группу. Точные значения метрик неизвестны. По собранным данным нужно построить оценки метрик. Оценки удобнее рассматривать как случайные величины. Их распределения вероятностей нужно подобрать для наибольшей совместимости с экспериментальными данными. Сравнение распределений позволяет оценить эффект.\n",
    "</em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bec192",
   "metadata": {},
   "source": [
    "Пока данных мало, неопределенность в оценках метрик большая. По мере набора данных оценки уточняются. Вместе с этим растет уверенность, какая из групп лучше. Когда уверенность достигает достаточного значения, эксперимент можно останавливать. Возможны другие критерии остановки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef663589",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/ab_dynamics.png\" alt=\"ab_dynamics\" width=\"430\"/>\n",
    "<br/>\n",
    "<em>\n",
    "По мере набора данных увеличивается точность оценки метрик и растет уверенность, какая из групп лучше. Эксперимент можно останавливать при достижении достаточного значения уверенности.\n",
    "</em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aaa4cd",
   "metadata": {},
   "source": [
    "Для оценки распределений метрик на основе экспериментальных данных используется байесовское моделирование [[SR](https://www.routledge.com/Statistical-Rethinking-A-Bayesian-Course-with-Examples-in-R-and-STAN/McElreath/p/book/9780367139919), [SGBS](https://www.amazon.co.uk/Students-Guide-Bayesian-Statistics/dp/1473916364)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd317e22",
   "metadata": {},
   "source": [
    "# Байесовское моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24a767",
   "metadata": {},
   "source": [
    "Первый пример: если утром облачно, будет ли днем дождь? Для ответа можно посчитать отношение кол-ва облачных дней с дождем к общему кол-ву облачных дней $P(\\mbox{Дождь | Облачно}) = (\\mbox{Облачно, дождь})/(\\mbox{Облачно})$. Общее количество облачных дней складывается из облачных дней с дождем и облачных дней без дождя $(\\mbox{Облачно}) = \\mbox{(Облачно, дождь) + (Облачно, без дождя)}$. Пусть дождливых дней в году $P(\\mbox{Дождь}) = 20\\%$, вероятность утренней облачности в дождливый день $P(\\mbox{Облачно | Дождь}) = 70\\%$, в день без дождя $P(\\mbox{Облачно | Без дождя}) = 10\\%$. Количество облачных дней с дождем можно выразить через соответствующие вероятности $\\mbox{(Облачно, дождь)} = (\\mbox{Всего дней}) P(\\mbox{Дождь}) P(\\mbox{Облачно | Дождь})$, аналогично для количества дней без дождя. После подстановки $P(\\mbox{Дождь | Облачно}) = (0.7 \\cdot 0.2)/(0.7 \\cdot 0.2 + 0.1 \\cdot 0.8) = 63.6 \\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f775492",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/bayes_rain.png\" alt=\"bayes_rain\" width=\"600\"/>\n",
    "<br/>\n",
    "<em>\n",
    "Вероятность дождливого дня при облачном утре оценивается отношением кол-ва дождливых облачных дней ко всем облачным дням - с дождем и без дождя.\n",
    "</em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc131d1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "P(\\mbox{Дождь | Облачно}) & = \\frac{\\mbox{Облачно, дождь}}{\\mbox{Облачно, дождь + Облачно, без дождя}} \n",
    "\\\\\n",
    "\\\\\n",
    "& = \\frac{P(\\mbox{Облачно | дождь})P(\\mbox{Дождь})}{P(\\mbox{Облачно | Дождь})P(\\mbox{Дождь}) + P(\\mbox{Облачно | Без дождя})P(\\mbox{Без дождя})}\n",
    "\\\\\n",
    "\\\\\n",
    "& = \\frac{0.7 \\cdot 0.2}{0.7 \\cdot 0.2 + 0.1 \\cdot 0.8} = 63.6 \\%\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e7180",
   "metadata": {},
   "source": [
    "В оценке вероятности дождя при облачности $P(\\mbox{Дождь | Облачно})$ кроме вероятности утренних облаков в дождливый день $P(\\mbox{Облачно | Дождь})$ важно учитывать долю дождливых дней $P(\\mbox{Дождь})$ и вероятность облачности в день без дождя $P(\\mbox{Облачно | Без дождя})$. Их игнорирование ведет к ошибке базового процента [[BaseFal](https://en.wikipedia.org/wiki/Base_rate_fallacy)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1e67b",
   "metadata": {},
   "source": [
    "Еще один пример. Вечером в парке вы видите непонятный предмет. Издалека видны только очертания. Вы пытаетесь угадать, что это. Формально можно использовать соотношение Байеса. Нужно предположить возможные варианты - листья, упавшая шапка, птица, лужа. Для каждого варианта оценить вероятность наблюдаемых очертаний $P(\\mbox{Очертания | Листья})$, $P(\\mbox{Очертания | Шапка})$ и т.д. Также учесть распространенность вариантов - листья встречаются чаще потярянной шапки $P(\\mbox{Листья}) > P(\\mbox{Шапка})$. С помощью соотношения Байеса определить вероятность каждого из вариантов $P(\\mbox{Листья | Очертания}) \\propto P(\\mbox{Очертания | Листья})P(\\mbox{Листья})$ и выбрать наиболее подходящий. Когда вы подходите ближе, предмет недовольно оглядывается и быстро залезает на дерево - это оказалась белка, вы давно не видели их в парке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56031c7",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/bayes_park.png\" alt=\"park\" width=\"600\"/>\n",
    "<em>\n",
    "<br/>\n",
    "Для выбора одного из вариантов с помощью соотношения Байеса нужно учесть распространненость вариантов (ширина вертикальных полос) и оценить вероятность каждого варианта дать наблюдаемые очертания (высота закрашенных областей). Вероятность каждого из вариантов будет отношением закрашенной площади внутри вертикальной полосы к площади всех закрашенных областей.\n",
    "</em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e29a9",
   "metadata": {},
   "source": [
    "На этом примере видны основные элементы байесовского моделирования. Есть данные/наблюдения/факты $\\mathcal{D}$ и объяснения/гипотезы/модели/предположения $\\mathcal{H}_i$. Для выбора одной гипотезы нужно оценить, насколько каждая из гипотез согласуется с данными. Для этого вычисляют вероятности получить данные в рамках каждой модели - функции правдоподобия $P(\\mathcal{D}|\\mathcal{H}_i)$. Прошлый опыт учитывают уверенностью в модели - априорных вероятностях $P(\\mathcal{H}_i)$. По соотношению Байеса вычисляют обновленную уверенность с учетом данных - апостериорные вероятности $P(\\mathcal{H}_i|\\mathcal{D})$. На их основе выбирают наиболее подходящую модель. Модели необходимо валидировать - хотя для объяснения данных удается выбрать лучшую из предложенных гипотез, ни одна из гипотез может не соответствовать реальности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa07aa",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "P(\\mathcal{H}_i | \\mathcal{D}) &= \\frac{ P(\\mathcal{D} | \\mathcal{H}_i) P(\\mathcal{H}_i) }{P(\\mathcal{D})}\n",
    "= \\frac{ P(\\mathcal{D} | \\mathcal{H}_i) P(\\mathcal{H}_i) }{\\sum \\limits_i P(\\mathcal{D} | \\mathcal{H}_i) P(\\mathcal{H}_i) }\n",
    "\\\\\n",
    "P(\\mathcal{H}_i | \\mathcal{D}) &\\mbox{ - апостериорное распределение вероятности} \n",
    "\\\\\n",
    "P(\\mathcal{D} | \\mathcal{H}_i) &\\mbox{ - функция правдоподобия}\n",
    "\\\\\n",
    "P(\\mathcal{H}_i) &\\mbox{ - априорное распределение вероятности}\n",
    "\\\\\n",
    "P(\\mathcal{D}) &\\mbox{ - нормировочный коэффициент}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567cefea",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/bayes_hypotheses_square.png\" alt=\"bayes_hypotheses_square\" width=\"900\"/>\n",
    "<em>\n",
    "<br/>\n",
    "Выбирается набор моделей для объяснения данных. Для каждой модели задается уверенность в этой модели относительно остальных - априорная вероятность, вычисляется вероятность получить данные в рамках выбранной модели - функция правдоподобия. По соотношению Байеса вычисляется обновленная уверенность в модели с учетом данных - апостериорная вероятность.\n",
    "</em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68672877",
   "metadata": {},
   "source": [
    "Следующий пример. На страницу сайта зашло $N = 1000$ человек, $n_s = 100$ из них нажали кнопку \"Продолжить\". Как выглядит распределение возможных значений конверсии $p$? Вероятность конверсии каждого пользователя можно считать одинаковой, все возможные априорные значения равновероятными. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d286c",
   "metadata": {},
   "source": [
    "Необходимо для заданных $n_s$ и $N$ оценить вероятность $P(\\mathcal{H} | \\mathcal{D}) = P(p | n_s, N)$. По соотношению Байеса $P(p | n_s, N) \\propto P(n_s, N | p) P(p)$. Пользователь делает клик с вероятностью $p$ и не делает с вероятностью $1-p$. Клики $N$ пользователей можно моделировать последовательностью случайных величин с 2 исходами - схемой Бернулли [[BernProc](https://en.wikipedia.org/wiki/Bernoulli_process), [SciPyBern](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bernoulli.html)]. Вероятность $n_s$ конверсий из $N$ при шансе на успех $p$ задается биномиальным распределением $P(\\mathcal{D} | \\mathcal{H}) = P(n_s, N | p) = \\mbox{Binom}(n_s, N; p)$ [[BinomDist](https://en.wikipedia.org/wiki/Binomial_distribution), [SciPyBinom](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html)]. Т.к. все возможные априорные значения конверсий равновероятны, априорное распределение равномерно $P(\\mathcal{H}) = P(p) = \\mbox{Unif}(0, 1) = 1$. Апостериорное распределение $P(p | n_s, N)$ будет бета-распределением [[BetaDist](https://en.wikipedia.org/wiki/Beta_distribution), [SciPyBeta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html)]. \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(\\mathcal{D} | \\mathcal{H}) = P(n_s, N | p) & = \\mbox{Binom}(n_s, N; p) = C^{n_s}_{N} p^{n_s} (1 - p)^{N-n_s}\n",
    "\\\\\n",
    "\\\\\n",
    "P(\\mathcal{H}) = P(p) & = \\mbox{Unif}(0, 1) = 1\n",
    "\\\\\n",
    "\\\\\n",
    "P(\\mathcal{H} | \\mathcal{D}) = P(p | n_s, N) \n",
    "& = \\frac{P(n_s, N | p) P(p)}{P(n_s, N)}\n",
    "= \\frac{P(n_s, N | p) P(p)}{\\int_0^1 d p P(n_s, N | p) P(p)}\n",
    "\\\\\n",
    "& = \\frac{p^{n_s} (1 - p)^{N-n_s}}{\\int_0^1 d p (1 - p)^{N-n_s} p^{n_s} }\n",
    "= \\mbox{Beta}(p; n_s + 1, N - n_s + 1)\n",
    "\\\\\n",
    "\\\\\n",
    "\\mbox{Beta}(x; \\alpha, \\beta) & \\equiv \\frac{x^{\\alpha-1} (1 - x)^{\\beta-1}}{\\int_0^1 dx x^{\\alpha-1} (1 - x)^{\\beta-1}}\n",
    " = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1 - x)^{\\beta-1}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136734e",
   "metadata": {},
   "source": [
    "График апостериорного распределения $P(p | n_s, N)$ ниже. Мода совпадает со средним в выборке $n_s/N$, наиболее вероятные значения $p$ лежат вблизи этого значения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d072080",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 100\n",
    "ntotal = 1000\n",
    "\n",
    "p_samp = ns / ntotal\n",
    "p_dist = stats.beta(a=ns+1, b=ntotal-ns+1)\n",
    "\n",
    "xaxis_max = 0.2\n",
    "x = np.linspace(0, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=p_dist.pdf(x), line_color='black', name='Распределение'))\n",
    "fig.add_trace(go.Scatter(x=[p_samp, p_samp], y=[0, max(p_dist.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "fig.update_layout(title='$\\mbox{Апостериорное распределение} \\, P(p | n_s, N)$',\n",
    "                  xaxis_title='$p$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[0, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch2_conv_example.png\", scale=2)\n",
    "#Плотность вероятности конверсий задается бета-распределением. Мода совпадает со средним в выборке. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2edc81",
   "metadata": {},
   "source": [
    "Еще один пример. На версию А страницы веб-сайта зашло $N_A = 1000$ человек, $n_{s_A} = 100$ нажали кнопку \"Продолжить\". На версию Б зашло $N_B = 1000$ человек, $n_{s_B} = 110$ нажали кнопку продолжить. С какой вероятностью конверсия страницы Б выше страницы А?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de5109d",
   "metadata": {},
   "source": [
    "Нужна вероятность $P(p_B > p_A)$. Апостериорное распределение конверсий каждой группы вычисляется как в предыдущем примере $P(p; n_s, N) = \\mbox{Beta}(p; n_s + 1, N - n_s + 1)$. Для оценки вероятности $P(p_B > p_A)$ можно построить распределение $p_B - p_A$ и посчитать вероятность $P(p_B - p_A > 0)$. Распределение $p_B - p_A$ в общем виде записывается сверткой [[ProbConv](https://en.wikipedia.org/wiki/Convolution_of_probability_distributions)], в текущем примере можно использовать приближение. При заданных параметрах апостериорные бета-распределения близки [[BetaDist](https://en.wikipedia.org/wiki/Beta_distribution#Special_and_limiting_cases)] нормальным распределениям [[NormDist](https://en.wikipedia.org/wiki/Normal_distribution), [SciPyNorm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html?highlight=norm)]. Разность случайных величин с нормальными распределениями также случайная величина с нормальным распределением [[NormSum](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables)]. Поэтому распределение $p_B - p_A$ приближенно нормальное со средним равным разности средних апостериорных бета-распределений и дисперсией равной сумме дисперсий. Нужная вероятность выражается через функцию распределения $P(p_B - p_A > 0) = 1 - F(0)$ [[CDF](https://en.wikipedia.org/wiki/Cumulative_distribution_function)]. Вместо аналитических преобразований можно сделать численную оценку. Для этого генерируют выборки из апострериорных распределений и сравнивают их между собой. На первом графике приведены апостериорные распределения в группах. На втором - приближенное аналитическое распределение $p_B - p_A$ и распределение разности выборок апостериорных распределений. Оба расчета дают близкий результат $P(p_B > p_A) = 77 \\%$.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(p_B > p_A) & = P(p_B - p_A > 0)\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_A}(x) = \\mbox{Beta}(x; n_{s_A} + 1, N_A - n_{s_A} + 1)\n",
    "& \\approx \\mbox{Norm}(x; \\mu_A, \\sigma_A^2),\n",
    "\\quad\n",
    "\\mu_A = n_{s_A}/N_A, \n",
    "\\,\n",
    "\\sigma_A^2 = \\mu_A (1 - \\mu_A) / N_A,\n",
    "\\quad\n",
    "N_A \\gg n_{s_A} \\gg 1\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B}(x) = \\mbox{Beta}(x; n_{s_B} + 1, N_B - n_{s_B} + 1)\n",
    "& \\approx \\mbox{Norm}(x; \\mu_B, \\sigma_B^2),\n",
    "\\quad\n",
    "\\mu_B = n_{s_B}/N_B, \n",
    "\\,\n",
    "\\sigma_B^2 = \\mu_B (1 - \\mu_B) / N_B,\n",
    "\\quad\n",
    "N_B \\gg n_{s_B} \\gg 1\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B - p_A}(x) = \n",
    "\\int_{-\\infty}^{\\infty} dy P_{p_B}(y) P_{p_A}(y-x)\n",
    "& \\approx \\mbox{Norm}\\left(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2\\right),\n",
    "\\quad\n",
    "\\mbox{Norm}(x ; \\mu, \\sigma^2) \\equiv \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\tfrac{(x-\\mu)^2}{2 \\sigma^2} }\n",
    "\\\\\n",
    "\\\\\n",
    "P(p_B - p_A > 0) & = 1 - F_{p_B - p_A}(0)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762b9a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "na = 1000\n",
    "sa = 100\n",
    "nb = 1000\n",
    "sb = 110\n",
    "\n",
    "p_dist_a = stats.beta(a=sa+1, b=na-sa+1)\n",
    "p_dist_b = stats.beta(a=sb+1, b=nb-sb+1)\n",
    "\n",
    "approx_diff_dist = stats.norm(loc=p_dist_b.mean() - p_dist_a.mean(), \n",
    "                              scale=np.sqrt(p_dist_b.std()**2 + p_dist_a.std()**2))\n",
    "dist_p_b_gt_a = 1 - approx_diff_dist.cdf(0)\n",
    "\n",
    "npost = 50000\n",
    "samp_a = p_dist_a.rvs(size=npost)\n",
    "samp_b = p_dist_b.rvs(size=npost)\n",
    "samp_p_b_gt_a = np.sum(samp_b > samp_a) / npost\n",
    "\n",
    "\n",
    "xaxis_max = 0.2\n",
    "x = np.linspace(0, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=p_dist_a.pdf(x), line_color='black', name='А'))\n",
    "fig.add_trace(go.Scatter(x=x, y=p_dist_b.pdf(x), line_color='black', opacity=0.3, name='Б'))\n",
    "fig.update_layout(title='Апостериорные распределения',\n",
    "                  xaxis_title='$p$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[0, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch2_conv_cmp_example.png\", scale=2)\n",
    "#Апостериорные распределения конверсий в обеих группах задаются бета-распределениями.\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "                         line_color='black', name='$\\mbox{Аналитическое приближение}$'))\n",
    "fig.add_trace(go.Histogram(x=samp_b - samp_a, histnorm='probability density', \n",
    "                           name='$\\mbox{Разность апостериорных выборок}$', nbinsx=500,\n",
    "                           marker_color='black', opacity=0.3))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch2_conv_cmp_diff.png\", scale=2)\n",
    "#Конверсия группы Б выше А с вероятностью 77%.\n",
    "\n",
    "print(f\"P(p_b > p_a) diff dist: {dist_p_b_gt_a}\")\n",
    "print(f\"P(p_b > p_a) post samples: {samp_p_b_gt_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20d872",
   "metadata": {},
   "source": [
    "# Конверсии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e7da1",
   "metadata": {},
   "source": [
    "В А/Б-тестах часто сравнивают конверсии в заказ, клик по кнопке и другие действия. Если пользователь не влияет на других, для моделирования можно использовать процесс Бернулли. При конверсии $p$ вероятность, что $n_s$ человек из $N$ совершит целевое действие, задается биномиальным распределением $P(n_s, N | p) = \\mbox{Binom}(n_s, N | p)$. Априорное распределение конверсий удобно задать бета-распределением $P(p) = \\mbox{Beta}(p; \\alpha, \\beta)$. Зависимость бета-распределения от $p$ без учета нормировочных коэффициентов $\\mbox{Beta}(p; \\alpha, \\beta) \\propto p^{\\alpha-1}(1-p)^{\\beta-1}$. Эта же форма сохранится для произведения правдоподобия на априорное распределение $P(p | n_s, N) \\propto \\mbox{Binom}(p, N) \\mbox{Beta}(p; \\alpha, \\beta) \\propto p^{n_s + \\alpha - 1} (1-p)^{N - n_s + \\beta - 1}$. Важна только зависимость от $p$, остальные множители войдут в нормировочный коэффициент. Таким образом апостериорное распределение также будет бета-распределением, но с другими параметрами $P(p | n_s, N) = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)$. Априорные распределения с подобным свойством называют сопряженными априорными распределениями [[ConjPrior](https://en.wikipedia.org/wiki/Conjugate_prior)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61b53d",
   "metadata": {},
   "source": [
    "$$\n",
    "P(\\mathcal{H} | \\mathcal{D}) \\propto P(\\mathcal{D} | \\mathcal{H}) P(\\mathcal{H})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{D} | \\mathcal{H}) = P(n_s, N | p) = \\mbox{Binom}(n_s, N | p) = C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H}) = P(p) = \\mbox{Beta}(p; \\alpha, \\beta) = \n",
    "\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} p^{\\alpha-1}(1-p)^{\\beta-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(\\mathcal{H} | \\mathcal{D}) & = P(p | n_s, N) \n",
    "\\\\\n",
    "& \\propto \\mbox{Binom}(n_s, N | p) \\mbox{Beta}(p; \\alpha, \\beta)\n",
    "\\\\\n",
    "& \\propto C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} p^{\\alpha-1}(1-p)^{\\beta-1}\n",
    "\\\\\n",
    "& \\propto p^{n_s + \\alpha - 1} (1-p)^{N - n_s + \\beta - 1}\n",
    "\\\\\n",
    "& = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4060da4a",
   "metadata": {},
   "source": [
    "Бета-распределения для различных параметров приведены на графике ниже [[BetaDist](https://en.wikipedia.org/wiki/Beta_distribution), [SciPyBeta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html)]. При $\\alpha = 1, \\beta=1$ распределение однородное - эти значения удобно выбрать как априорные. Для остальных случаев максимум распределения в точке $p = (\\alpha-1) / (\\alpha + \\beta - 2)$. При увеличении $\\alpha$ и $\\beta$ распределение сужается и приближается к нормальному. Вместо $\\alpha = 1, \\beta=1$ начальные значения параметров $\\alpha, \\beta$ можно подобрать по историческим данным, чтобы априорное распределение конверсий совпадало с историческим значением. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "a, b = 1, 1\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='dash',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 1, 5\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 3, 5\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 25, 30\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 150, 50\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}')) \n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0.93, 0.08, 0.30, 0.53, 0.84],\n",
    "    y=[1.35, 5.00, 2.80, 6.20, 12.0],\n",
    "    mode=\"text\",\n",
    "    name=None,\n",
    "    showlegend=False,\n",
    "    text=[\"a=1, b=1\", \"a=1, b=5\", \"a=3, b=5\", \"a=25, b=30\", \"a=150, b=50\"],\n",
    "    textposition=\"middle center\"\n",
    "))\n",
    "fig.update_layout(title='Бета-распределение Beta(a, b)',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  showlegend=False,\n",
    "                  xaxis_range=[0, 1],\n",
    "                  height=550)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch3_beta.png\", scale=2)\n",
    "#Бета-распределение при различных параметрах. При a=1, b=1 бета-распределение переходит в однородное, при больших a,b приближается к нормальному."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7918681",
   "metadata": {},
   "source": [
    "Для проверки расчета конверсии по данным задается точное значение конверсии `p`, генерируется `nsample` бинарных случайных величин. По выборке строится апостериорное распределение возможных значений конверсий `post_dist`. На графике мода апостериорного распределения совпадает со средним в выборке и близка точному значению `p`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e25350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "    \n",
    "p = 0.1\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist = stats.bernoulli(p=p)\n",
    "data = exact_dist.rvs(nsample)\n",
    "post_dist = posterior_dist_binom(ns=np.sum(data), ntotal=len(data))\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist.pdf(x), line_color='black', name='Апостериорное'))\n",
    "fig.add_trace(go.Scatter(x=[data.mean(), data.mean()], y=[0, max(post_dist.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist.mean(), exact_dist.mean()], y=[0, max(post_dist.pdf(x))*1.05], \n",
    "                         line_color='red', mode='lines', line_dash='dash', name='Точное p'))\n",
    "fig.update_layout(title='Апостериорное распределение',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[p-0.1, p+0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch3_postdist.png\", scale=2)\n",
    "#Мода апостериорного распределения конверсии близка точному значению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e3d75",
   "metadata": {},
   "source": [
    "Для примера сравнения двух групп задается конверсия $p_A$, конверсия $p_B$ выбирается на 5% больше. Для каждой группы генерируется `nsample` точек, по ним строятся апостериорные распределения конверсий. Сэмплированием из распределений оценивается вероятность конверсии группы Б больше группы А $P(p_B > p_A)$. На графике $P(p_B > p_A) = 84.0 \\%$. Т.к. количество точек `nsample` относительно небольшое, значения могут поменяться при повторном запуске."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "p_A = 0.1\n",
    "p_B = p_A * 1.05\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist_A = stats.bernoulli(p=p_A)\n",
    "exact_dist_B = stats.bernoulli(p=p_B)\n",
    "data_A = exact_dist_A.rvs(nsample)\n",
    "data_B = exact_dist_B.rvs(nsample)\n",
    "\n",
    "post_dist_A = posterior_dist_binom(ns=np.sum(data_A), ntotal=len(data_A))\n",
    "post_dist_B = posterior_dist_binom(ns=np.sum(data_B), ntotal=len(data_B))\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist_A.pdf(x), line_color='black', name='A'))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist_B.pdf(x), line_color='black', opacity=0.2, name='Б'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_A.mean(), exact_dist_A.mean()], y=[0, max(post_dist_A.pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', name='Точное A'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_B.mean(), exact_dist_B.mean()], y=[0, max(post_dist_A.pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', opacity=0.2, name='Точное Б'))\n",
    "fig.update_layout(title='Апостериорные распределения',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[p_A/2, p_A*2],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch3_groups_cmp.png\", scale=2)\n",
    "#Апостериорные распределения конверсии в группах. Конверсия группы Б выше А с вероятностью 84%.\n",
    "\n",
    "print(f'P(pB > pA): {prob_pb_gt_pa(post_dist_A, post_dist_B)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a5abff",
   "metadata": {},
   "source": [
    "Динамика оценок конверсий и $P(p_B > p_A)$ по мере набора данных иллюстрируется следующим примером. Сравнивается две группы, задается конверсия $p_A$, конверсия второй группы $p_B$ выбирается на 5% больше. В каждой группе генерируется `npoints` точек `nstep` раз (всего `N = npoints * nstep` точек). По накопленным данным на каждом шаге строятся апостериорные распределения и считается вероятность $P(p_B > p_A)$. Также в обеих группах строятся и отображаются на графике центральные области апостериорных распределений, в которых лежит 95% распределения. По мере набора данных интервалы сужаются, вероятность стремится к 1 в пользу лучшей группы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca6765",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def posterior_binom_approx_95pdi(post_dist):\n",
    "    lower = post_dist.ppf(0.025)\n",
    "    upper = post_dist.ppf(0.975)\n",
    "    return lower, upper\n",
    "\n",
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = 1000\n",
    "nstep = 150\n",
    "sa = stats.binom.rvs(p=pa, n=npoints, size=nstep)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints, size=nstep)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['npoints'] = [npoints] * nstep\n",
    "df['sa_step'] = sa\n",
    "df['sb_step'] = sb\n",
    "df['N'] = df['npoints'].cumsum()\n",
    "df['sa'] = df['sa_step'].cumsum()\n",
    "df['sb'] = df['sb_step'].cumsum()\n",
    "df['pa'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).mean(), axis=1)\n",
    "df[['pa_lower', 'pa_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sa'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb'] = df.apply(lambda r: posterior_dist_binom(r['sb'], r['N']).mean(), axis=1)\n",
    "df[['pb_lower', 'pb_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sb'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb_gt_pa'] = df.apply(lambda r: prob_pb_gt_pa(posterior_dist_binom(r['sa'], r['N']), posterior_dist_binom(r['sb'], r['N']), post_samp=10_000), axis=1)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pa'], name='A',\n",
    "                         line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pa_upper']) + list(reversed(df['pa_lower'])),\n",
    "                         fill=\"toself\", name='A, 95% PDI', marker_color='black', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb'], name='B',\n",
    "                         line_color='blue'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pb_upper']) + list(reversed(df['pb_lower'])),\n",
    "                         fill=\"toself\", name='B, 95% PDI', marker_color='blue', opacity=0.2))\n",
    "fig.update_layout(title='$p_A, p_B$',\n",
    "                  yaxis_tickformat = ',.1%',\n",
    "                  xaxis_title='N')\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch3_conv_dynamics.png\", scale=2)\n",
    "#Оценки конверсий уточняются по мере набора данных.\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'], name='P(pb > pa)',\n",
    "                         line_color='black'))\n",
    "fig.update_layout(title='$P(p_B > p_A)$',\n",
    "                  yaxis_range=[0, 1],\n",
    "                  xaxis_title='N')\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch3_pbgta_dynamics.png\", scale=2)\n",
    "#Уверенность в лучшей группе растет по мере набора данных и уточнения конверсий."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6e39c0",
   "metadata": {},
   "source": [
    "Доля правильно угаданных вариантов демонстрируется следующим образом. В группе А задается конверсия `p`, в группе Б выбирается случайное значение в диапазоне $\\pm 5\\%$ от `p`. В группах генерируются данные с шагом `n_samp_step`. На каждом шаге считаются апостериорные распределения и $P(p_B > p_A)$. Эксперимент останавливается, если  $P(p_B > p_A)$ или $P(p_A > p_B)$  достигает `prob_stop=0.95` или сгенерировано максимальное количество точек `n_samp_max`. Процедура повторяется `nexps` раз, считается доля правильно угаданных групп во всех экспериментах. В данном случае в `nexps = 100` правильно угадано 94. Точность 0.94 близка к `prob_stop = 0.95`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874dbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best'])\n",
    "\n",
    "p = 0.1\n",
    "nexps = 100\n",
    "cmp['A'] = [p] * nexps\n",
    "cmp['B'] = p * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 30_000_000\n",
    "n_samp_step = 10_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    pA = cmp.at[i, 'A']\n",
    "    pB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.bernoulli(p=pA)\n",
    "    exact_dist_B = stats.bernoulli(p=pB)\n",
    "    n_samp_total = 0\n",
    "    ns_A = 0\n",
    "    ns_B = 0\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA = exact_dist_A.rvs(n_samp_step)\n",
    "        dB = exact_dist_B.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        ns_A = ns_A + np.sum(dA)\n",
    "        ns_B = ns_B + np.sum(dB)\n",
    "        post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "        post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "        pb_gt_pa = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "        best_gr = 'B' if pb_gt_pa >= prob_stop else 'A' if (1 - pb_gt_pa) >= prob_stop else None\n",
    "        if best_gr:\n",
    "            cmp.at[i, 'A_exp'] = post_dist_A.mean()\n",
    "            cmp.at[i, 'B_exp'] = post_dist_B.mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best'] = max(pb_gt_pa, 1 - pb_gt_pa)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P(b>a) {pb_gt_pa}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2fe9ea",
   "metadata": {},
   "source": [
    "Эксперименты останавливаются на заданном уровне уверенности, оценка времени и другие критерии остановки обсуждаются в приложениях [[Apx](https://github.com/andrewbrdk/Bayesian-AB-Testing/blob/main/appendices)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f2a0f",
   "metadata": {},
   "source": [
    "# Средние"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a0af2",
   "metadata": {},
   "source": [
    "Байесовский подход требует предположения распределений сравниваемых величин. Выбор модели всегда произвольный и всегда остаются вопросы обоснования модели. Во многих случаях не нужно полное распределение, достаточно сравнивать средние: среднюю выручку на пользователя, среднюю длительностю просмотра и т.д. Для средних часто применима центральная предельная теорема [[CLT](https://en.wikipedia.org/wiki/Central_limit_theorem)], что позволяет использовать нормальное распределение [[NormDist](https://en.wikipedia.org/wiki/Normal_distribution), [SciPyNorm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html?highlight=norm)] в качестве функции правдоподобия даже при неизвестной форме исходного распределения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c0cff",
   "metadata": {},
   "source": [
    "Центральная предельная теорема формализует следующее наблюдение. Если взять произвольное распределение со средним значением $\\mu$ и диспресий $\\sigma^2$, выбирать из него сэмплы длины $N$ и считать среднее в каждом сэмпле, то средние значения сэмплов будут распределены приблизительно нормально $Norm(\\mu, \\sigma^2/N)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455a8b2",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/central_limit_theorem_ru.png\" alt=\"Центральная предельная теорема\" width=\"800\"/>\n",
    "<br>\n",
    "<em>\n",
    "    Выборочные средние произвольного распределения с конечным средним и диспресий распределены приблизительно нормально.\n",
    "</em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88227652",
   "metadata": {},
   "source": [
    "Есть несколько центральных предельных теорем [[CLT](https://en.wikipedia.org/wiki/Central_limit_theorem)]. Одна из формулировок следующая. Пусть есть последовательность независимых одинаково распределенных случайных величин $X_1, X_2, \\dots$ с конечными математическим ожиданием $\\mu$ и дисперсией $\\sigma^2$. Пусть $\\overline{X}_N = \\frac{1}{N} \\sum_{i=1}^{N} X_i$ их выборочное среднее. Тогда при стремящемся к бесконечности $N$ распределение центрированных и масштабированных выборочных средних сходится к нормальному распределению со средним значением 0 и дисперсией 1. Сходимость понимается как сходимость по распределению [[RandVarsConv](https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_distribution)].\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P \\left( \\frac{\\overline{X}_N - \\mu}{\\sigma / \\sqrt{N}} = x \\right) & \\to Norm(x; 0, 1), \\quad N \\to \\infty\n",
    "\\\\ \n",
    "Norm(x ; \\mu, \\sigma^2) & = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\tfrac{(x-\\mu)^2}{2 \\sigma^2} }\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094021f4",
   "metadata": {},
   "source": [
    "На графике приведено сравнение распределения выборочных средних с нормальным распределением на основе центральной предельной теоремы. Из гамма-распределения $P(x; \\alpha, \\beta) \\propto x^{\\alpha-1} \\exp(-\\beta x)$ [[GammaDist](https://en.wikipedia.org/wiki/Gamma_distribution), [SciPyGamma](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html)] генерируется `n_sample` выборок по `sample_len` точек. В каждой выборке считаются средние, их распределение выводится на график. По точным значениям среднего и дисперсии исходного распределения определяются параметры нормального распределения центральной предельной теоремы `clt_mu, clt_stdev`. Это распределение также отображается на графике. Визуально распределение выборочных средних близко к нормальному распределению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "sample_len = 100\n",
    "n_samples = 1000\n",
    "\n",
    "exact_dist = stats.gamma(a=a)\n",
    "samp = exact_dist.rvs(size=(n_samples, sample_len))\n",
    "means = np.array([x.mean() for x in samp])\n",
    "clt_mu = exact_dist.mean()\n",
    "clt_stdev = exact_dist.std() / np.sqrt(sample_len)\n",
    "means_stdev = means.std()\n",
    "\n",
    "x = np.linspace(0, 10, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='solid', name='Исходное распределение'))\n",
    "fig.add_trace(go.Histogram(x=np.concatenate(samp), histnorm='probability density', name='Выборка', nbinsx=500,\n",
    "                           marker_color='black', opacity=0.3))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=clt_mu, scale=clt_stdev), \n",
    "                         mode='lines', line_color='black', line_dash='dash', name='$Norm(\\mu, \\sigma^2/N)$'))\n",
    "fig.add_trace(go.Histogram(x=means, histnorm='probability density', name='Выборочные средние', nbinsx=50,\n",
    "                           marker_color='green', opacity=0.5))\n",
    "fig.update_layout(title='Выборочные средние',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "fig.update_layout(xaxis_range=[0, 5])\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch4_clt_gamma.png\", scale=2)\n",
    "#Распределение выборочных средних гамма-распределения близко нормальному с параметрами на основе центральной предельной теоремы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb7b62",
   "metadata": {},
   "source": [
    "Центральная предельная теорема говорит о сходимости к нормальному распределению центрированных и масштабированных выборочных средних $\\overline{X}_N$ при стремлении $N$ к бесконечности. Для конечного $N$ нормальное распределение не гарантируется. Отклонение распределения суммы конечного числа слагаемых от нормального дает теорема Берри-Эссеена [[BerryEsseenTheorem](https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem)]. Отличие зависит от количества слагаемых $N$ и коэффициента асимметрии исходного распределения. В приведенной формулировке центральная предельная теорема требует существования конечных среднего и дисперсии у исходного распределения. Примерами распределений, для которых эти свойства могут не выполнятся, являются распределение Парето [[ParetoDist](https://en.wikipedia.org/wiki/Pareto_distribution), [SciPyPareto](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pareto.html)] и близкое к нему распределение Ломакса [[LomaxDist](https://en.wikipedia.org/wiki/Lomax_distribution), [SciPyLomax](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lomax.html)]. Плотность вероятности последнего имеет вид\n",
    "\n",
    "$$\n",
    "P(x; c) = \\frac{c}{(1 + x )^{c + 1}}, \\quad x \\ge 0, c > 0.\n",
    "$$\n",
    "\n",
    "При значениях параметра $c$ меньше или равном 2 дисперсия распределения Ломакса не является конечной. \n",
    "На графиках ниже приведена гистограмма `n_samples` выборочных средних с количеством слагаемых `sample_len` и нормальное распределение с параметрами из центральной предельной теоремы на основе точного распределения `clt_mu, clt_stdev`. Распределение выборочных средних скошено и сильнее отличается от нормального, чем в предыдущем случае. Перекос происходит из-за попадания в выборки больших значений из хвоста исходного распределения. На практике распределения ограничены, поэтому дисперсии и средние конечны. Центральная предельная теорема будет применима, но для приближения выборочных средних нормальным распределением потребуется большое количество точек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1.7\n",
    "sample_len = 500\n",
    "n_samples = 1000\n",
    "\n",
    "exact_dist = stats.lomax(c=c)\n",
    "samp = exact_dist.rvs(size=(n_samples, sample_len))\n",
    "means = np.array([x.mean() for x in samp])\n",
    "clt_mu = exact_dist.mean()\n",
    "means_stdev = means.std()\n",
    "\n",
    "xaxis_max=10\n",
    "x = np.linspace(0, xaxis_max, 2000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='solid', name='Исходное распределение'))\n",
    "fig.add_trace(go.Histogram(x=np.concatenate(samp)[np.concatenate(samp) < xaxis_max], histnorm='probability density', \n",
    "                           name='Выборка', nbinsx=500,\n",
    "                           marker_color='black', opacity=0.3))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=clt_mu, scale=means_stdev), \n",
    "                         mode='lines', line_color='black', line_dash='dash', name='$Norm(\\mu, \\sigma_{\\overline{X}_N}^2)$'))\n",
    "fig.add_trace(go.Histogram(x=means, histnorm='probability density', name='Выборочные средние', nbinsx=150,\n",
    "                          marker_color='green', opacity=0.5))\n",
    "fig.update_layout(title='Выборочные средние',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  xaxis_range=[0, xaxis_max],\n",
    "                  height=550)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch4_clt_lomax.png\", scale=2)\n",
    "#Дисперсия распределения Ломакса при определенных параметрах неограничена. \n",
    "#Распределение выборочных средних отличается от нормального. \n",
    "#Для сильно скошенных распределений даже при конечном среднем и дисперсии требуется много точек для приближения выборочных средних нормальным распределением."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb9782",
   "metadata": {},
   "source": [
    "Для байесовской оценки параметров нормального распределения по выборке функция правдоподобия задается нормальным распределением $P(\\mathcal{D} | \\mathcal{H}) = Norm(x | \\mu, \\sigma_x^2)$. У этой функции 2 параметра - $\\mu$ и $\\sigma_x$. Для такой модели известно сопряженное априорное распределение [[ConjPrior](https://en.wikipedia.org/wiki/Conjugate_prior), [Apx](https://github.com/andrewbrdk/Bayesian-AB-Testing/blob/main/appendices)]. Ниже рассмотрен упрощенный вариант с одним параметром - подбирается только распределение $\\mu$, значение $\\sigma_x$ фиксировано. Сопряженным априорным распределением $P(\\mu)$ в этом случае также будет нормальное распределение $P(\\mu) = Norm(\\mu | \\mu_0, \\sigma_0^2)$, но со своими параметрами $\\mu_0$, $\\sigma_0$. При расчете апостериорного распределения понадобится произведение функций правдоподобия по всем точкам $x_i$ $P(\\mathcal{H} | \\mathcal{D}) \\propto \\prod_i^N Norm(x_i | \\mu, \\sigma_x^2) Norm(\\mu | \\mu_0, \\sigma_0^2)$. В преобразованиях достаточно следить за зависимостью от $\\mu$, множители без $\\mu$ войдут в нормировочный коэффициент итогового распределения. Апостериорное распределение сохранит нормальную форму $P(\\mu | \\mathcal{D}) = Norm(\\mu | \\mu_N, \\sigma_N^2)$ с обновленными параметрами $\\mu_N$, $\\sigma_N$.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(\\mathcal{D} | \\mathcal{H}) & = Norm(x | \\mu, \\sigma_x^2) = \n",
    "\\frac{1}{\\sqrt{2 \\pi \\sigma_x^2}} e^{-\\tfrac{(x - \\mu)^2}{2 \\sigma_x^2}}\n",
    "\\\\\n",
    "P(\\mathcal{H}) & = Norm(\\mu | \\mu_0, \\sigma_0^2) = \n",
    "\\frac{1}{\\sqrt{2 \\pi \\sigma_{0}^2}} e^{-\\tfrac{(\\mu-\\mu_0)^2}{2 \\sigma_{0}^2}} \n",
    "\\\\\n",
    "P(\\mathcal{H} | \\mathcal{D}) \n",
    "& \\propto\n",
    "\\prod_i^N\n",
    "Norm(x_i | \\mu, \\sigma_x^2)\n",
    "Norm(\\mu | \\mu_0, \\sigma_0^2)\n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "\\prod_i^N\n",
    "e^{-\\tfrac{(x_i - \\mu)^2}{2 \\sigma_x^2}}\n",
    "e^{-\\tfrac{(\\mu-\\mu_0)^2}{2 \\sigma_0^2}} \n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "e^{-\\mu^2 \\left[\\tfrac{N}{2 \\sigma_x^2} + \\tfrac{1}{2 \\sigma_0^2} \\right] + \n",
    "   2\\mu \\left[\\tfrac{\\mu_0}{2 \\sigma_0^2} + \\tfrac{1}{2 \\sigma_x^2} \\sum_i^N x_i \\right]}\n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "e^{-\\tfrac{(\\mu - \\mu_N)^2}{2 \\sigma_N^2}}\n",
    "= Norm(\\mu | \\mu_N, \\sigma_N^2),\n",
    "\\quad\n",
    "\\sigma_N^2 = \\frac{\\sigma_0^2 \\sigma_x^2}{\\sigma_x^2 + N \\sigma_0^2},\n",
    "\\quad\n",
    "\\mu_N = \\mu_0 \\frac{\\sigma_N^2}{\\sigma_0^2} + \\frac{\\sigma_N^2}{\\sigma_x^2} \\sum_i^N x_i\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda70fb7",
   "metadata": {},
   "source": [
    "Для проверки построения апостериорного распределения по данным задается нормальное распределение с параметрами `mu, sigma` и генерируется выборка размера `nsample`. Начальные параметры $\\sigma_x, \\sigma_0$ выбираются равными стандартному отклонению в выборке, $\\mu_0$ - значению первой точки. Параметры $\\mu_N, \\sigma_N$ расчитываются по оставшимся точкам. Использовать всю выборку для задания начальных параметров некорректно, лучше использовать часть данных или исторические данные. На первом графике апостериорное распределение $\\mu$ сравнивается с точным средним. Мода близка к среднему в выборке и точному среднему. На втором графике апостериорное прогнозное распределение $x$ сравнивается с исходным. Для построения распределения $x$ вначале нужно сгенерировать $\\mu \\sim Norm(\\mu | \\mu_N, \\sigma_N^2)$, после чего с этим $\\mu$ сгенерировать $x \\sim Norm(x | \\mu, \\sigma_x^2)$. Гистограмма $x$ визуально близка исходному нормальному распределению. На последнем графике приведено сравнение распределений $x$ и $\\mu$. Это разные распределения - $P(x|\\mathcal{D})$ приближает исходное нормальное распределение, $P(\\mu|\\mathcal{D})$ - оценка среднего. Распределение $\\mu$ существенно уже. Его дисперсия задается $\\sigma_N$, тогда как дисперсия $P(x|\\mathcal{D})$ определяется $\\sigma_x$ и вариацией $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf7c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConjugateNormalParams = namedtuple('ConjugateNormalParams', 'mu sigma sx')\n",
    "\n",
    "def initial_params_normal(mu, sigma, sx):\n",
    "    return ConjugateNormalParams(mu=mu, sigma=sigma, sx=sx)\n",
    "\n",
    "def posterior_params_normal(data, initial_pars):\n",
    "    N = len(data)\n",
    "    sigma_n_2 = (initial_pars.sigma**2 * initial_pars.sx**2) / (initial_pars.sx**2 + N * initial_pars.sigma**2)\n",
    "    mu_n = initial_pars.mu * sigma_n_2 / initial_pars.sigma**2 + np.sum(data) * sigma_n_2 / initial_pars.sx**2    \n",
    "    return ConjugateNormalParams(mu=mu_n, sigma=np.sqrt(sigma_n_2), sx=initial_pars.sx)\n",
    "\n",
    "def posterior_mu_dist(params):\n",
    "    return stats.norm(loc=params.mu, scale=params.sigma)\n",
    "\n",
    "def posterior_rvs(params, nsamp):\n",
    "    mus = stats.norm.rvs(loc=params.mu, scale=params.sigma, size=nsamp)\n",
    "    return stats.norm.rvs(loc=mus, scale=params.sx, size=nsamp)\n",
    "\n",
    "mu = 3\n",
    "sigma = 1\n",
    "nsample = 1000\n",
    "npostsamp = 100000\n",
    "\n",
    "exact_dist = stats.norm(loc=mu, scale=sigma)\n",
    "data = exact_dist.rvs(nsample)\n",
    "\n",
    "sx = np.std(data)\n",
    "mu0 = data[0]\n",
    "sigma0 = np.std(data)\n",
    "pars = initial_params_normal(mu=mu0, sigma=sigma0, sx=sx)\n",
    "pars = posterior_params_normal(data[1:], pars)\n",
    "post_mu = posterior_mu_dist(pars)\n",
    "post_samp = posterior_rvs(pars, npostsamp)\n",
    "\n",
    "x = np.linspace(0, 10, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_mu.pdf(x), line_color='black', name='$\\mbox{Апостериорное }\\mu$'))\n",
    "fig.add_trace(go.Scatter(x=[data.mean(), data.mean()], y=[0, max(post_mu.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist.mean(), exact_dist.mean()], y=[0, max(post_mu.pdf(x))*1.05], \n",
    "                         line_color='red', mode='lines', line_dash='dash', name='Точное среднее'))\n",
    "fig.update_layout(title='$\\mbox{Апостериорное распределение } \\mu$',\n",
    "                  xaxis_title='$\\mu$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[2, 4],\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)                  \n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch4_norm_postdist_mu.png\", scale=2)\n",
    "#Мода распределения mu близка точному среднему и среднему в выборке.\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), line_color='red', line_dash='dash', name='Точное распределение'))\n",
    "fig.add_trace(go.Histogram(x=post_samp, histnorm='probability density', name='Сэмпл апостериорного x', nbinsx=100,\n",
    "                           marker_color='black', opacity=0.8))\n",
    "fig.update_layout(title='Сэмпл апостериорного распределения x',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  #xaxis_range=[0, 10],\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)                  \n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch4_norm_postdist_x.png\", scale=2)\n",
    "#Апостериорное предиктивное распределение x близко исходному нормальному распределению.\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_mu.pdf(x), line_color='black', name='$\\mbox{Апостериорное }\\mu$'))\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), line_color='red', line_dash='dash', name='Точное распределение'))\n",
    "fig.add_trace(go.Histogram(x=post_samp, histnorm='probability density', name='Сэмпл апостериорного x', nbinsx=100,\n",
    "                           marker_color='black', opacity=0.8))\n",
    "fig.update_layout(title='$\\mbox{Распределения } x \\mbox{ и } \\mu$',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[0, 6],\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)                  \n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch4_norm_postdist_mu_x.png\", scale=2)\n",
    "#Сравнение апостериорных распределений x и mu. Распределение mu - оценка среднего исходного распределения, распределение x - приближение всего исходного нормального распределения. Распределение mu существенно уже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0832248a",
   "metadata": {},
   "source": [
    "Оценка среднего произвольного распределения показана для гамма-распределения. Выбирается `nsample` точек, сэмпл разбивается на части по `nsplit` штук, в каждой части считается среднее. Выборочные средние `means` предполагаются распределенными нормально, к ним применяется байесовское моделирование. Начальные параметры $\\sigma_x$ и $\\sigma_0$ задаются равными стандартному отклонению выборочных средних `sx = np.std(means), sigma0 = sx`, $\\mu_0$ - первому выборочному среднему `mu0 = means[0]`. Количество точек `nsplit=100` выбрано произвольно, точнее можно оценить по теореме Берри-Эссеена. Вместо деления данных на части по `nsplit` можно посчитать среднее по всей выборке. В таком случае распределение $P(\\mu|\\mathcal{D})$ нужно будет оценивать по одной точке, что не позволит валидировать модель. Количество точек `nsplit` лучше считать гиперпараметром модели. На первом графике показано исходное распределение и распределение выборочных средних, которое ожидается приблизительно нормальным. На втором построено апостериорное распределение $\\mu$, мода близка среднему в выборке и точному среднему. На третьем графике приведено апостериорное прогнозное распределение выборочных средних. Оно визуально близко нормальному распределению с параметрами на основе центральной предельной теоремы. Как и в первом примере, распределение $\\mu$ (второй график) уже распределение выборочных средних (третий график). Для сравнения средних нужно ориентироваться на распределения $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37578db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_compute_means(sample, n_split):\n",
    "    n_means = len(sample) // n_split\n",
    "    samp_reshaped = np.reshape(sample[0 : n_means * n_split], (n_means, n_split))\n",
    "    means = np.array([x.mean() for x in samp_reshaped])\n",
    "    return means\n",
    "\n",
    "def exact_clt_dist(exact_dist, n_split):\n",
    "    clt_mu = exact_dist.mean()\n",
    "    clt_stdev = exact_dist.std() / np.sqrt(n_split)\n",
    "    return stats.norm(loc=clt_mu, scale=clt_stdev)\n",
    "\n",
    "def sample_clt_dist(means):\n",
    "    clt_mu = means.mean()\n",
    "    clt_std = means.std()\n",
    "    return stats.norm(loc=clt_mu, scale=clt_std)\n",
    "\n",
    "nsample = 50000\n",
    "nsplit = 100\n",
    "npostsamp = 50000\n",
    "\n",
    "a = 1\n",
    "b = 2\n",
    "exact_dist = stats.gamma(a=a, scale=1/b)\n",
    "data = exact_dist.rvs(nsample)\n",
    "\n",
    "means = reshape_and_compute_means(data, nsplit)\n",
    "clt_dist_exact = exact_clt_dist(exact_dist, nsplit)\n",
    "\n",
    "sx = np.std(means)\n",
    "mu0 = means[0]\n",
    "sigma0 = sx\n",
    "pars = initial_params_normal(mu=mu0, sigma=sigma0, sx=sx)\n",
    "pars = posterior_params_normal(means[1:], pars)\n",
    "post_mu = posterior_mu_dist(pars)\n",
    "post_samp = posterior_rvs(pars, npostsamp)\n",
    "\n",
    "x = np.linspace(0, 10, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='solid', name='Исходное распределение'))\n",
    "fig.add_trace(go.Scatter(x=x, y=clt_dist_exact.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='dash', name='$Norm(\\mu, \\sigma^2/N)$'))\n",
    "fig.add_trace(go.Histogram(x=means, histnorm='probability density', name='Выборочные средние', nbinsx=50,\n",
    "                           marker_color='green', opacity=0.5))\n",
    "fig.update_layout(title='Выборочные средние',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "fig.update_layout(xaxis_range=[0, 3])\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch4_gamma_means.png\", scale=2)\n",
    "#Исходное гамма-распределение и выборочные средние. Выборочные средние близки нормальному распределению на основе центральной предельной теоремы.\n",
    "\n",
    "x = np.linspace(0, 4, 10000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_mu.pdf(x), line_color='black', name='$\\mbox{Распределение }\\mu$'))\n",
    "fig.add_trace(go.Scatter(x=[data.mean(), data.mean()], y=[0, max(post_mu.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist.mean(), exact_dist.mean()], y=[0, max(post_mu.pdf(x))*1.05], \n",
    "                         line_color='red', mode='lines', line_dash='dash', name='Точное среднее'))\n",
    "fig.update_layout(title='$\\mbox{Распределение }\\mu$',\n",
    "                  xaxis_title='$\\mu$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[exact_dist.mean()-0.1, exact_dist.mean()+0.1],\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)                  \n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch4_gamma_postdist_mu.png\", scale=2)\n",
    "#Оценка mu по выборочным средним. Мода распределения близка точному среднему гамма-распределения.\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), line_dash='solid', line_color='black', name='Исходное распределение'))\n",
    "fig.add_trace(go.Scatter(x=x, y=clt_dist_exact.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='dash', name='$Norm(\\mu, \\sigma^2/N)$'))\n",
    "fig.add_trace(go.Histogram(x=post_samp, histnorm='probability density', name='$\\mbox{Апострериорное } \\overline{X}_N$', nbinsx=300,\n",
    "                           marker_color='black', opacity=0.2))\n",
    "fig.update_layout(title='$\\mbox{Апостериорное распределение } \\overline{X}_N$',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[0, 3],\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)                  \n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch4_gamma_postdist_means.png\", scale=2)\n",
    "#Апостериорное прогнозное распределение выборочных средних близко нормальному на основе центральной предельной теоремы.\n",
    "\n",
    "stderrmean = data.std() / np.sqrt(len(data))\n",
    "print(f'Среднее выборки: {data.mean():5f}, Стандартная ошибка среднего: {stderrmean:5f}')\n",
    "print(f'Среднее апостериорного mu: {post_mu.mean():5f}, Стандартное отклонение апостериорного mu: {post_mu.std():5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82526e6d",
   "metadata": {},
   "source": [
    "Для примера сравнения групп задаются 2 гамма-распределения. Параметры $a$ одинаковы, параметр $b$ группы Б на $5\\%$ меньше А. Из каждого делается выборка размера `nsample`, считаются выборочные средние. По выборочным средним строятся апостериорные распределения $\\mu$. По этим распределениям вычисляется вероятность среднего в группе Б больше группы А $P(\\mu_B > \\mu_A)$. На первом графике приведены исходные распределения и точные средние. На втором - распределения $\\mu$ и точные средние. При выбранных сэмплах распределения $P(\\mu|\\mathcal{D})$ пересекаются слабо $P(\\mu_B > \\mu_A) = 1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab84338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "nsample = 30000\n",
    "npostsamp = 50000\n",
    "nsplit = 100\n",
    "\n",
    "A, B = {}, {}\n",
    "A['dist_pars'] = {'a': 1, 'b': 2}\n",
    "B['dist_pars'] = {'a': 1, 'b': 2*0.95}\n",
    "for g in [A, B]:\n",
    "    g['exact_dist'] = stats.gamma(a=g['dist_pars']['a'], scale=1/g['dist_pars']['b'])\n",
    "    g['data'] = g['exact_dist'].rvs(nsample)\n",
    "    g['means'] = reshape_and_compute_means(g['data'], nsplit)\n",
    "    g['post_pars'] = initial_params_normal(mu=g['means'][0], sigma=np.std(g['means']), sx=np.std(g['means']))\n",
    "    g['post_pars'] = posterior_params_normal(g['means'][1:], g['post_pars'])\n",
    "    g['post_mu'] = posterior_mu_dist(g['post_pars'])\n",
    "    g['post_samp'] = posterior_rvs(g['post_pars'], npostsamp)\n",
    "\n",
    "    \n",
    "x = np.linspace(0, 3, 5000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=A['exact_dist'].pdf(x), line_color='black', opacity=0.2, name='A'))\n",
    "fig.add_trace(go.Scatter(x=x, y=B['exact_dist'].pdf(x), line_color='black', name='Б'))\n",
    "fig.add_trace(go.Scatter(x=[A['exact_dist'].mean(), A['exact_dist'].mean()], y=[0, max(A['exact_dist'].pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', opacity=0.2, name='Точное среднее A'))\n",
    "fig.add_trace(go.Scatter(x=[B['exact_dist'].mean(), B['exact_dist'].mean()], y=[0, max(B['exact_dist'].pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', name='Точное среднее Б'))\n",
    "fig.update_layout(title='Исходные распределения',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[0, 3],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch4_gamma_cmp_orig.png\", scale=2)\n",
    "#Исходные гамма-распределения и точные средние. Среднее Б больше А.\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=A['post_mu'].pdf(x), line_color='black', opacity=0.2, name='A'))\n",
    "fig.add_trace(go.Scatter(x=x, y=B['post_mu'].pdf(x), line_color='black', name='Б'))\n",
    "fig.add_trace(go.Scatter(x=[A['exact_dist'].mean(), A['exact_dist'].mean()], y=[0, max(A['post_mu'].pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', opacity=0.2, name='Точное среднее A'))\n",
    "fig.add_trace(go.Scatter(x=[B['exact_dist'].mean(), B['exact_dist'].mean()], y=[0, max(B['post_mu'].pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', name='Точное среднее Б'))\n",
    "fig.update_layout(title='$\\mbox{Распределения } \\mu$',\n",
    "                  xaxis_title='$\\mu$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[A['exact_dist'].mean()-0.1, A['exact_dist'].mean()+0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch4_gamma_cmp_mu.png\", scale=2)\n",
    "#Оценки mu по выборочным средним. По собранным данным среднее Б больше А с вероятностью 1.\n",
    "\n",
    "print(f\"P(mu_B > mu_A): {prob_pb_gt_pa(A['post_mu'], B['post_mu'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b9afd",
   "metadata": {},
   "source": [
    "Для демонстрации доли правильно угаданных вариантов задается 2 группы с гамма-распределениями. В группе A параметры гамма-распределения фиксированы, в Б параметр $b$ меняется в пределах $\\pm5\\%$ группы A. Вместе с параметрами меняются средние. Из распределений генерируются данные с шагом `n_samp_step`. На каждом шаге считаются выборочные средние `nsplit`. По выборочным средним проводится оценка параметров $\\mu$. Распределения этих параметров сравниваются. Набор данных останавливается, если $P(\\mu_B > \\mu_A)$ или $P(\\mu_A > \\mu_B)$ достигает `prob_stop = 0.95`, или достигнуто предельное количество точек `n_samp_max`. Проводится `nexps` экспериментов, считается доля правильно угаданных групп с большим средним. В примере доля 0.97 близка `prob_stop = 0.95`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89dc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "nexps = 100\n",
    "prob_stop = 0.95\n",
    "nsplit = 100\n",
    "n_samp_max = 1_000_000\n",
    "n_samp_step = 10_000\n",
    "\n",
    "A = {'a': 1, 'b': 2}\n",
    "\n",
    "cmp = pd.DataFrame(columns=['A_pars', 'B_pars', 'A_mean', 'B_mean', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best'])\n",
    "cmp['A_pars'] = [A] * nexps\n",
    "cmp['B_pars'] = cmp['A_pars'].apply(lambda x: {'a': x['a'], 'b': x['b'] * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1))})\n",
    "cmp['A_mean'] = cmp['A_pars'].apply(lambda x: stats.gamma(a=x['a'], scale=1/x['b']).mean())\n",
    "cmp['B_mean'] = cmp['B_pars'].apply(lambda x: stats.gamma(a=x['a'], scale=1/x['b']).mean())\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B_mean'] > r['A_mean'] else 'A', axis=1)\n",
    "\n",
    "for i in range(nexps):\n",
    "    A_pars = cmp.at[i, 'A_pars']\n",
    "    B_pars = cmp.at[i, 'B_pars']\n",
    "    exact_dist_A = stats.gamma(a=A_pars['a'], scale=1/A_pars['b'])\n",
    "    exact_dist_B = stats.gamma(a=B_pars['a'], scale=1/B_pars['b'])\n",
    "    n_samp_total = 0\n",
    "    dA = []\n",
    "    dB = []\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA.extend(exact_dist_A.rvs(n_samp_step))\n",
    "        dB.extend(exact_dist_B.rvs(n_samp_step))\n",
    "        n_samp_total += n_samp_step\n",
    "        means_A = reshape_and_compute_means(dA, nsplit)\n",
    "        post_pars_A = initial_params_normal(mu=means_A[0], sigma=np.std(means_A), sx=np.std(means_A))\n",
    "        post_pars_A = posterior_params_normal(means_A[1:], post_pars_A)\n",
    "        post_mu_A = posterior_mu_dist(post_pars_A)\n",
    "        means_B = reshape_and_compute_means(dB, nsplit)\n",
    "        post_pars_B = initial_params_normal(mu=means_B[0], sigma=np.std(means_B), sx=np.std(means_B))\n",
    "        post_pars_B = posterior_params_normal(means_B[1:], post_pars_B)\n",
    "        post_mu_B = posterior_mu_dist(post_pars_B)\n",
    "        pb_gt_pa = prob_pb_gt_pa(post_mu_A, post_mu_B)\n",
    "        best_gr = 'B' if pb_gt_pa >= prob_stop else 'A' if (1 - pb_gt_pa) >= prob_stop else None\n",
    "        if best_gr:\n",
    "            cmp.at[i, 'A_exp'] = post_mu_A.mean()\n",
    "            cmp.at[i, 'B_exp'] = post_mu_B.mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best'] = max(pb_gt_pa, 1 - pb_gt_pa)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P(B>A) {pb_gt_pa}')\n",
    "\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a347639",
   "metadata": {},
   "source": [
    "# Транзакционная выручка на пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908983d",
   "metadata": {},
   "source": [
    "Выручка на пользователя - одна из основных метрик А/Б-тестов. Средние значения сравнивают методом предыдущего раздела. Кроме средних бывают нужны полные распределения - например, в транзакционных сервисах для оценки вклада высокоплатящих пользователей. Полное распределение можно оценить байесовским методом. В выручке на пользователя $P_{пользователи}(x)$ удобно выделить выручку на платящего $P_{платящие}(x)$. При конверсии в оплату $p$ распределение ненулевой выручки на пользователя $p P_{платящие}(x)$, с вероятностью $1-p$ выручка нулевая.\n",
    "\n",
    "$$\n",
    "P_{пользователи}(x) = \n",
    "\\begin{cases}\n",
    "1-p, \\, x = 0\n",
    "\\\\\n",
    "p P_{платящие}(x), \\, x > 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b73ebe",
   "metadata": {},
   "source": [
    "Оценка конверсии в оплату $p$ делалась ранее. Выручку на платящего можно моделировать логнормальным распределением [[LognormDist](https://en.wikipedia.org/wiki/Log-normal_distribution),\n",
    "[SciPyLognorm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html)] или распределением Парето [[ParetoDist](https://en.wikipedia.org/wiki/Pareto_distribution), [SciPyPareto](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pareto.html)] по аналогии с распределением богатства. Для транзакционных сервисов, в частности маркетплейсов, лучше подходит логнормальное распределение. Случайная величина логнормальная $X \\sim Lognormal(\\mu, s^2)$, если логарифм распределен нормально $\\ln(X) \\sim Norm(\\mu, s^2)$. Плотность вероятности приведена ниже \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(x) & = \\frac{1}{x s \\sqrt{2 \\pi}} e^{-\\tfrac{(\\ln(x) - \\mu)^2}{2 s^2}}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943467ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 20, 2000)\n",
    "fig = go.Figure()\n",
    "mu, s = 1, 1\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.lognorm.pdf(x, s=s, scale=np.exp(mu)), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'$\\mu={mu}, \\, s={s}$'))\n",
    "mu, s = 2, 1\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.lognorm.pdf(x, s=s, scale=np.exp(mu)), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'$\\mu={mu}, \\, s={s}$'))\n",
    "mu, s = 1, 2\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.lognorm.pdf(x, s=s, scale=np.exp(mu)), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'$\\mu={mu}, \\, s={s}$'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[2.90, 11.2, 1.80],\n",
    "    y=[0.25, 0.06, 0.48],\n",
    "    mode=\"text\",\n",
    "    name=None,\n",
    "    showlegend=False,\n",
    "    text=[\"$\\mu=1, \\, s=1$\", \"$\\mu=2, \\, s=1$\", \"$\\mu=1, \\, s=2$\"],\n",
    "    textposition=\"middle center\"\n",
    "))\n",
    "fig.update_layout(title='Логнормальное распределение',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  hovermode=\"x\",\n",
    "                  showlegend=False,\n",
    "                  height=550)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch5_lognorm.png\", scale=2)\n",
    "#Логнормальное распределение с различными параметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014435d5",
   "metadata": {},
   "source": [
    "Сопряженное априорное распределение к логнормальной функции правдоподобия $P(\\mathcal{D} | \\mathcal{H}) = Lognorm(x | \\mu, s^2)$ строится аналогично нормальному распределению [[ConjPrior](https://en.wikipedia.org/wiki/Conjugate_prior)]. Для упрощенной модели с одним параметром $\\mu$ и фиксированным $s$ сопряженное априорное распределение нормальное $P(\\mu) = Norm(\\mu | \\mu_0, \\sigma_0^2)$ с параметрами $\\mu_0$, $\\sigma_0$. Апостериорное распределение нормальное $P(\\mu | \\mathcal{D}) = Norm(\\mu | \\mu_N, \\sigma_N^2)$ с обновленными параметрами $\\mu_N$, $\\sigma_N$. В $\\mu_N$ суммируются логарифмы точек выборки.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(\\mathcal{D} | \\mathcal{H}) & = Lognorm(x | \\mu, s^2) = \n",
    "\\frac{1}{x \\sqrt{2 \\pi s^2}} e^{-\\tfrac{(\\ln x - \\mu)^2}{2 s^2}}\n",
    "\\\\\n",
    "P(\\mathcal{H}) & = Norm(\\mu | \\mu_0, \\sigma_0^2) = \n",
    "\\frac{1}{\\sqrt{2 \\pi \\sigma_{0}^2}} e^{-\\tfrac{(\\mu-\\mu_0)^2}{2 \\sigma_{0}^2}} \n",
    "\\\\\n",
    "P(\\mathcal{H} | \\mathcal{D}) \n",
    "& \\propto\n",
    "\\prod_i^N\n",
    "Lognorm(x_i | \\mu, s^2)\n",
    "Norm(\\mu | \\mu_0, \\sigma_0^2)\n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "\\prod_i^N\n",
    "e^{-\\tfrac{(\\ln x_i - \\mu)^2}{2 s^2}}\n",
    "e^{-\\tfrac{(\\mu-\\mu_0)^2}{2 \\sigma_0^2}} \n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "e^{-\\mu^2 \\left[\\tfrac{N}{2 s^2} + \\tfrac{1}{2 \\sigma_0^2} \\right] + \n",
    "   2\\mu \\left[\\tfrac{\\mu_0}{2 \\sigma_0^2} + \\tfrac{1}{2 s^2} \\sum_i^N \\ln x_i \\right]}\n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "e^{-\\tfrac{(\\mu - \\mu_N)^2}{2 \\sigma_N^2}}\n",
    "= Norm(\\mu | \\mu_N, \\sigma_N^2),\n",
    "\\quad\n",
    "\\sigma_N^2 = \\frac{\\sigma_0^2 s^2}{s^2 + N \\sigma_0^2},\n",
    "\\quad\n",
    "\\mu_N = \\mu_0 \\frac{\\sigma_N^2}{\\sigma_0^2} + \\frac{\\sigma_N^2}{s^2} \\sum_i^N \\ln x_i\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0789d8c8",
   "metadata": {},
   "source": [
    "Для примера построения апостериорного распределения по данным из логнормального распределения с параметрами `mu, s` генерируется выборка размера `nsample`. Считается логарифм точек выборки. Параметры $s$ и $\\sigma_0$ выбираются равными стандартному отклонению логарифма точек выборки, $\\mu_0$ задается равным значению первой точки. По оставшимся точкам расчитываются $\\mu_N, \\sigma_N$. Апостериорное распределение $\\mu$ приведено на первом графике. Среднее логнормального распределения задается выражением $E[x] = \\exp(\\mu + s^2/2)$, поэтому $\\mu + s^2/2$ должно быть оценкой логарифма точного среднего. Т.к. $\\mu$ распределено нормально $P(\\mu) = Norm(\\mu_N, \\sigma_N^2)$, величина $\\mu + s^2/2$ также распределена нормально $Norm(\\mu_N + s^2/2, \\sigma_N^2)$. На первом графике мода распределения $\\mu + s^2/2$ близка логарифму среднего в выборке и точного среднего. На втором графике апостериорное прогнозное распределение $x$ сравнивается с исходным. Гистограмма $x$ близка исходному.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(x) & = Lognorm(x | \\mu, s^2)\n",
    "\\\\\n",
    "E[x] & = e^{\\mu + s^2/2}\n",
    "\\\\\n",
    "P(\\mu) & = Norm(\\mu | \\mu_N, \\sigma_N^2)\n",
    "\\\\\n",
    "P_{\\mu + s^2/2}(y) & = Norm(y | \\mu_N + s^2/2, \\sigma_N^2)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConjugateLognormalParams = namedtuple('ConjugateLognormalParams', 'mu sigma sx')\n",
    "\n",
    "def initial_params_lognormal(mu, sigma, sx):\n",
    "    return ConjugateLognormalParams(mu=mu, sigma=sigma, sx=sx)\n",
    "\n",
    "def posterior_params_lognormal(data, initial_pars):\n",
    "    N = len(data)\n",
    "    lnx = np.log(data)\n",
    "    sigma_n_2 = (initial_pars.sigma**2 * initial_pars.sx**2) / (initial_pars.sx**2 + N * initial_pars.sigma**2)\n",
    "    mu_n = initial_pars.mu * sigma_n_2 / initial_pars.sigma**2 + np.sum(lnx) * sigma_n_2 / initial_pars.sx**2    \n",
    "    return ConjugateLognormalParams(mu=mu_n, sigma=np.sqrt(sigma_n_2), sx=initial_pars.sx)\n",
    "\n",
    "def posterior_mu_dist_lognormal(params):\n",
    "    return stats.norm(loc=params.mu, scale=params.sigma)\n",
    "\n",
    "def posterior_lognormal_rvs(params, nsamp):\n",
    "    mus = stats.norm.rvs(loc=params.mu, scale=params.sigma, size=nsamp)\n",
    "    return stats.lognorm.rvs(s=params.sx, scale=np.exp(mus), size=nsamp)\n",
    "\n",
    "def posterior_mean_dist_lognormal(params):\n",
    "    return stats.lognorm(scale=np.exp(params.mu + params.sx**2/2), s=params.sigma)\n",
    "\n",
    "def posterior_ln_mean_dist_lognormal(params):\n",
    "    return stats.norm(loc=params.mu + params.sx**2/2, scale=params.sigma)\n",
    "    \n",
    "s = 1\n",
    "mu = 1.5\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist = stats.lognorm(s=s, scale=np.exp(mu))\n",
    "data = exact_dist.rvs(nsample)\n",
    "\n",
    "lnx = np.log(data)\n",
    "sx = np.std(lnx)\n",
    "mu0 = lnx[0]\n",
    "sigma0 = sx\n",
    "\n",
    "pars = initial_params_lognormal(mu=mu0, sigma=sigma0, sx=sx)\n",
    "pars = posterior_params_lognormal(data[1:], pars)\n",
    "post_mu = posterior_mu_dist_lognormal(pars)\n",
    "post_lnmeans = posterior_ln_mean_dist_lognormal(pars)\n",
    "npostsamp = 10000\n",
    "post_samp = posterior_lognormal_rvs(pars, npostsamp)\n",
    "\n",
    "x = np.linspace(0, 4, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_mu.pdf(x), line_color='black', name='$\\mbox{Распределение }\\mu$'))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_lnmeans.pdf(x), line_color='black', opacity=0.2, name='$\\mbox{Распределение } \\mu + s^2/2$'))\n",
    "fig.add_trace(go.Scatter(x=[np.log(data.mean()), np.log(data.mean())], y=[0, max(post_mu.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='Логарифм среднего в выборке'))\n",
    "fig.add_trace(go.Scatter(x=[np.log(exact_dist.mean()), np.log(exact_dist.mean())], y=[0, max(post_mu.pdf(x))*1.05], \n",
    "                         line_color='red', mode='lines', line_dash='dash', name='Логарифм точного среднего'))\n",
    "fig.update_layout(title='$\\mbox{Апостериорные распределения } \\mu \\mbox{ и } \\mu + s^2/2$',\n",
    "                  xaxis_title='$\\mu$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  #xaxis_range=[2, 4],\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)                  \n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch5_lognorm_postdist_mu_mean.png\", scale=2)\n",
    "#Апостериорное распределение mu + s^2/2 близко логарифму точного среднего.\n",
    "\n",
    "xaxis_max=20\n",
    "x = np.linspace(0, xaxis_max, 10000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), line_dash='dash', line_color='red', name='Точное распределение'))\n",
    "fig.add_trace(go.Histogram(x=post_samp[post_samp < xaxis_max], histnorm='probability density', name='Сэмпл апостериорного', nbinsx=100,\n",
    "                          marker_color='black', opacity=0.8))\n",
    "fig.update_layout(title='$\\mbox{Апостериорное распределение } x$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  #xaxis_range=[0, 10],\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)                  \n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch5_lognorm_postdist_x.png\", scale=2)\n",
    "#Апостериорное распределение x близко исходному распределению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcfa8c",
   "metadata": {},
   "source": [
    "Для большей ожидаемой выручки на платящего нужно сравнивать группы по $E[x]=\\exp(\\mu + s^2/2)$. Достаточно сравнивать $\\mu + s^2/2$. Распределение этой величины нормальное $Norm(\\mu + s^2/2 | \\mu_N, \\sigma_N)$. В примере задаются 2 логнормальных распределения: одно с параметрами `s, mu`, во втором `mu` на 5\\% больше. Генерируется `nsample` точек. Строятся апостериорные распределения. Вероятность $P(E[x]_B > E[x]_A)$ ожидаемой выручки на пользователя группы Б больше А в данном случае близка 1. На первом графике приведены исходные распределения и их точные средние. На втором - распределения $Norm(\\mu + s^2/2 | \\mu_N, \\sigma_N)$ в группах. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c38b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "nsample = 3000\n",
    "npostsamp = 50000\n",
    "\n",
    "A, B = {}, {}\n",
    "s = 1\n",
    "mu = 2\n",
    "A['dist_pars'] = {'s': s, 'scale': np.exp(mu)}\n",
    "B['dist_pars'] = {'s': s, 'scale': np.exp(mu * 1.05)}\n",
    "for g in [A, B]:\n",
    "    g['exact_dist'] = stats.lognorm(s=g['dist_pars']['s'], scale=g['dist_pars']['scale'])\n",
    "    g['data'] = g['exact_dist'].rvs(nsample)\n",
    "    g['post_pars'] = initial_params_lognormal(mu=np.log(g['data'])[0], sigma=np.std(np.log(g['data'])), sx=np.std(np.log(g['data'])))\n",
    "    g['post_pars'] = posterior_params_lognormal(g['data'][1:], g['post_pars'])\n",
    "    g['post_ln_means_dist'] = posterior_ln_mean_dist_lognormal(g['post_pars'])\n",
    "    \n",
    "x = np.linspace(0, 30, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=A['exact_dist'].pdf(x), line_color='black', opacity=0.2, name='Исходное A'))\n",
    "fig.add_trace(go.Scatter(x=x, y=B['exact_dist'].pdf(x), line_color='black', name='Исходное Б'))\n",
    "fig.add_trace(go.Scatter(x=[A['exact_dist'].mean(), A['exact_dist'].mean()], y=[0, max(A['exact_dist'].pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='red', opacity=0.2, name='Точное среднее A'))\n",
    "fig.add_trace(go.Scatter(x=[B['exact_dist'].mean(), B['exact_dist'].mean()], y=[0, max(B['exact_dist'].pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='red', name='Точное среднее Б'))\n",
    "fig.update_layout(title='Исходные распределения',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch5_lognorm_cmp_orig.png\", scale=2)\n",
    "#Исходные распределения и точные средние.\n",
    "\n",
    "x = np.linspace(0, 3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=A['post_ln_means_dist'].pdf(x), line_color='black', opacity=0.2, name='A'))\n",
    "fig.add_trace(go.Scatter(x=x, y=B['post_ln_means_dist'].pdf(x), line_color='black', name='Б'))\n",
    "fig.add_trace(go.Scatter(x=[np.log(A['exact_dist'].mean()), np.log(A['exact_dist'].mean())], y=[0, max(A['post_ln_means_dist'].pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='red', opacity=0.3, name='Логарифм точного среднего А'))\n",
    "fig.add_trace(go.Scatter(x=[np.log(B['exact_dist'].mean()), np.log(B['exact_dist'].mean())], y=[0, max(B['post_ln_means_dist'].pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='red', name='Логарифм точного среднего Б'))\n",
    "fig.update_layout(title='$\\mbox{Распределения } \\mu + s^2/2$',\n",
    "                  xaxis_title='$\\mu$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[2, 3],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch5_lognorm_cmp_means.png\", scale=2)\n",
    "#Распределения оценок логарифма среднего mu + s^2/2. Среднее Б больше А с вероятностью 1.\n",
    "\n",
    "print(f\"P(E[x]_B > E[x]_A): {prob_pb_gt_pa(A['post_ln_means_dist'], B['post_ln_means_dist'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411f12e",
   "metadata": {},
   "source": [
    "Доля правильно угаданных вариантов проверяется для выручки на пользователя $P_{пользователи}(x)$. В группе А задается конверсия $p$ и выручка на платящего $\\mu, s$. В группе Б параметры $p$ и $\\mu$ случайно выбираются в пределах $\\pm 5\\%$ от A. Параметры меняются независимо, на практике они чаще меняются согласованно в противоположные стороны. Группы сравниваются по большей средней выручке на пользователя $E_{пользователи}[x] = p \\exp(\\mu + s^2/2)$. Для оценки $p$ используется бета-распределение $P(p) = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)$, где $N$ - общее количество пользователей, $n_s$ - количество платящих. Выручка на платящего моделируется логнормальным распределением. Т.к. распределение $\\mu + s^2/2$ нормальное, распределение $\\exp(\\mu + s^2/2)$ логнормальное $P_{\\exp(\\mu + s^2/2)}(y) = Lognorm(y | \\mu_N + s^2/2, \\sigma_N^2)$. Распределение $p\\exp(\\mu + s^2/2)$ будет произведением бета- и логнормального распределений $P_{p\\exp(\\mu + s^2/2)} \\sim \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s) Lognorm(y ; \\mu_N + s^2/2, \\sigma_N^2)$. Данные в каждом эксперименте добавляются с шагом `n_samp_step`. Эксперимент останавливается при достижении вероятности среднего в одной группе больше другой `prob_stop` или при наборе `n_samp_max` точек. При малом `n_samp_step` доля правильно угаданных вариантов может быть ниже `prob_stop`, что можно объяснить неточностью модели и попаданием выбросов. При достаточно большом `n_samp_step` доля правильно угаданных вариантов соответствует ожидаемой `prob_stop`.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P_{пользователи}(x) & = \n",
    "\\begin{cases}\n",
    "1-p, \\, x = 0\n",
    "\\\\\n",
    "p P_{платящие}(x), \\, x > 0\n",
    "\\end{cases}\n",
    "= \n",
    "\\begin{cases}\n",
    "1-p, \\, x = 0\n",
    "\\\\\n",
    "p Lognorm(x | s, \\mu_N, \\sigma_N), \\, x > 0\n",
    "\\end{cases}\n",
    "\\\\\n",
    "E_{пользователи}[x] & = p e^{\\mu + s^2/2}\n",
    "\\\\\n",
    "P(p) & = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s),\n",
    "\\\\\n",
    "P_{\\exp(\\mu + s^2/2)}(y) & = Lognorm(y | \\mu_N + s^2/2, \\sigma_N^2)\n",
    "\\\\\n",
    "P_{p\\exp(\\mu + s^2/2)} & \\sim \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s) Lognorm(y ; \\mu_N + s^2/2, \\sigma_N^2)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba57502",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConjugateRevPerUserParams = namedtuple('ConjugateRevPerUserParams', 'a b mu sigma sx')\n",
    "\n",
    "def posterior_params_rev_per_user(data):\n",
    "    d_paying = data[data != 0]\n",
    "    d_paying_total = len(d_paying)\n",
    "    d_total = len(data)\n",
    "    a, b = posterior_params_binom(ns=d_paying_total, ntotal=d_total)\n",
    "    post_pars = initial_params_lognormal(mu=np.log(d_paying)[0], sigma=np.std(np.log(d_paying)), sx=np.std(np.log(d_paying)))\n",
    "    post_pars = posterior_params_lognormal(d_paying[1:], post_pars)\n",
    "    return ConjugateRevPerUserParams(a=a, b=b, mu=post_pars.mu, sigma=post_pars.sigma, sx=post_pars.sx)\n",
    "\n",
    "def posterior_params_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns\n",
    "    return a, b\n",
    "\n",
    "def rev_per_user_p_dist(params):\n",
    "    return stats.beta(a=params.a, b=params.b)\n",
    "\n",
    "def posterior_mean_rev_per_user_rvs(params, nsamples=100_000):\n",
    "    p_dist = rev_per_user_p_dist(params)\n",
    "    ps = p_dist.rvs(size=nsamples)\n",
    "    means_dist = posterior_mean_dist_lognormal(params)\n",
    "    means = means_dist.rvs(nsamples)\n",
    "    return ps * means\n",
    "\n",
    "def exact_rev_per_user_rvs(p, mu, s, nsamples):\n",
    "    conv = stats.bernoulli.rvs(p=p, size=nsamples)\n",
    "    rev = stats.lognorm.rvs(s=s, scale=np.exp(mu), size=nsamples)\n",
    "    return conv * rev\n",
    "\n",
    "def prob_pb_gt_pa_samples(post_samp_A, post_samp_B):\n",
    "    if len(post_samp_A) != len(post_samp_B):\n",
    "        return None\n",
    "    b_gt_a = np.sum(post_samp_B > post_samp_A)\n",
    "    return b_gt_a / len(post_samp_A)\n",
    "\n",
    "nexps = 100\n",
    "prob_stop = 0.95\n",
    "n_samp_max = 3_000_000\n",
    "n_samp_step = 30000\n",
    "n_post_samp = 50000\n",
    "\n",
    "A = {'p': 0.1, 'mu': 2, 's': 1}\n",
    "\n",
    "cmp = pd.DataFrame(columns=['A_pars', 'B_pars', 'A_mean', 'B_mean', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best'])\n",
    "cmp['A_pars'] = [A] * nexps\n",
    "cmp['B_pars'] = cmp['A_pars'].apply(lambda x: {'p': x['p'] * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1)), 's': x['s'], 'mu': x['mu'] * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1))})\n",
    "cmp['A_mean'] = cmp['A_pars'].apply(lambda x: x['p'] * stats.lognorm(s=x['s'], scale=np.exp(x['mu'])).mean())\n",
    "cmp['B_mean'] = cmp['B_pars'].apply(lambda x: x['p'] * stats.lognorm(s=x['s'], scale=np.exp(x['mu'])).mean())\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B_mean'] > r['A_mean'] else 'A', axis=1)\n",
    "\n",
    "for i in range(nexps):\n",
    "    A_pars = cmp.at[i, 'A_pars']\n",
    "    B_pars = cmp.at[i, 'B_pars']\n",
    "    n_samp_total = 0\n",
    "    dA = np.array([])\n",
    "    dB = np.array([])\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA = np.append(dA, exact_rev_per_user_rvs(p=A_pars['p'], mu=A_pars['mu'], s=A_pars['s'], nsamples=n_samp_step))\n",
    "        dB = np.append(dB, exact_rev_per_user_rvs(p=B_pars['p'], mu=B_pars['mu'], s=B_pars['s'], nsamples=n_samp_step))\n",
    "        n_samp_total += n_samp_step\n",
    "        post_pars_A = posterior_params_rev_per_user(dA)\n",
    "        post_pars_B = posterior_params_rev_per_user(dB)\n",
    "        post_samp_A = posterior_mean_rev_per_user_rvs(post_pars_A)\n",
    "        post_samp_B = posterior_mean_rev_per_user_rvs(post_pars_B)\n",
    "        pb_gt_pa = prob_pb_gt_pa_samples(post_samp_A, post_samp_B)\n",
    "        best_gr = 'B' if pb_gt_pa >= prob_stop else 'A' if (1 - pb_gt_pa) >= prob_stop else None\n",
    "        if best_gr:\n",
    "            cmp.at[i, 'A_exp'] = post_samp_A.mean()\n",
    "            cmp.at[i, 'B_exp'] = post_samp_B.mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best'] = pb_gt_pa\n",
    "            break\n",
    "    print(f'done {i}: n_samp {n_samp_total}, best_group {best_gr}, P(b>a) {pb_gt_pa}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(10))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346681e",
   "metadata": {},
   "source": [
    "# Заказы на посетителя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c3c5a",
   "metadata": {},
   "source": [
    "Посетитель может сделать несколько заказов или не сделать ни одного. Для распределения количества заказов посетителя $P_{заказы}(n)$, $n \\in 0, 1, 2, \\dots$ можно ожидать дискретный аналог лог-нормального или степенное распределение вроде распределения Ципфа $P(n ; s) \\propto n^{-s}$ [[ZipfDist](https://en.wikipedia.org/wiki/Zipf%27s_law#Formal_definition), [SciPyZipfian](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.zipfian.html), [SciPyZipf](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.zipf.html)]. Важно точно промоделировать вероятности небольшого количества заказов. Распределение Ципфа в качестве функции правдоподобия может этого не позволить. Более гибкой моделью будет набор вероятностей $p_i$ сделать $i$ заказов. Пусть максимальное количество заказов $N$ ограничено, $n_i$ - количество пользователей с $i=0, 1, 2, \\dots, N$ заказами. Функция правдоподобия задается мультиномиальным распределением $P(\\mathcal{D} | \\mathcal{H}) = Mult(n_0, \\dots, n_N | p_0, \\dots, p_N)$ [[MultiDist](https://en.wikipedia.org/wiki/Multinomial_distribution), [SciPyMult](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multinomial.html)]. Сопряженным априорным распределением будет распределение Дирихле $P(\\mathcal{H}) = Dir \\left( p_{0}, \\dots, p_{N}; \\alpha_{0}, \\dots, \\alpha_{N} \\right)$ [[DirDist](https://en.wikipedia.org/wiki/Dirichlet_distribution), [SciPyDir](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.dirichlet.html)]. В апостериорном распределении обновленные параметры $\\alpha_i + n_i$. Маржинальными распределениями каждого $p_i$ будут бета-распределения, что согласуется с интерпретацией $p_i$ как конверсией в $i$ заказов.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(\\mathcal{D} | \\mathcal{H}) & = Mult(n_0, \\dots, n_N | p_0, \\dots, p_N) = \\frac{(n_0 + \\dots + n_N)!}{n_{0}! \\dots n_{N}!} p_{0}^{n_{0}} \\dots p_{N}^{n_{N}} \n",
    "\\\\\n",
    "P(\\mathcal{H}) & = \n",
    "Dir \\left( p_{0}, \\dots, p_{N}; \\alpha_{0}, \\dots, \\alpha_{N} \\right) = \n",
    "\\dfrac{1}{B( \\alpha_{0}, \\dots, \\alpha_{N} )} \\prod_{i=0}^{N} p_{i}^{\\alpha_{i}-1},\n",
    "\\qquad\n",
    "\\sum_{i=0}^{N} p_i = 1,\n",
    "\\qquad\n",
    "p_i \\in [0, 1], \n",
    "\\qquad\n",
    "B(\\alpha_{0}, \\dots, \\alpha_{N}) = \n",
    "\\frac{\\prod \\limits_{i=0}^{N} \\Gamma( \\alpha_{i} )}\n",
    "{\\Gamma \\left( \\sum \\limits_{i=0}^{N} \\alpha_{i} \\right)}\n",
    "\\\\\n",
    "P(\\mathcal{H} | \\mathcal{D}) \n",
    "& \\propto Mult(n_0, \\dots, n_N | p_0, \\dots, p_N) Dir \\left( p_{0}, \\dots, p_{N}; \\alpha_{0}, \\dots, \\alpha_{N} \\right)\n",
    "\\\\\n",
    "& \\propto\n",
    "p_{0}^{n_{0}} \\dots p_{N}^{n_{N}} \n",
    "\\prod _{i=0}^{N} p_{i}^{\\alpha_{i}-1}\n",
    "\\\\\n",
    "& \\propto\n",
    "\\prod_{i=0}^{N} p_{i}^{n_{i} + \\alpha_{i} - 1}\n",
    "\\\\\n",
    "& =\n",
    "Dir \\left( p_{0}, \\dots, p_{N}; \\alpha_{0} + n_0, \\dots, \\alpha_{N} + n_N \\right)\n",
    "\\\\\n",
    "P(p_i | \\mathcal{D} ) & = \n",
    "\\int dp_0 \\dots dp_{i-1}dp_{i+i} \\dots dp_N P(\\mathcal{H} | \\mathcal{D}) \n",
    "=\n",
    "Beta( p_i; \\alpha_i + n_i, \\sum_{k=0}^{N} (\\alpha_k + n_k) - \\alpha_i - n_i )\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73e2ef",
   "metadata": {},
   "source": [
    "Для примера оценки параметров задается распределение Ципфа с параметрами `s, Nmax`. Из него делается выборка, по выборке строится апострериорное распределение. Также считаются распределения конверсий в $i$ заказов $p_i$. На графике приведены исходное распределение, выборка, апостериорное предиктивное распределение $x$, оценки и 95\\%-интервалы $p_i$. Для большей части $i$ точные значения лежат внутри интервалов $p_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5714d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_params_dir(N):\n",
    "    return np.ones(N)\n",
    "\n",
    "def posterior_params_dir(data, initial_pars):\n",
    "    u, c = np.unique(data, return_counts=True)\n",
    "    post_pars = np.copy(initial_pars)\n",
    "    for k, v in zip(u, c):\n",
    "        post_pars[k] = post_pars[k] + v\n",
    "    return post_pars\n",
    "\n",
    "def posterior_dist_dir(params):\n",
    "    return stats.dirichlet(alpha=params)\n",
    "\n",
    "def posterior_nords_dir_rvs(params, nsamp):\n",
    "    nords = np.empty(nsamp)\n",
    "    d = posterior_dist_dir(params)\n",
    "    probs = d.rvs(size=nsamp)\n",
    "    for i, p in enumerate(probs):\n",
    "        nords[i] = np.argmax(stats.multinomial.rvs(n=1, p=p))\n",
    "    return nords\n",
    "\n",
    "def marginal_pi_dist_dir(i, params):\n",
    "    return stats.beta(a=params[i], b=np.sum(params) - params[i])\n",
    "\n",
    "def posterior_pi_mean_95pdi(i, params):\n",
    "    p = marginal_pi_dist_dir(i, params)\n",
    "    m = p.mean()\n",
    "    lower = p.ppf(0.025)\n",
    "    upper = p.ppf(0.975)\n",
    "    return m, lower, upper\n",
    "\n",
    "Nmax = 30\n",
    "s = 1.5\n",
    "nsample = 1000\n",
    "\n",
    "Npars = Nmax + 1\n",
    "exact_dist = stats.zipfian(a=s, n=Npars, loc=-1)\n",
    "data = exact_dist.rvs(nsample)\n",
    "pars = initial_params_dir(Npars)\n",
    "pars = posterior_params_dir(data, pars)\n",
    "post_samp = posterior_nords_dir_rvs(pars, 100000)\n",
    "pi = [posterior_pi_mean_95pdi(i, pars) for i in range(Npars)]\n",
    "\n",
    "x = np.arange(0, Npars+1)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pmf(x), name='Точное распределение Ципфа', \n",
    "                         line_color='black'))\n",
    "fig.add_trace(go.Histogram(x=data, histnorm='probability', name='Выборка', nbinsx=round(Nmax*2),\n",
    "                         marker_color='black'))\n",
    "fig.add_trace(go.Histogram(x=post_samp, histnorm='probability', name='$\\mbox{Апостериорные } n_i$', \n",
    "                         marker_color='black', opacity=0.2, nbinsx=round(Nmax*2)))\n",
    "fig.add_trace(go.Scatter(x=x, \n",
    "                         y=[p[0] for p in pi],\n",
    "                         error_y=dict(type='data', symmetric=False, array=[p[2] - p[0] for p in pi], arrayminus=[p[0] - p[1] for p in pi]), \n",
    "                         name='$\\mbox{Оценки } p_i$',\n",
    "                         mode='markers',\n",
    "                         line_color='red',\n",
    "                         opacity=0.8))\n",
    "fig.update_layout(title='Заказы на посетителя',\n",
    "                  xaxis_title='$Заказы$',\n",
    "                  yaxis_title='Вероятность',\n",
    "                  xaxis_range=[-1, Nmax+1],\n",
    "                  hovermode=\"x\",\n",
    "                  barmode=\"group\",\n",
    "                  height=550)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch6_postdist.png\", scale=2)\n",
    "#Распределение заказов на посетителя. Точные конверсии в i заказов лежат внутри оцененных интервалов. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8502fe",
   "metadata": {},
   "source": [
    "Распределение количества заказов позволяет оценить среднее количество заказов $E[n] = \\sum_{i=0}^N i p_i$, конверсию в заказ $1-p_0$, конверсию в 2 и более заказов $1-p_0-p_1$. Ниже приведен пример сравнения среднего количества заказов $E[n]$. Задается 2 распределения Ципфа, параметр `s` группы Б на 5\\% меньше группы А. На первом графике приведены точные распределения, точные средние и оценки $p_i$. Для большей части $i$ точные значения лежат внутри интервалов $p_i$. На втором графике приведено апостериорное распределение среднего количества заказов. Для выбранных параметров вероятность, что среднее группы Б выше А $P(E[n]_B > E[n]_A) = 90\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_nords_mean_rvs(params, nsample):\n",
    "    ns = np.arange(len(params))\n",
    "    probs = stats.dirichlet.rvs(alpha=params, size=nsample)\n",
    "    means = np.sum(ns * probs, axis=1)\n",
    "    return means\n",
    "\n",
    "def prob_pb_gt_pa_samples(post_samp_A, post_samp_B):\n",
    "    if len(post_samp_A) != len(post_samp_B):\n",
    "        return None\n",
    "    b_gt_a = np.sum(post_samp_B > post_samp_A)\n",
    "    return b_gt_a / len(post_samp_A)\n",
    "\n",
    "nsample = 3000\n",
    "Nmax = 30\n",
    "Npars = Nmax + 1\n",
    "\n",
    "post_samp_len = 100000\n",
    "A, B = {}, {}\n",
    "s = 1.5\n",
    "A['dist_pars'] = {'s': s}\n",
    "B['dist_pars'] = {'s': s * 0.95}\n",
    "for g in [A, B]:\n",
    "    g['exact_dist'] = stats.zipfian(a=g['dist_pars']['s'], n=Npars, loc=-1)\n",
    "    g['data'] = g['exact_dist'].rvs(nsample)\n",
    "    g['post_pars'] = initial_params_dir(Npars)\n",
    "    g['post_pars'] = posterior_params_dir(g['data'], g['post_pars'])\n",
    "    g['post_nords'] = posterior_nords_dir_rvs(g['post_pars'], post_samp_len)\n",
    "    g['post_means'] = posterior_nords_mean_rvs(g['post_pars'], post_samp_len)\n",
    "    g['pi'] = [posterior_pi_mean_95pdi(i, g['post_pars']) for i in range(Npars)]\n",
    "\n",
    "x = np.arange(0, Npars)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=x, y=A['exact_dist'].pmf(x), name='Точное распределение A',\n",
    "                        marker_color='black', opacity=0.2))\n",
    "fig.add_trace(go.Bar(x=x, y=B['exact_dist'].pmf(x), name='Точное распределение Б',\n",
    "                        marker_color='black', opacity=0.8))\n",
    "fig.add_trace(go.Scatter(x=[A['exact_dist'].mean(), A['exact_dist'].mean()], \n",
    "                         y=[0, np.max(A['exact_dist'].pmf(x))*1.1],\n",
    "                         name='Точное среднее A', \n",
    "                         mode='lines', line_dash='dash',\n",
    "                         line_color='black', opacity=0.3))\n",
    "fig.add_trace(go.Scatter(x=[B['exact_dist'].mean(), B['exact_dist'].mean()], \n",
    "                         y=[0, np.max(B['exact_dist'].pmf(x))*1.1],\n",
    "                         name='Точное среднее Б', \n",
    "                         mode='lines', line_dash='dash',\n",
    "                         line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=x - 0.1, \n",
    "                         y=[p[0] for p in A['pi']],\n",
    "                         error_y=dict(type='data', symmetric=False, array=[p[2] - p[0] for p in A['pi']], arrayminus=[p[0] - p[1] for p in A['pi']]), \n",
    "                         name='$p_i, \\mbox{ А}$',\n",
    "                         line_color='black', opacity=0.3,\n",
    "                         mode='markers'\n",
    "                    ))\n",
    "fig.add_trace(go.Scatter(x=x + 0.1, \n",
    "                         y=[p[0] for p in B['pi']],\n",
    "                         error_y=dict(type='data', symmetric=False, array=[p[2] - p[0] for p in B['pi']], arrayminus=[p[0] - p[1] for p in B['pi']]), \n",
    "                         name='$p_i, \\mbox{ Б}$',\n",
    "                         line_color='black',\n",
    "                         mode='markers'))\n",
    "fig.update_layout(title='Заказы на посетителя',\n",
    "                  xaxis_title='$Заказы$',\n",
    "                  yaxis_title='Вероятность',\n",
    "                  xaxis_range=[-1, Npars+1-20],\n",
    "                  hovermode=\"x\",\n",
    "                  barmode=\"group\",\n",
    "                  height=550)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch6_cmp_orig.png\", scale=2)\n",
    "#Точные распределения, точные средние количества заказов и оценки конверсий.\n",
    "\n",
    "x = np.arange(0, Npars)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[A['exact_dist'].mean(), A['exact_dist'].mean()], \n",
    "                         y=[0, np.max(A['exact_dist'].pmf(x))*1.1],\n",
    "                         name='Точное среднее A', \n",
    "                         mode='lines', line_dash='dash',\n",
    "                         line_color='black', opacity=0.3))\n",
    "fig.add_trace(go.Scatter(x=[B['exact_dist'].mean(), B['exact_dist'].mean()], \n",
    "                         y=[0, np.max(B['exact_dist'].pmf(x))*1.1],\n",
    "                         name='Точное среднее Б', \n",
    "                         mode='lines', line_dash='dash',\n",
    "                         line_color='black'))\n",
    "fig.add_trace(go.Histogram(x=A['post_means'], histnorm='probability', name='$E[n], \\mbox{ А}$', \n",
    "                           marker_color='black', opacity=0.3, nbinsx=round(Nmax*2)))\n",
    "fig.add_trace(go.Histogram(x=B['post_means'], histnorm='probability', name='$E[n], \\mbox{ Б}$', \n",
    "                           marker_color='black', nbinsx=round(Nmax*2)))\n",
    "fig.update_layout(title='Среднее количество заказов',\n",
    "                  xaxis_title='$Заказы$',\n",
    "                  yaxis_title='Вероятность',\n",
    "                  xaxis_range=[-1, Npars+1-20],\n",
    "                  hovermode=\"x\",\n",
    "                  barmode=\"group\",\n",
    "                  height=550)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch6_cmp_means.png\", scale=2)\n",
    "#Оценки среднего количества заказов. Среднее Б выше А с вероятностью 90%.\n",
    "\n",
    "print(f\"P(E[n]_B > E[n]_A): {prob_pb_gt_pa_samples(A['post_means'], B['post_means'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e72371d",
   "metadata": {},
   "source": [
    "Количество правильно угаданных \"лучших\" групп проверяется в `nexps` экспериментах. В группе A количество заказов на пользователя задается распределением Ципфа с параметром `s`, в группе Б параметр в пределах $\\pm 5\\%$ от A. Группы сравниваются по среднему количеству заказов. В экспериментах в выборки пошагово добавляется `n_samp_step` точек, считаются параметры апостериорных распределений и вероятность $P(E[n]_B > E[n]_A)$. Эксперимент останавливается при достижении вероятности среднего одной из групп больше другой `prob_stop` или наборе максимального количества точек `n_samp_max`. Доля правильно угаданных групп 0.94 близка ожидаемой `prob_stop = 0.95`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best'])\n",
    "\n",
    "s = 1.5\n",
    "Nmax = 30\n",
    "Npars = Nmax + 1\n",
    "nexps = 100\n",
    "cmp['A'] = [s] * nexps\n",
    "cmp['B'] = s * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "\n",
    "n_samp_max = 200000\n",
    "n_samp_step = 5000\n",
    "\n",
    "prob_stop = 0.95\n",
    "for i in range(nexps):\n",
    "    s_a = cmp.at[i, 'A']\n",
    "    s_b = cmp.at[i, 'B']\n",
    "    exact_dist_a = stats.zipfian(a=s_a, n=Npars, loc=-1)\n",
    "    exact_dist_b = stats.zipfian(a=s_b, n=Npars, loc=-1)\n",
    "    cmp.at[i, 'best_exact'] = 'A' if exact_dist_a.mean() > exact_dist_b.mean() else 'B'\n",
    "    n_samp_total = 0\n",
    "    pars_a = initial_params_dir(Npars)\n",
    "    pars_b = initial_params_dir(Npars)\n",
    "    while n_samp_total < n_samp_max:\n",
    "        data_a = exact_dist_a.rvs(n_samp_step)\n",
    "        data_b = exact_dist_b.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        pars_a = posterior_params_dir(data_a, pars_a)\n",
    "        pars_b = posterior_params_dir(data_b, pars_b)\n",
    "        post_samp_len = 10000\n",
    "        post_means_a = posterior_nords_mean_rvs(pars_a, post_samp_len)\n",
    "        post_means_b = posterior_nords_mean_rvs(pars_b, post_samp_len)\n",
    "        pb_gt_pa = prob_pb_gt_pa_samples(post_means_a, post_means_b)\n",
    "        best_gr = 'B' if pb_gt_pa >= prob_stop else 'A' if (1 - pb_gt_pa) >= prob_stop else None\n",
    "        if best_gr:\n",
    "            cmp.at[i, 'A_exp'] = post_means_a.mean()\n",
    "            cmp.at[i, 'B_exp'] = post_means_b.mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best'] = pb_gt_pa\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P(B>A) {pb_gt_pa}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(10))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03324297",
   "metadata": {},
   "source": [
    "# Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed684a7d",
   "metadata": {},
   "source": [
    "Байесовское моделирование применено к сравнению конверсий, средних с помощью центральной предельной теоремы, выручки на пользователя, заказов на посетителя. Для каждой метрики предложено модельное распределение. Параметры моделей задаются сопряженными априорными распределениями, что позволяет строить апостериорные распределения аналитически. Показана оценка параметров по выборке, сравнение двух групп, проверка доли правильно угаданных \"лучших\" групп в серии экспериментов. Доля соответствует ожидаемой. Валидация моделей не обсуждалась - на практике необходимо проверять применимость моделей к конкретной ситуации. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69bfd22",
   "metadata": {},
   "source": [
    "# Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc114b95",
   "metadata": {},
   "source": [
    "[Apx] - [Bayesian A/B-Testing, Appendices](https://github.com/andrewbrdk/Bayesian-AB-Testing/blob/main/appendices), *GitHub*.  \n",
    "[BaseFal] - [Base Rate Fallacy](https://en.wikipedia.org/wiki/Base_rate_fallacy), *Wikipedia.*  \n",
    "[BernProc] - [Bernoulli Process](https://en.wikipedia.org/wiki/Bernoulli_process), *Wikipedia.*  \n",
    "[BerryEsseenTheorem] - [Berry-Esseen Theorem](https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem), *Wikipedia.*   \n",
    "[BetaDist] - [Beta Distribution](https://en.wikipedia.org/wiki/Beta_distribution), *Wikipedia.*     \n",
    "[BinomDist] - [Binomial Distribution](https://en.wikipedia.org/wiki/Binomial_distribution), *Wikipedia.*  \n",
    "[CausalDAG] - [Causal Graph](https://en.wikipedia.org/wiki/Causal_graph), *Wikipedia.*    \n",
    "[CDF] - [Cumulative Distribution Function](https://en.wikipedia.org/wiki/Cumulative_distribution_function), *Wikipedia.*  \n",
    "[CLT] - [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem), *Wikipedia.*    \n",
    "[ConjPrior] - [Conjugate Prior](https://en.wikipedia.org/wiki/Conjugate_prior), *Wikipedia.*   \n",
    "[DirDist] - [Dirichlet Distribution](https://en.wikipedia.org/wiki/Dirichlet_distribution), *Wikipedia.*    \n",
    "[GammaDist] - [Gamma Distribution](https://en.wikipedia.org/wiki/Gamma_distribution), *Wikipedia.*     \n",
    "[LognormDist] - [Log-normal Distribution](https://en.wikipedia.org/wiki/Log-normal_distribution), *Wikipedia.*    \n",
    "[LomaxDist] - [Lomax Distribution](https://en.wikipedia.org/wiki/Lomax_distribution), *Wikipedia.*     \n",
    "[MicroExp] - R. Kohavi et al, [Online Experimentation at Microsoft](https://www.microsoft.com/en-us/research/publication/online-experimentation-at-microsoft/).  \n",
    "[MultiDist] - [Multinomial Distribution](https://en.wikipedia.org/wiki/Multinomial_distribution), *Wikipedia.*    \n",
    "[NormDist] - [Normal Distribution](https://en.wikipedia.org/wiki/Normal_distribution), *Wikipedia.*  \n",
    "[NormSum] - [Sum of Normally Distributed Random Variables](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables), *Wikipedia.*  \n",
    "[ParetoDist] - [Pareto Distribution](https://en.wikipedia.org/wiki/Pareto_distribution), *Wikipedia.*     \n",
    "[ProbConv] - [Convolution of Probability Distributions](https://en.wikipedia.org/wiki/Convolution_of_probability_distributions), *Wikipedia.*    \n",
    "[RandVarsConv] - [Convergence of Random Variables](https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_distribution), *Wikipedia.*   \n",
    "[SGBS] - B. Lambert, A Student’s Guide to Bayesian Statistics ([Textbook](https://www.amazon.co.uk/Students-Guide-Bayesian-Statistics/dp/1473916364), [Student Resources](https://study.sagepub.com/lambert)).     \n",
    "[SR] - R. McElreath, Statistical Rethinking: A Bayesian Course with Examples in R and STAN ([Textbook](https://www.routledge.com/Statistical-Rethinking-A-Bayesian-Course-with-Examples-in-R-and-STAN/McElreath/p/book/9780367139919), [Video Lectures](https://www.youtube.com/playlist?list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus), [Course Materials](https://github.com/rmcelreath/stat_rethinking_2024)).   \n",
    "[SciPyBern] - [scipy.stats.bernoulli](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bernoulli.html), *SciPy Reference.*  \n",
    "[SciPyBeta] - [scipy.stats.beta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html), *SciPy Reference.*   \n",
    "[SciPyBinom] - [scipy.stats.binom](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html), *SciPy Reference.*   \n",
    "[SciPyDir] - [scipy.stats.dirichlet](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.dirichlet.html), *SciPy Reference.*  \n",
    "[SciPyGamma] - [scipy.stats.gamma](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html), *SciPy Reference.*     \n",
    "[SciPyLognorm] - [scipy.stats.lognorm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html), *SciPy Reference.*      \n",
    "[SciPyLomax] - [scipy.stats.lomax](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lomax.html), *SciPy Reference.*       \n",
    "[SciPyMult] - [scipy.stats.multinomial](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multinomial.html), *SciPy Reference.*   \n",
    "[SciPyNorm] - [scipy.stats.norm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html), *SciPy Reference.*   \n",
    "[SciPyPareto] - [scipy.stats.pareto](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pareto.html), *SciPy Reference.*    \n",
    "[SciPyZipf] - [scipy.stats.zipf](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.zipf.html), *SciPy Reference.*   \n",
    "[SciPyZipfian] - [scipy.stats.zipfian](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.zipfian.html), *SciPy Reference.*    \n",
    "[SubjProb] - [Probability Interpretations](https://en.wikipedia.org/wiki/Probability_interpretations#Subjectivism), *Wikipedia.*    \n",
    "[ZipfDist] - [Zipf's Law](https://en.wikipedia.org/wiki/Zipf%27s_law#Formal_definition), *Wikipedia.*   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b3a58-e085-4b9b-89ef-882575639ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
