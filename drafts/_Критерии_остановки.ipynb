{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee15c77",
   "metadata": {},
   "source": [
    "# Критерии остановки и оценка длительности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159af27",
   "metadata": {},
   "source": [
    "В предыдущих примерах эксперименты останавливались при достижении 95% вероятности целевой метрики одной группы больше других. Порог 95% произволен - возможны 80%, 99%, другие значения. Удобен объективный критерий остановки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65bc3f",
   "metadata": {},
   "source": [
    "Качественные закономерности следующие. Продолжение эксперимента дает новые данные и уточняет метрики. При этом часть пользователей попадает в неоптимальную группу, что ведет к потерям. Поддержка эксперимента также связана с потерями из-за усложнения разработки, хотя этот эффект тяжело оценить. Ценность новых данных убывает по мере их накопления - первые 100 точек сильнее влияют на решение, чем дополнительные 100 точек к 10 млн. Наконец, решение об остановке должно учитывать последствия выбора. Чем выше цена ошибки, тем большая нужна уверенность. Например, для лекарств нужно убедиться в отсутствии побочных эффектов, поэтому порог вероятности при тестировании должен быть высоким. В веб-сервисах выбранных вариант может продержатся год до следующего эксперимента.  \n",
    "  \n",
    "\n",
    "Таким образом, цена поддержания эксперимента постоянна, ценность новых данных падает. Эксперимент пора останавливать, когда ценность новых данных становится ниже их стоимости. Ценность данных должна учитывать последствия выбора."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d50668",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../figs/ab_data_value.png\" alt=\"ab_data_value\" width=\"600\"/>\n",
    "    \n",
    "<em>Цена поддержания эксперимента постоянна, ценность новых данных падает. Эксперимент пора останавливать при ценности новых данных ниже их стоимости. Ценность данных должна учитывать последствия выбора одного из вариантов. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574c98f",
   "metadata": {},
   "source": [
    "Реализация этих закономерностей зависит от конкретных метрик. Далее будут рассматриваться конверсии. Конверсии можно моделировать последовательностью случайных величин с двумя возможными исходами - успехом и неудачей. Для оценки вероятности успеха $p$ в серии $N$ испытаний с $n_s$ успехами правдоподобие удобно задавать биномиальным распределением $P(\\mathcal{D} | \\mathcal{H}) = \\mbox{Binom}(n_s, N | p)$, априорное распределение - бета-распределением $P(\\mathcal{H}) = \\mbox{Beta}(p; \\alpha, \\beta)$ с параметрами $\\alpha, \\beta$. Тогда апостериорная вероятность также будет бета-распределением с обновленными параметрами $P(\\mathcal{H} | \\mathcal{D}) = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)$. При достаточно большом количестве данных $N \\gg n_s \\gg \\alpha, \\beta$ бета-распределение близко нормальному $\\mbox{Beta}(x; \\alpha + n_s, \\beta + N - n_s) \\approx \\mbox{Norm}(x; \\mu, \\sigma^2), \\, \\mu = n_s / N, \\, \\sigma^2 = \\mu (1 - \\mu) / N$.\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H} | \\mathcal{D}) \\propto P(\\mathcal{D} | \\mathcal{H}) P(\\mathcal{H})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{D} | \\mathcal{H}) = P(n_s, N | p) = \\mbox{Binom}(n_s, N | p)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H}) = P(p) = \\mbox{Beta}(p; \\alpha, \\beta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H} | \\mathcal{D}) = P(p | n_s, N) = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "N \\gg n_s \\gg \\alpha, \\beta: \\quad\n",
    "\\mbox{Beta}(x; \\alpha + n_s, \\beta + N - n_s) \n",
    "\\approx \\mbox{Norm}(x; \\mu, \\sigma^2),\n",
    "\\quad\n",
    "\\mu = n_s / N, \n",
    "\\,\n",
    "\\sigma^2 = \\mu (1 - \\mu) / N\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{Binom}(n_s, N | p) = C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "\\qquad\n",
    "\\mbox{Beta}(x; \\alpha, \\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1 - x)^{\\beta-1}\n",
    "\\qquad\n",
    "\\mbox{Norm}(x ; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\tfrac{(x-\\mu)^2}{2 \\sigma^2} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a552c",
   "metadata": {},
   "source": [
    "Апостериорные распределения для двух групп показаны на графике ниже. Конверсия в одной группе $p_A = 10\\%$, в другой на 5% больше $p_B = 10.5\\%$. Из этих групп делается выборка 10000 точек. Апостериорные распределения построены по первой тысяче точек и по всем 10000. Видно, что распределения по 10000 точек уже. Это показывает общую тенденцию - по мере набора данных оценки конверсий уточняются, средние апостериорных распределений приближаются к точным средним, а распределения сужаются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aee051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = [1000, 9000]\n",
    "sa = stats.binom.rvs(p=pa, n=npoints)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints)\n",
    "npoints = np.cumsum(npoints)\n",
    "sa = np.cumsum(sa)\n",
    "sb = np.cumsum(sb)\n",
    "\n",
    "xaxis_min = 0.05\n",
    "xaxis_max = 0.17\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sa[-1], npoints[-1]).pdf(x), \n",
    "                         line_color='red', opacity=0.8, name=f'А, N={npoints[-1]}'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sa[0], npoints[0]).pdf(x), \n",
    "                         line_color='red', opacity=0.3, name=f'А, N={npoints[0]}'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sb[-1], npoints[-1]).pdf(x), \n",
    "                         line_color='blue', opacity=0.8, name=f'B, N={npoints[-1]}'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sb[0], npoints[0]).pdf(x), \n",
    "                         line_color='blue', opacity=0.3, name=f'B, N={npoints[0]}'))\n",
    "fig.update_layout(title='Апостериорные распределения',\n",
    "                  xaxis_title='$p$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad40479e",
   "metadata": {},
   "source": [
    "Для оценки эффекта и выбора лучшей группы нужно распределение разности конверсий $P_{p_B - p_A}$. Бета-распределения близки нормальным. Разность случайных величин с нормальным распределением также случайная величина с нормальным распределением. Среднее равно разности средних, диспресия - сумме дисперсий. Поэтому разность приближенно можно считать нормальным распределением $P_{p_B - p_A}(x) \\approx \\mbox{Norm}\\left(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2\\right)$. Вероятность конверсии группы Б больше А $P(p_B > p_A)$ равна вероятности разности $p_B - p_A$ больше 0 $P(p_B - p_A > 0)$. Можно посчитать с помощью функции распределения $1 - F_{p_B - p_A}(0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906dd7ba",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{gather}\n",
    "P_{p_A} = \\mbox{Beta}(x; \\alpha + n_{s_A}, \\beta + N_A - n_{s_A})\n",
    "\\approx \\mbox{Norm}(x; \\mu_A, \\sigma^2_A),\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B} = \\mbox{Beta}(x; \\alpha + n_{s_B}, \\beta + N_B - n_{s_B})\n",
    "\\approx \\mbox{Norm}(x; \\mu_B, \\sigma^2_B)\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B - p_A}(x) = \n",
    "\\int_{-\\infty}^{\\infty} dy P_{p_B}(y) P_{p_A}(y-x)\n",
    "\\approx \\mbox{Norm}\\left(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2\\right)\n",
    "\\\\\n",
    "\\\\\n",
    "P(p_B > p_A) = P(p_B - p_A > 0) = 1 - F_{p_B - p_A}(0)\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c225229",
   "metadata": {},
   "source": [
    "По мере набора данных средние в выборках будут приближаться к точным средним, а апостериорные распределения сужаются. То же для разности. Задано две группы, конверсия в одной $p_A = 10\\%$, в другой на 5% больше $p_B = 10.5\\%$. В этих группах набираются данные с шагом 1000 точек. На первом графике показаны апостериорные распределения при 1000 и 10000 точек в каждой группе. Видно, что распределения при большем количестве точек уже. На втором графике показаны средние и 95% области наибольшей плотности вероятности по мере набора N. По мере набора данных средние в выборках приближаются к точным средним, а 95% области наибольшей плотности вероятности сужаются. На третьем графике показа вероятность $P(p_B > p_A)$. Она растет по мере накопления данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e252b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "def posterior_binom_approx_95pdi(post_dist):\n",
    "    lower = post_dist.ppf(0.025)\n",
    "    upper = post_dist.ppf(0.975)\n",
    "    return lower, upper\n",
    "\n",
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = 1000\n",
    "nstep = 150\n",
    "sa = stats.binom.rvs(p=pa, n=npoints, size=nstep)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints, size=nstep)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['npoints'] = [npoints] * nstep\n",
    "df['sa_step'] = sa\n",
    "df['sb_step'] = sb\n",
    "df['N'] = df['npoints'].cumsum()\n",
    "df['sa'] = df['sa_step'].cumsum()\n",
    "df['sb'] = df['sb_step'].cumsum()\n",
    "df['pa'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).mean(), axis=1)\n",
    "df[['pa_lower', 'pa_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sa'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb'] = df.apply(lambda r: posterior_dist_binom(r['sb'], r['N']).mean(), axis=1)\n",
    "df[['pb_lower', 'pb_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sb'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb_gt_pa'] = df.apply(lambda r: prob_pb_gt_pa(posterior_dist_binom(r['sa'], r['N']), posterior_dist_binom(r['sb'], r['N']), post_samp=10_000), axis=1)\n",
    "df['diff_mu'] = df.apply(lambda r: r['pb'] - r['pa'], axis=1)\n",
    "df['diff_s'] = df.apply(lambda r: np.sqrt(posterior_dist_binom(r['sa'], r['N']).std()**2 + posterior_dist_binom(r['sb'], r['N']).std()**2), axis=1)\n",
    "df[['diff_lower', 'diff_upper']] = df.apply(lambda r: (r['diff_mu'] - 2*r['diff_s'], r['diff_mu'] + 2*r['diff_s']), axis=1, result_type=\"expand\")\n",
    "\n",
    "xaxis_min = -0.1\n",
    "xaxis_max = 0.1  \n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "for N, o in [(1000, 0.3), (10000, 1)]:\n",
    "    dist_a = posterior_dist_binom(df[df['N'] == N]['sa'], N)\n",
    "    dist_b = posterior_dist_binom(df[df['N'] == N]['sb'], N)\n",
    "    #fig.add_trace(go.Scatter(x=x, y=dist_a.pdf(x), line_color='red', opacity=o, name=f'А, N={N}'))\n",
    "    #fig.add_trace(go.Scatter(x=x, y=dist_b.pdf(x), line_color='blue', opacity=o, name=f'Б, N={N}'))\n",
    "    #\n",
    "    diff = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "    fig.add_trace(go.Scatter(x=x, y=diff.pdf(x), line_color='black', opacity=o, name=f'Diff, N={N}'))\n",
    "    fig.update_layout(title='$p_B - p_A$',\n",
    "                      xaxis_title='$p$',\n",
    "                      yaxis_title='Плотность вероятности',\n",
    "                      xaxis_range=[xaxis_min, xaxis_max],\n",
    "                      hovermode=\"x\",\n",
    "                      height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pa'], name='$p_A$',\n",
    "                         line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pa_upper']) + list(reversed(df['pa_lower'])),\n",
    "                         fill=\"toself\", name='$p_A, \\, \\mbox{95% PDI}$', marker_color='red', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb'], name='$p_B$',\n",
    "                         line_color='blue'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pb_upper']) + list(reversed(df['pb_lower'])),\n",
    "                         fill=\"toself\", name='$p_B, \\, \\mbox{95% PDI}$', marker_color='blue', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_mu'], name='$p_B-p_A$',\n",
    "                         line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['diff_lower']) + list(reversed(df['diff_upper'])),\n",
    "                         fill=\"toself\", name='$p_B - p_A, \\, \\mbox{95% PDI}$', marker_color='black', opacity=0.2))\n",
    "fig.update_layout(title='$p_A, p_B$',\n",
    "                  yaxis_tickformat = ',.1%',\n",
    "                  xaxis_title='N',\n",
    "                  height=600)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'],\n",
    "                         line_color='black', name='$p_B > p_A$'))\n",
    "fig.update_layout(title='$P(p_B > p_A)$',\n",
    "                  xaxis_title='$N$',\n",
    "                  #yaxis_title='sigma',\n",
    "                  yaxis_range=[0, 1],\n",
    "                  #xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db11181",
   "metadata": {},
   "source": [
    "Дисперсия бета-распределения убывает пропорционально $1/N$. Это видно как из точного выражения для дисперсии бета-распределения, так и из приближения нормальным распределением. Т.к. дисперсия разности равна сумме дисперсий $p_A, p_B$, для нее эта зависимость так же справедлива. \n",
    "\n",
    "$$\n",
    "\\mbox{Var}(\\mbox{Beta}(x; \\alpha, \\beta)) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}\n",
    "\\\\\n",
    "\\\\\n",
    "N \\gg n_s \\gg \\alpha, \\beta:\n",
    "\\quad\n",
    "\\mbox{Var}(\\mbox{Beta}(x; \\alpha + n_s, \\beta + N - n_s)) \\approx \\frac{n_s (N - n_s)}{N^3} \n",
    "= \\frac{\\mu (1 - \\mu)}{N},\n",
    "\\quad\n",
    "\\mu = n_s / N\n",
    "\\\\\n",
    "\\mbox{Var}(P_{p_A}), \\mbox{Var}(P_{p_B}), \\mbox{Var}(P_{{p_B}-{p_A}}) \\sim 1/N\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a71f148",
   "metadata": {},
   "source": [
    "Для графика ниже заново сгенерированы 150 тыс. точек в каждой группе с шагом 1000 точек. Показано стандартное отклонение разности по мере набора точек и величина $\\sigma_0 \\sqrt{N_0/N}$, где $\\sigma_0$ и $N_0$ - стандартное отклонение и количество точек на первом шаге набора данных. Величины близки.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = 1000\n",
    "nstep = 150\n",
    "sa = stats.binom.rvs(p=pa, n=npoints, size=nstep)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints, size=nstep)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['npoints'] = [npoints] * nstep\n",
    "df['sa_step'] = sa\n",
    "df['sb_step'] = sb\n",
    "df['N'] = df['npoints'].cumsum()\n",
    "df['sa'] = df['sa_step'].cumsum()\n",
    "df['sb'] = df['sb_step'].cumsum()\n",
    "df['pa'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).mean(), axis=1)\n",
    "df['pb'] = df.apply(lambda r: posterior_dist_binom(r['sb'], r['N']).mean(), axis=1)\n",
    "df['diff_mu'] = df.apply(lambda r: r['pb'] - r['pa'], axis=1)\n",
    "df['diff_s'] = df.apply(lambda r: np.sqrt(posterior_dist_binom(r['sa'], r['N']).std()**2 + posterior_dist_binom(r['sb'], r['N']).std()**2), axis=1)\n",
    "df['diff_var'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).std()**2 + posterior_dist_binom(r['sb'], r['N']).std()**2, axis=1)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s'],\n",
    "                         line_color='black', name='$\\sigma_{p_B - p_A}$'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s'][0] * np.sqrt(df['N'][0] / df['N']), \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='sigma0 * sqrt(N0/N)'))\n",
    "# fig.add_trace(go.Scatter(x=df['N'], y=df['diff_var'],\n",
    "#                          line_color='black', name='Var'))\n",
    "# fig.add_trace(go.Scatter(x=df['N'], y=df['diff_var'][0] * df['N'][0] / df['N'], \n",
    "#                          line_color='black', mode='lines', line_dash='dash', name='sigma0 * sqrt(N0/N)'))\n",
    "fig.update_layout(title='Стандартное отклонение pB - pA',\n",
    "                  xaxis_title='$N$',\n",
    "                  #yaxis_title='sigma',\n",
    "                  #xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852a486b",
   "metadata": {},
   "source": [
    "Таким образом, по мере набора данных средние в выборках стремятся к точному среднему, разность средних стремится к точной разности. Дисперсии распределений и разности сужаются пропорционально $1/N$. Растет уверенность в лучшей группе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51db89e",
   "metadata": {},
   "source": [
    "Эксперимент имеет смысл останавливать при максимальном ожидаемом выигрыше. Ожидаемый выигрыш при выобре одной из групп пропорционален ожидаемому значению разности целевой метрики в группах. Хотя по мере набора данных разность сходится к точному значению, сказать как именно она будет меняться по имеющимся данным нельзя. Если в каждой группе уже собрано $N$ точек, при добавлении еще $\\Delta N$ ожидаемое значение можно считать близким к текущей оценке $E[p_B-p_A | N + \\Delta N] \\approx E[p_B -p_A | N]$. Если ожидаемая разность сильно не меняется, ожидаемый выигрыш тоже не меняется. Т.к. дисперсия будет убывать, распределение станет немного уже при том же среднем. При одинаковых средних у более узкого распределения ниже возможные потери, чем у более широкого, что предпочтительнее. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56d7c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52b0fa9e",
   "metadata": {},
   "source": [
    "На графике два распределения разности с одинаковыми средними. Ожидаемые потери - среднее по части распределения левее нуля. У более узкого распределения ожидаемые потери меньше, чем у широкого при том же среднем. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c166e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "mu = pb - pa\n",
    "N = 5000\n",
    "s = np.sqrt((pb*(1-pb)/N) + (pa*(1-pa)/N))\n",
    "d = stats.norm(loc=mu, scale=s)\n",
    "fig.add_trace(go.Scatter(x=x, y=d.pdf(x), \n",
    "                         line_color='black', name=f'N={N}'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(d.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=d.pdf(x[x<0]), fill='tozeroy',\n",
    "                         line_color='black', opacity=0.3, name='loss', showlegend=False))\n",
    "N = 1000\n",
    "s = np.sqrt((pb*(1-pb)/N) + (pa*(1-pa)/N))\n",
    "d = stats.norm(loc=mu, scale=s)\n",
    "fig.add_trace(go.Scatter(x=x, y=d.pdf(x), \n",
    "                         line_color='black', opacity=0.3, name=f'N={N}'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=d.pdf(x[x<0]), fill='tozeroy',\n",
    "                         line_color='black', opacity=0.3, name='loss'))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.05, 0.05],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e542f",
   "metadata": {},
   "source": [
    "Эксперимент пора останавливать, если разность ожидаемых потерь на следующем шаге $E[L(p_B - p_A | N + \\Delta N)]$ и ожидаемых потерь при немедленной остановке $E[L(p_B - p_A | N)]$ меньше стоимости данных $\\mbox{Cost}(\\Delta N)$. Ожидаемые потери должны учитывать количество будущих пользователей $M$, на которых повлияют изменения, и LTV. Стоимость данных - ожидаемые потери из-за попадания части пользователей в худшую группу. Они определяются как потери конверсии на LTV на долю пользователей в худшей группе $w_A$ на количество пользователей $\\Delta N$. \n",
    "\n",
    "LTV -> $LTV_{B-A}$ или $\\Delta LTV$ - разница LTV в группах \n",
    "\n",
    "$$\n",
    "E[L(p_B - p_A | N + \\Delta N)] - E[L(p_B - p_A | N)] < \\mbox{Cost}(\\Delta N)\n",
    "\\\\\n",
    "\\begin{split}\n",
    "E[L(p_B - p_A | N)] & = LTV \\cdot M \\int_{-\\infty}^0 x P_{p_B - p_A}(x) dx\n",
    "\\\\\n",
    "& = LTV \\cdot M \\int_{-\\infty}^0 x Norm(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2 | N) dx\n",
    "\\\\\n",
    "& = LTV \\cdot M \\cdot I(N)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mbox{Cost}(\\Delta N) \\approx LTV \\cdot w_A \\Delta N \\cdot E[P_{p_B - p_A}]  = LTV \\cdot w_A \\Delta N \\cdot (\\mu_B - \\mu_A)\n",
    "$$\n",
    "\n",
    "$$\n",
    "LTV \\cdot M (I(N+\\Delta N) - I(N)) < LTV \\cdot w_A (\\mu_B - \\mu_A) \\Delta N\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{I(N+\\Delta N) - I(N)}{\\Delta N} < \\frac{w_A}{M} (\\mu_B - \\mu_A)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e392f",
   "metadata": {},
   "source": [
    "Разность можно приближенно заменить производной. Ожидаемые потери аналитически \n",
    "\n",
    "$$\n",
    "\\frac{d I(N)}{dN} < \\frac{w_A}{M} (\\mu_B - \\mu_A)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "I(N) &= \\int_{-\\infty}^{0} x \\mathcal N(x; m, \\sigma^2) dx\n",
    "  = \\int_{-\\infty}^{0} \\big(x + m - m\\big) \\mathcal N(x;m,\\sigma^2) dx \n",
    "  \\\\\n",
    "  & = m \\int_{-\\infty}^{0} \\mathcal N(x;m,\\sigma^2) dx + \\int_{-\\infty}^{0} (x-m) \\mathcal N(x;m,\\sigma^2) dx \n",
    "  \\\\\n",
    "  &= m \\Phi \\left(\\tfrac{0-m}{\\sigma}\\right) + \\sigma \\int_{-\\infty}^{(0-m)/\\sigma} t \\varphi(t) dt \n",
    "  = m \\Phi \\left(-\\tfrac{m}{\\sigma}\\right) - \\sigma \\varphi \\left(-\\tfrac{m}{\\sigma}\\right)\n",
    "  \\\\\n",
    "  & = m \\Phi \\left(-\\tfrac{m}{\\sigma}\\right) - \\sigma \\varphi \\left(\\tfrac{m}{\\sigma}\\right)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "При $\\sigma(N) = \\sigma_0 \\sqrt{N_0 / N}$:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "I(N) &= m\\,\\Phi\\!\\left(-\\tfrac{m}{\\sigma(N)}\\right) \\;-\\; \\sigma(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right), \\\\[6pt]\n",
    "\\frac{dI}{dN}\n",
    "&= m\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\\cdot\\frac{m\\,\\sigma'(N)}{\\sigma(N)^2}\n",
    "\\;-\\;\\Big[\\sigma'(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "+ \\sigma(N)\\,\\varphi'\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\\cdot\\frac{dz}{dN}\\Big], \\\\[6pt]\n",
    "&= \\frac{m^2\\sigma'(N)}{\\sigma(N)^2}\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "- \\sigma'(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "- \\frac{m^2\\sigma'(N)}{\\sigma(N)^2}\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right), \\\\[6pt]\n",
    "&= -\\,\\sigma'(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right).\n",
    "\\end{split}\n",
    "\\\\\n",
    "\\sigma'(N) = -\\sigma(N) / 2 N \n",
    "\\\\\n",
    "\\frac{dI}{dN} \\;=\\; \\frac{\\sigma(N)}{2N}\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "= \\frac{\\sigma(N)^2}{2N} Norm\\left(0; \\mu_B - \\mu_A, \\sigma^2 \\right)\n",
    "$$\n",
    "\n",
    "Условие остановки\n",
    "$$\n",
    "\\frac{\\sigma(N)^2}{2N} Norm\\left(0; \\mu_B - \\mu_A, \\sigma^2 \\right) < \\frac{w_A}{M} (\\mu_B - \\mu_A)\n",
    "\\\\\n",
    "Norm\\left(0; \\mu_B - \\mu_A, \\sigma^2 \\right) < 2 w_A \\frac{N}{M} \\frac{(\\mu_B - \\mu_A)}{\\sigma(N)^2}\n",
    "\\\\\n",
    "\\phi(z) < 2 w_A \\frac{N}{M} z, \\quad z = \\frac{\\mu_B - \\mu_A}{\\sigma}, \\quad \\phi(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e924289",
   "metadata": {},
   "source": [
    "Ограничение хвостов нормального распределения https://en.wikipedia.org/wiki/Mills_ratio .  \n",
    "Т.к. $u/z \\ge 1, u \\in [z, \\infty)$\n",
    "\n",
    "$$\n",
    "\\Phi(-z) \n",
    "= \\frac{1}{\\sqrt{2\\pi}}\\int_{z}^{\\infty} e^{-u^{2}/2}\\,du\n",
    "\\;\\le\\; \\frac{1}{\\sqrt{2\\pi}}\\int_{z}^{\\infty} \\frac{u}{z} e^{-u^{2}/2}\\,du\n",
    "= \\frac{1}{z\\sqrt{2\\pi}} e^{-z^{2}/2}\n",
    "= \\frac{\\varphi(z)}{z}, \\qquad z>0 .\n",
    "$$\n",
    "\n",
    "Условие остановки: вероятность группа B хуже (левый хвост) ограничена сверху $Norm(x)/x$ меньше $2w_A N/M$. \n",
    "\n",
    "$$\n",
    "F(0; \\mu_B - \\mu_A, \\sigma^2) < \\frac{\\phi(z)}{z} < 2w_A \\frac{N}{M}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9417fc1e",
   "metadata": {},
   "source": [
    "Если бы средние по мере набора данных не менялись, графики выглядели бы как в примере ниже. Разные $M$ соответствуют разным вероятностям остановки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = 1000\n",
    "nstep = 150\n",
    "sa = stats.binom.rvs(p=pa, n=npoints, size=nstep)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints, size=nstep)\n",
    "\n",
    "mu = pb - pa\n",
    "df = pd.DataFrame()\n",
    "df['npoints'] = [npoints] * nstep\n",
    "df['N'] = df['npoints'].cumsum()\n",
    "df['s'] = np.sqrt((pb*(1-pb)/df['N']) + (pa*(1-pa)/df['N']))\n",
    "df['pbgtpa'] = df['s'].apply(lambda s: 1 - stats.norm(loc=mu, scale=s).cdf(0))\n",
    "df['stopping_lhs'] = df['s'].apply(lambda s: s**2 / mu * stats.norm.pdf(0, loc=mu, scale=s))\n",
    "\n",
    "wA = 0.5\n",
    "M1 = 100000\n",
    "M2 = 1000000\n",
    "M3 = 10000000\n",
    "df['stopping_rhs_m1'] = (2 * wA / M1) * df['N'] \n",
    "df['stopping_rhs_m2'] = (2 * wA / M2) * df['N'] \n",
    "df['stopping_rhs_m3'] = (2 * wA / M3) * df['N'] \n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['stopping_lhs'], \n",
    "                         line_color='black', mode='lines', name='LHS'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['stopping_rhs_m1'], \n",
    "                         line_color='black', line_dash='dash', opacity=0.3, mode='lines', name='RHS, M=1e5'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['stopping_rhs_m2'], \n",
    "                         line_color='black', line_dash='longdash', opacity=0.3, mode='lines', name='RHS, M=1e6'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['stopping_rhs_m3'], \n",
    "                         line_color='black', line_dash='longdashdot', opacity=0.3, mode='lines', name='RHS, M=1e7'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pbgtpa'],\n",
    "                         line_color='black', opacity=0.3, name='$P(p_B - p_A > 0)$'))\n",
    "fig.update_layout(title='Критерий остановки',\n",
    "                  xaxis_title='$N$',\n",
    "                  #yaxis_title='sigma',\n",
    "                  #xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  yaxis_range=[0, 1],\n",
    "                  height=500)  \n",
    "fig.show()\n",
    "\n",
    "print('Stopping condition LHS < RHS:')\n",
    "for M, mi in [(M1,'m1'), (M2,'m2'), (M3,'m3')]:\n",
    "    N, pbgtpa = df.iloc[np.argmax(df['stopping_lhs'] < df[f'stopping_rhs_{mi}'])][['N', 'pbgtpa']]\n",
    "    print(f'M={M}: N={int(N)}, pb>pa: {pbgtpa*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf27ca9",
   "metadata": {},
   "source": [
    "Таким образом, для предполагаемого эффекта и выбранного количества пользоватлей, на которых повлияет раскатка, можно оценить пороговую вероятность остановки эксперимента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a2aa5f",
   "metadata": {},
   "source": [
    "Среднее меняется по мере набора данных.  \n",
    "Поэтому графики выглядят менее плавно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = 1000\n",
    "nstep = 150\n",
    "sa = stats.binom.rvs(p=pa, n=npoints, size=nstep)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints, size=nstep)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['npoints'] = [npoints] * nstep\n",
    "df['sa_step'] = sa\n",
    "df['sb_step'] = sb\n",
    "df['N'] = df['npoints'].cumsum()\n",
    "df['sa'] = df['sa_step'].cumsum()\n",
    "df['sb'] = df['sb_step'].cumsum()\n",
    "df['pa'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).mean(), axis=1)\n",
    "df['pb'] = df.apply(lambda r: posterior_dist_binom(r['sb'], r['N']).mean(), axis=1)\n",
    "df['pb_gt_pa'] = df.apply(lambda r: prob_pb_gt_pa(posterior_dist_binom(r['sa'], r['N']), posterior_dist_binom(r['sb'], r['N']), post_samp=10_000), axis=1)\n",
    "df['diff_mu'] = df.apply(lambda r: r['pb'] - r['pa'], axis=1)\n",
    "df['diff_s'] = df.apply(lambda r: np.sqrt(posterior_dist_binom(r['sa'], r['N']).std()**2 + posterior_dist_binom(r['sb'], r['N']).std()**2), axis=1)\n",
    "\n",
    "\n",
    "wA = 0.5\n",
    "M1 = 100000\n",
    "M2 = 1000000\n",
    "M3 = 10000000\n",
    "\n",
    "df['stopping_lhs'] = df.apply(lambda r: r['diff_s']**2 / r['diff_mu'] * stats.norm.pdf(0, loc=r['diff_mu'], scale=r['diff_s']), axis=1)\n",
    "df['stopping_rhs_m1'] = (2 * wA / M1) * df['N'] \n",
    "df['stopping_rhs_m2'] = (2 * wA / M2) * df['N'] \n",
    "df['stopping_rhs_m3'] = (2 * wA / M3) * df['N'] \n",
    "\n",
    "#todo: add numerical lhs\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'],\n",
    "                         line_color='black', name='$p_B > p_A$'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['stopping_lhs'], mode='lines', name='LHS'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['stopping_rhs_m1'], mode='lines', name='RHS, M=1e5'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['stopping_rhs_m2'], mode='lines', name='RHS, M=1e6'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['stopping_rhs_m3'], mode='lines', name='RHS, M=1e7'))\n",
    "fig.update_layout(title='Condition vs N (RHS linear in N)',\n",
    "                  xaxis_title='$N$',\n",
    "                  yaxis_title='Value',\n",
    "                  hovermode=\"x unified\",\n",
    "                  yaxis_range=[0, 1],\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# df_flt = df[5:]\n",
    "# display(df_flt.iloc[[(df_flt['stopping_lhs'] < df_flt['stopping_rhs_m1']).idxmax()]][['N', 'pb_gt_pa']])\n",
    "# display(df_flt.iloc[[(df_flt['stopping_lhs'] < df_flt['stopping_rhs_m2']).idxmax()]][['N', 'pb_gt_pa']])\n",
    "# display(df_flt.iloc[[(df_flt['stopping_lhs'] < df_flt['stopping_rhs_m3']).idxmax()]][['N', 'pb_gt_pa']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4533f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a352f657",
   "metadata": {},
   "source": [
    "Оценка длительности до фиксированной вероятности $P(p_B - p_A) > 0$.   \n",
    "Нужно задать базовое значени $p_A$.   \n",
    "Предположить эффект $dp$ или базовое значение $p_B$.  \n",
    "Ожидаемый эффект $p_B - p_A$.  \n",
    "Для конверсий дисперсия связана со средним $\\sigma^2 = p(1-p)/N$.  \n",
    "Дисперсия разности - сумма дисперсий групп $\\sigma_A^2 + \\sigma_B^2$.  \n",
    "Можно посчитать, как меняется $P(p_B - p_A > 0)$ по мере роста $N$: $P(p_B > p_A) = 1 - F_{p_B - p_A}(0)$  \n",
    "Найти минимальное $N$, для которого вероятность $P(p_B - p_A > 0)$ больше пороговой.  \n",
    "\n",
    "$N$ для групп по отдельности. \n",
    "Чаще удобнее суммировать. \n",
    "\n",
    "\n",
    "Для средних дисперсия не связана со средним.   \n",
    "Нужна оценка дисперсии по историческим данным. \n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "P_{p_A} = \\mbox{Beta}(x; \\alpha + n_{s_A}, \\beta + N_A - n_{s_A})\n",
    "\\approx \\mbox{Norm}(x; \\mu_A, \\sigma^2_A),\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B} = \\mbox{Beta}(x; \\alpha + n_{s_B}, \\beta + N_B - n_{s_B})\n",
    "\\approx \\mbox{Norm}(x; \\mu_B, \\sigma^2_B)\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B - p_A}(x) = \n",
    "\\int_{-\\infty}^{\\infty} dy P_{p_B}(y) P_{p_A}(y-x)\n",
    "\\approx \\mbox{Norm}\\left(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2\\right)\n",
    "\\\\\n",
    "\\\\\n",
    "P(p_B > p_A) = P(p_B - p_A > 0) = 1 - F_{p_B - p_A}(0)\n",
    "\\end{gather}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f03fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "dp = pb - pa  \n",
    "N = np.arange(100, 100000, 100)\n",
    "s = np.sqrt(pa * (1 - pa) / N + pb * (1 - pb) / N)\n",
    "pbgtpa = np.array([1 - stats.norm(loc=dp, scale=s).cdf(0) for s in s])\n",
    "p_stop = 0.95\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=N, y=pbgtpa,\n",
    "                         line_color='black', line_dash='solid', name='pb_gt_pa, fixed mean'))\n",
    "fig.add_hline(p_stop, line_dash='dash')\n",
    "fig.add_vline(N[np.argmax(pbgtpa > p_stop)], line_dash='dash')\n",
    "fig.update_layout(title='P(pB > pA)',\n",
    "                  xaxis_title='$N$',\n",
    "                  yaxis_range=[0, 1.05],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()\n",
    "\n",
    "N[np.argmax(pbgtpa > p_stop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968987f6",
   "metadata": {},
   "source": [
    "Сравнить оценку с моделированием.  \n",
    "Распределение длительности при фиксированном эффекте.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "p_stop = 0.93\n",
    "\n",
    "dp = pb - pa  \n",
    "N = np.arange(100, 100000, 100)\n",
    "s = np.sqrt(pa * (1 - pa) / N + pb * (1 - pb) / N)\n",
    "pbgtpa = np.array([1 - stats.norm(loc=dp, scale=s).cdf(0) for s in s])\n",
    "Nest = N[np.argmax(pbgtpa > p_stop)]\n",
    "\n",
    "Nstop = []\n",
    "won = []\n",
    "Nexp = 10000\n",
    "nmax = 5000000\n",
    "nstep = 1000\n",
    "for i in range(Nexp):\n",
    "    if i % 1000 == 0: print(f'Nexp: {i}')\n",
    "    N = 0\n",
    "    sa = 0\n",
    "    sb = 0\n",
    "    while N < nmax:\n",
    "        N += nstep\n",
    "        sa += stats.binom.rvs(p=pa, n=nstep)\n",
    "        sb += stats.binom.rvs(p=pb, n=nstep)\n",
    "        mua = sa / N\n",
    "        mub = sb / N\n",
    "        s = np.sqrt(mua * (1 - mua) / N + mub * (1 - mub) / N)\n",
    "        pbgtpa = 1 - stats.norm(loc=mub-mua, scale=s).cdf(0)\n",
    "        if pbgtpa > p_stop or pbgtpa < 1 - p_stop:\n",
    "            bestgr = 'B' if pbgtpa > p_stop else 'A'\n",
    "            won.append(bestgr)\n",
    "            Nstop.append(N)\n",
    "            #print(f'Exp {i}: Nstop {N}')\n",
    "            break\n",
    "\n",
    "#print(Nest, Nstop)\n",
    "            \n",
    "freq = pd.DataFrame({\n",
    "    'total': pd.Series(won).value_counts().sort_index(),\n",
    "})\n",
    "freq['frequency'] = freq['total'] / freq['total'].sum()\n",
    "display(freq)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=Nstop, nbinsx=100))\n",
    "fig.add_vline(Nest)\n",
    "fig.show()\n",
    "\n",
    "print(f'Est.N: {Nest}')\n",
    "print(f'Exp ended before estimate: {np.sum(Nstop < Nest), np.sum(Nstop < Nest) / Nexp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b561355",
   "metadata": {},
   "source": [
    "Распределение - обратное биномиальное?  \n",
    "Количество попыток до определенного числа успехов p_stop?\n",
    "\n",
    "Сумма двух обратных биномиальных (p>p_stop + p<p_stop)?\n",
    "\n",
    "Как записать условие $P(p_B > p_A) = 1 - F_{p_B - p_A}(0)$ в терминах отдельных точек?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c724a8",
   "metadata": {},
   "source": [
    "Можно ли думать о наборе данных как о случайном процессе?  \n",
    "https://en.wikipedia.org/wiki/Stochastic_process  \n",
    "https://en.wikipedia.org/wiki/Random_walk  \n",
    "https://en.wikipedia.org/wiki/Wiener_process  \n",
    "\n",
    "https://en.wikipedia.org/wiki/First-hitting-time_model  \n",
    "https://en.wikipedia.org/wiki/Hitting_time  \n",
    "\n",
    "https://en.wikipedia.org/wiki/Gambler%27s_ruin  \n",
    "https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BE_%D1%80%D0%B0%D0%B7%D0%BE%D1%80%D0%B5%D0%BD%D0%B8%D0%B8_%D0%B8%D0%B3%D1%80%D0%BE%D0%BA%D0%B0\n",
    "\n",
    "Еще вариант: на каждом шаге случайная величина\n",
    "{pb>pa: +1, pb=pa: 0, pb<pa:-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2460dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97d5b9c6",
   "metadata": {},
   "source": [
    "На практике эффект неизвестен заранее.  \n",
    "\n",
    "Еще одна проблема - много ошибок при ранних остановках.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cfa53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e57446b1",
   "metadata": {},
   "source": [
    "Много ошибок из-за ранних остановок.   \n",
    "Чем меньше nstep, тем больше ошибок.  \n",
    "Чем больше nstep, тем ближе доля ошибок к заявленной.  \n",
    "\n",
    "Попробовать выставлять минимальное время для эксп.  \n",
    "Но основании ожидаемого эффекта.  \n",
    "Скажем, треть времени.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f0fca",
   "metadata": {},
   "source": [
    "Оценка минимальной длительности:  \n",
    "изменение дисперсии много меньше величины эффекта?  \n",
    "$$\n",
    "\\delta \\sigma \\ll \\Delta \\mu\n",
    "$$\n",
    "Или нет.\n",
    "Меняется оценка среднего, дисперсия сильно не меняется.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c646bd3",
   "metadata": {},
   "source": [
    "Насколько сильно изменится оценка если добавить еще точек.\n",
    "\n",
    "Предположим, текущая оценка соответствует неверному решению.  \n",
    "Причем, если уверенность в неверной оценке большая - это должно быть редкое событие.  \n",
    "Как она поменяется, если добавить еще точек?  \n",
    "Считать длительность для изменения решения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0665d",
   "metadata": {},
   "source": [
    "Минимальный эффект: \n",
    "$$\n",
    "2 \\sigma < \\Delta \\mu\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57155934",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45ac51cb",
   "metadata": {},
   "source": [
    "Считать время на изменение решения.  \n",
    "Готовы ли держать еще столько времени?  \n",
    "Это способ оценить расходы на поддержание эксперимента на глаз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e7148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc5e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4597bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_histogram(x=nstop, xbins={'start':0, 'size':nstep, 'end':nmax})\n",
    "fig.add_vline(Ndr)\n",
    "fig.show()\n",
    "\n",
    "vals, counts = np.unique(won, return_counts=True)\n",
    "print('Best gr: ', dict(zip(vals, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266a3d1",
   "metadata": {},
   "source": [
    "Разброс непредсказуемый.  \n",
    "Даже если угадать эффект, сделанная оценка длительности говорит не ясно о чем. \n",
    "\n",
    "Вместо точной оценки может хватить оценки сверху.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f0e5d3",
   "metadata": {},
   "source": [
    "В реальности эффект заранее неизвестен.   \n",
    "Корректировать оценку при появлении данных.  \n",
    "- Предположить эффект.  \n",
    "- Оценить длительность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776434e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "951d82f3",
   "metadata": {},
   "source": [
    "Что будет, если использовать другой критерий остановки?  \n",
    "Какая будет точность?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05cd1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30040e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65801100",
   "metadata": {},
   "source": [
    "Если между группами небольшая разница, не интересно дожидаться вероятности 95%.  \n",
    "Займет много времени, но смысла в этом нет.  \n",
    "\n",
    "Если эффект меньше заданной величины, эксперимент пора прекращать.  \n",
    "Отсюда же можно строить оценки длительности.\n",
    "\n",
    "Как записать?\n",
    "\n",
    "$$\n",
    "\\frac{p_B - p_A}{p_A} < 0.03\n",
    "$$\n",
    "\n",
    "Относительная разность меньше 3% с вероятностью 95% .\n",
    "$$\n",
    "P\\left(\\frac{p_B - p_A}{p_A} < 0.03\\right) > 95 \\%\n",
    "$$\n",
    "\n",
    "$$\n",
    "P\\left(\\frac{p_B}{p_A} < 1.03\\right) > 95 \\%\n",
    "$$\n",
    "\n",
    "Нужно учесть знак.\n",
    "\n",
    "$$\n",
    "\\frac{|p_B - p_A|}{p_A} < 0.03\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4491b3a",
   "metadata": {},
   "source": [
    "При нормальных распределениях pb, pa по распространению ошибок\n",
    "\n",
    "Если распределения $p_A$ и $p_B$ нормальные, то распределение $\\Delta p$ также можно приближенно считать нормальным. \n",
    "Также нужно $\\mathrm{Cov}(p_A, p_B) = 0$ и малая плотность вероятности $p_A$ вблизи 0.\n",
    "\n",
    "$$\n",
    "P_{p_A}(x) = \\text{Norm}(x; \\mu_A, \\sigma^2_A),\n",
    "\\qquad\n",
    "P_{p_B}(x) = \\text{Norm}(x; \\mu_B, \\sigma^2_B)\n",
    "\\\\\n",
    "P_{\\Delta p}(x) \\approx \\text{Norm}(x; \\mu_{\\Delta}, \\sigma_{\\Delta}^2), \n",
    "\\quad\n",
    "\\mu_{\\Delta} = \\frac{\\mu_B - \\mu_A}{\\mu_A},\n",
    "\\quad\n",
    "\\sigma_{\\Delta} = \\frac{|\\mu_B|}{|\\mu_A|}\n",
    "\\sqrt{\n",
    "\\frac{\\sigma_{A}^{2}}{\\mu_A^{2}}\n",
    "+ \\frac{\\sigma_{B}^{2}}{\\mu_B^{2}}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b8d7e",
   "metadata": {},
   "source": [
    "Для отношения:\n",
    "$$\n",
    "P_{p_A}(x) = \\text{Norm}(x; \\mu_A, \\sigma^2_A),\n",
    "\\qquad\n",
    "P_{p_B}(x) = \\text{Norm}(x; \\mu_B, \\sigma^2_B)\n",
    "\\\\\n",
    "P_{B/A}(x) \\approx \\text{Norm}(x; \\mu_{B/A}, \\sigma_{B/A}^2), \n",
    "\\quad\n",
    "\\mu_{B/A} = \\frac{\\mu_B}{\\mu_A},\n",
    "\\quad\n",
    "\\sigma_{B/A} = \\frac{|\\mu_B|}{|\\mu_A|}\n",
    "\\sqrt{\n",
    "\\frac{\\sigma_{A}^{2}}{\\mu_A^{2}}\n",
    "+ \\frac{\\sigma_{B}^{2}}{\\mu_B^{2}}\n",
    "}\n",
    "$$\n",
    "\n",
    "Для оценок конверсий:\n",
    "$$\n",
    "\\mu = p, \\quad \\sigma^2 = p(1-p)/N\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66599cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 0.1\n",
    "pb = 0.1 * 1.03\n",
    "\n",
    "rel_thr = 1.01\n",
    "p_stop = 0.99\n",
    "\n",
    "N = np.arange(100, 1_000_000, 1000)\n",
    "spa = np.sqrt(pa * (1 - pa) / N)\n",
    "spb = np.sqrt(pb * (1 - pb) / N)\n",
    "rel_d = pb / pa\n",
    "rel_s = pb / pa * np.sqrt(spa**2 / pa**2 + spb**2 / pb**2)\n",
    "#rel_dist = stats.norm(loc=rel_d, scale=rel_s)\n",
    "#p_thr = rel_dist.cdf(rel_thr)\n",
    "p_thr = [stats.norm.cdf(rel_thr, loc=rel_d, scale=s) for s in rel_s]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=N, y=p_thr,\n",
    "                         line_color='black', line_dash='solid', name='pb_gt_pa, fixed mean'))\n",
    "fig.add_hline(p_stop, line_dash='dash')\n",
    "fig.add_hline(1-p_stop, line_dash='dash')\n",
    "#fig.add_vline(N[np.argmax(pbgtpa > p_stop)], line_dash='dash')\n",
    "fig.update_layout(title=f'P(pB/pA < {rel_thr})',\n",
    "                  xaxis_title='$N$',\n",
    "                  yaxis_range=[0, 1.05],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4827d4b",
   "metadata": {},
   "source": [
    "Для относительной разности граница постоянная.  \n",
    "Можно применить задачи касания стенки.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3ad3d",
   "metadata": {},
   "source": [
    "Ссылки\n",
    "\n",
    "https://en.wikipedia.org/wiki/Expected_value_of_sample_information  \n",
    "\n",
    "https://en.wikipedia.org/wiki/Truncated_normal_distribution  \n",
    "\n",
    "https://en.wikipedia.org/wiki/Mills_ratio\n",
    "\n",
    "https://en.wikipedia.org/wiki/Conjugate_prior\n",
    "\n",
    "https://en.wikipedia.org/wiki/Posterior_predictive_distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Beta-binomial_distribution\n",
    "\n",
    "Ожидаемое значение след. шага равно последнему известному значению.  \n",
    "https://en.wikipedia.org/wiki/Martingale_(probability_theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17064d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f56872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e8eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e722dcaa",
   "metadata": {},
   "source": [
    "Начать с абсолютной разности.\n",
    "\n",
    "$$\n",
    "P(|p_B - p_A| < c)\n",
    "\\\\\n",
    "P_{p_B - p_A}(x) \n",
    "\\approx \\mbox{Norm}\\left(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2\\right)\n",
    "\\\\\n",
    "\\\\\n",
    "\\begin{split}\n",
    "P(|p_B - p_A| < c) & = P(p_B - p_A < c) + P(p_B - p_A > 1 - c) \n",
    "\\\\\n",
    "& = F_{p_B - p_A}(c) + 1 - F_{p_B - p_A}(1 - c)\n",
    "\\\\\n",
    "& = 1 - 2 F_{p_B - p_A}(c)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Условие остановки: либо одна группа лучше другой $P(B>A) > 95\\%$, либо разница несущественна $P(|B-A| < c) > 95\\%$.\n",
    "\n",
    "То же для относительной разности.\n",
    "\n",
    "$$\n",
    "P(\\frac{|p_B - p_A|}{p_A} < c)\n",
    "$$\n",
    "\n",
    "Следующий вопрос - как выбрать $c$ и $95\\%$?  \n",
    "Здесь понадобится оценка последствий.  \n",
    "\n",
    "Вероятность одной группы лучше другой связана с оценкой эффекта?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccd573",
   "metadata": {},
   "source": [
    "Нарисовать картинку с динамикой.  \n",
    "Разность по мере набора данных.  \n",
    "Полоса [-c, c]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2.5\n",
    "x= np.linspace(-7, 7, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x),\n",
    "                        line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=[c, c], y=[0, max(stats.norm.pdf(x)*1.1)],\n",
    "                         mode='lines', line_dash='dash', line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=[-c, -c], y=[0, max(stats.norm.pdf(x)*1.1)],\n",
    "                         mode='lines', line_dash='dash', line_color='black'))\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b39d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42b843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17413e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed8e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991916b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccce458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fadd780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f66cabfe",
   "metadata": {},
   "source": [
    "Оценки длительности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3343773",
   "metadata": {},
   "source": [
    "Есть оценка распределения. Или априорное распределение. Как оценить длительность эксп?\n",
    "\n",
    "При остановке по достижении вероятности:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pb - pa\n",
    "s = np.sqrt((pb*(1-pb)/df['N']) + (pa*(1-pa)/df['N']))\n",
    "pbgtpa = [1-stats.norm(loc=mu, scale=s).cdf(0) for s in s]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'],\n",
    "                         line_color='red', name='pb_gt_pa, simulated'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=pbgtpa,\n",
    "                         line_color='black', line_dash='dash', name='pb_gt_pa, fixed mean'))\n",
    "fig.update_layout(title='P(pB > pA)',\n",
    "                  xaxis_title='$N$',\n",
    "                  yaxis_range=[0, 1.05],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80045465",
   "metadata": {},
   "source": [
    "Проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a370a4",
   "metadata": {},
   "source": [
    "Фиксированный эффект.  \n",
    "Оценивается длительность.  \n",
    "Сравнивается с фактической в неск. эксп.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ae8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pb - pa\n",
    "N = np.arange(1000, 150000, 1000)\n",
    "s = [np.sqrt((pb*(1-pb)/n) + (pa*(1-pa)/n)) for n in N]\n",
    "pbgtpa = np.array([1-stats.norm(loc=mu, scale=s).cdf(0) for s in s])\n",
    "\n",
    "Ndr = N[pbgtpa > 0.95][0]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=N, y=pbgtpa,\n",
    "                         line_color='black', line_dash='dash', name='pb_gt_pa, fixed mean'))\n",
    "fig.add_vline(Ndr)\n",
    "fig.update_layout(title='P(pB > pA)',\n",
    "                  xaxis_title='$N$',\n",
    "                  yaxis_range=[0, 1.05],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d41bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 0.1\n",
    "pb = pa * 1.03\n",
    "p_stop = 0.95\n",
    "nmax = 5000000\n",
    "nstep = 100\n",
    "\n",
    "nexp = 1000\n",
    "\n",
    "won = []\n",
    "nstop = []\n",
    "for ne in range(nexp):\n",
    "    N = np.arange(nstep, nmax + nstep, nstep)\n",
    "    sa = stats.binom.rvs(p=pa, n=nstep, size=nmax//nstep)\n",
    "    sb = stats.binom.rvs(p=pb, n=nstep, size=nmax//nstep)\n",
    "    Sa = sa.cumsum()\n",
    "    Sb = sb.cumsum()\n",
    "    Pa = Sa / N\n",
    "    Pb = Sb / N\n",
    "    #for n, pa_n, pb_n in zip(N, Pa, Pb):\n",
    "        #mu = pb_n - pa_n\n",
    "        #sigma = np.sqrt((pb_n*(1-pb_n)/n) + (pa_n*(1-pa_n)/n))\n",
    "    for n, sa_n, sb_n in zip(N, Sa, Sb):\n",
    "        post_a = posterior_dist_binom(sa_n, n)\n",
    "        post_b = posterior_dist_binom(sb_n, n)\n",
    "        mu = post_b.mean() - post_a.mean()\n",
    "        sigma = np.sqrt(post_a.std()**2 + post_b.std()**2)\n",
    "        pbgtpa = 1 - stats.norm(loc=mu, scale=sigma).cdf(0)\n",
    "        pbest = np.maximum(pbgtpa, 1-pbgtpa)\n",
    "        if pbest > p_stop:\n",
    "            #nstop.append(np.argmax(pbest > p_stop))\n",
    "            nstop.append(n)\n",
    "            #won.append('B' if pb_n > pa_n else 'A')\n",
    "            won.append('B' if sb_n > sa_n else 'A')\n",
    "            break\n",
    "#nstop\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_histogram(x=nstop, xbins={'start':0, 'size':nstep, 'end':nmax})\n",
    "fig.add_vline(Ndr)\n",
    "fig.show()\n",
    "\n",
    "vals, counts = np.unique(won, return_counts=True)\n",
    "print('Best gr: ', dict(zip(vals, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dad88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de86e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac57ad2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2bafe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77e6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03dc41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c2612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc393572",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "P_{p_A}(x) = \\mbox{Beta}(x; n_{s_A} + \\alpha, N_A - n_{s_A} + \\beta)\n",
    "& \\approx \\mbox{Norm}(x; \\mu_A, \\sigma_A^2),\n",
    "\\quad\n",
    "\\mu_A = (n_{s_A} + \\alpha - 1) /N_A, \n",
    "\\,\n",
    "\\sigma_A^2 = \\mu_A (1 - \\mu_A) / N_A,\n",
    "\\quad\n",
    "N_A \\gg n_{s_A} \\gg 1\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B}(x) = \\mbox{Beta}(x; n_{s_B} + \\alpha, N_B - n_{s_B} + \\beta)\n",
    "& \\approx \\mbox{Norm}(x; \\mu_B, \\sigma_B^2),\n",
    "\\quad\n",
    "\\mu_B = (n_{s_B} + \\alpha - 1)/N_B, \n",
    "\\,\n",
    "\\sigma_B^2 = \\mu_B (1 - \\mu_B) / N_B,\n",
    "\\quad\n",
    "N_B \\gg n_{s_B} \\gg 1\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B - p_A}(x) = \n",
    "\\int_{-\\infty}^{\\infty} dy P_{p_B}(y) P_{p_A}(y-x)\n",
    "& \\approx \\mbox{Norm}\\left(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2\\right),\n",
    "\\quad\n",
    "\\mbox{Norm}(x ; \\mu, \\sigma^2) \\equiv \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\tfrac{(x-\\mu)^2}{2 \\sigma^2} }\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aba197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1489e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06289424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "def posterior_binom_approx_95pdi(post_dist):\n",
    "    lower = post_dist.ppf(0.025)\n",
    "    upper = post_dist.ppf(0.975)\n",
    "    return lower, upper\n",
    "\n",
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = 1000\n",
    "nstep = 150\n",
    "sa = stats.binom.rvs(p=pa, n=npoints, size=nstep)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints, size=nstep)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['npoints'] = [npoints] * nstep\n",
    "df['sa_step'] = sa\n",
    "df['sb_step'] = sb\n",
    "df['N'] = df['npoints'].cumsum()\n",
    "df['sa'] = df['sa_step'].cumsum()\n",
    "df['sb'] = df['sb_step'].cumsum()\n",
    "df['pa'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).mean(), axis=1)\n",
    "df[['pa_lower', 'pa_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sa'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb'] = df.apply(lambda r: posterior_dist_binom(r['sb'], r['N']).mean(), axis=1)\n",
    "df[['pb_lower', 'pb_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sb'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb_gt_pa'] = df.apply(lambda r: prob_pb_gt_pa(posterior_dist_binom(r['sa'], r['N']), posterior_dist_binom(r['sb'], r['N']), post_samp=10_000), axis=1)\n",
    "df['diff_mu'] = df.apply(lambda r: r['pb'] - r['pa'], axis=1)\n",
    "df['diff_s'] = df.apply(lambda r: np.sqrt(posterior_dist_binom(r['sa'], r['N']).std()**2 + posterior_dist_binom(r['sb'], r['N']).std()**2), axis=1)\n",
    "df[['diff_lower', 'diff_upper']] = df.apply(lambda r: (r['diff_mu'] - 2*r['diff_s'], r['diff_mu'] + 2*r['diff_s']), axis=1, result_type=\"expand\")\n",
    "#todo: loss\n",
    "\n",
    "xaxis_min = -0.05\n",
    "xaxis_max = 0.15  \n",
    "#x = np.linspace(0, xaxis_max, 1000)\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "for N, o in [(1000, 0.3), (10000, 1)]:\n",
    "    dist_a = posterior_dist_binom(df[df['N'] == N]['sa'], N)\n",
    "    dist_b = posterior_dist_binom(df[df['N'] == N]['sb'], N)\n",
    "    fig.add_trace(go.Scatter(x=x, y=dist_a.pdf(x), line_color='red', opacity=o, name=f'А, N={N}'))\n",
    "    fig.add_trace(go.Scatter(x=x, y=dist_b.pdf(x), line_color='blue', opacity=o, name=f'Б, N={N}'))\n",
    "    #\n",
    "    diff = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "    fig.add_trace(go.Scatter(x=x, y=diff.pdf(x), line_color='black', opacity=o, name=f'Diff, N={N}'))\n",
    "    fig.update_layout(title='Апостериорные распределения',\n",
    "                      xaxis_title='$p$',\n",
    "                      yaxis_title='Плотность вероятности',\n",
    "                      xaxis_range=[xaxis_min, xaxis_max],\n",
    "                      hovermode=\"x\",\n",
    "                      height=500)\n",
    "#     fig.update_layout(title='Апостериорные распределения',\n",
    "#                       xaxis_title='$p$',\n",
    "#                       yaxis_title='Плотность вероятности',\n",
    "#                       xaxis_range=[0, xaxis_max],\n",
    "#                       hovermode=\"x\",\n",
    "#                       height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# xaxis_min = -0.05\n",
    "# xaxis_max = 0.15    \n",
    "# x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "# fig = go.Figure()\n",
    "# for N in [1000, 10000]:\n",
    "#     diff = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "#     fig.add_trace(go.Scatter(x=x, y=diff.pdf(x), line_color='black', name=f'Diff, N={N}'))\n",
    "#     fig.update_layout(title='Апостериорные распределения',\n",
    "#                       xaxis_title='$p$',\n",
    "#                       yaxis_title='Плотность вероятности',\n",
    "#                       xaxis_range=[xaxis_min, xaxis_max],\n",
    "#                       hovermode=\"x\",\n",
    "#                       height=500)\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pa'], name='A',\n",
    "                         line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pa_upper']) + list(reversed(df['pa_lower'])),\n",
    "                         fill=\"toself\", name='A, 95% PDI', marker_color='red', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb'], name='B',\n",
    "                         line_color='blue'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pb_upper']) + list(reversed(df['pb_lower'])),\n",
    "                         fill=\"toself\", name='B, 95% PDI', marker_color='blue', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_mu'], name='Diff',\n",
    "                         line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['diff_lower']) + list(reversed(df['diff_upper'])),\n",
    "                         fill=\"toself\", name='A, 95% PDI', marker_color='black', opacity=0.2))\n",
    "fig.update_layout(title='$p_A, p_B$',\n",
    "                  yaxis_tickformat = ',.1%',\n",
    "                  xaxis_title='N',\n",
    "                  height=700)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=df['N'], y=df['diff_mu'], name='$p_B - p_A$',\n",
    "#                          line_color='black'))\n",
    "# fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "#                          y=list(df['diff_lower']) + list(reversed(df['diff_upper'])),\n",
    "#                          fill=\"toself\", name='$p_B - p_A, \\mbox{ 95% PDI}$', marker_color='black', opacity=0.2))\n",
    "# fig.update_layout(title='$p_B - p_A$',\n",
    "#                   yaxis_tickformat = ',.1%',\n",
    "#                   xaxis_title='N')\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'], name='P(pb > pa)',\n",
    "#                          line_color='black'))\n",
    "# fig.update_layout(title='$P(p_B > p_A)$',\n",
    "#                   yaxis_range=[0, 1],\n",
    "#                   xaxis_title='N')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbd502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "approx_diff_dist = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "                         line_color='black', name='$\\mbox{Аналитическое приближение}$'))\n",
    "# fig.add_trace(go.Scatter(x=[approx_diff_dist.mean()[0], approx_diff_dist.mean()[0]], \n",
    "#                          y=[0, max(approx_diff_dist.pdf(x))], \n",
    "#                          line_color='black', mode='lines', name='mean'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=approx_diff_dist.pdf(x[x<0]), fill='tozeroy',\n",
    "                         line_color='black', opacity=0.3, name='loss'))\n",
    "# fig.add_trace(go.Scatter(x=x[x>=0], y=approx_diff_dist.pdf(x[x>=0]), \n",
    "#                          line_color='black', fillcolor='white', name='gain', fill='tozeroy'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9df690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28575a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pb - pa\n",
    "s = np.sqrt((pb*(1-pb)/df['N']) + (pa*(1-pa)/df['N']))\n",
    "pbgtpa = [1-stats.norm(loc=mu, scale=s).cdf(0) for s in s]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s']*10,\n",
    "                         line_color='red', name='s*10, simulated'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=s*10,\n",
    "                         line_color='black', line_dash='dash', name='s*10, fixed mean'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'],\n",
    "                         line_color='red', name='pb_gt_pa, simulated'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=pbgtpa,\n",
    "                         line_color='black', line_dash='dash', name='pb_gt_pa, fixed mean'))\n",
    "#todo: loss\n",
    "fig.update_layout(title='Стандартное отклонение pB - pA',\n",
    "                  xaxis_title='$N$',\n",
    "                  #yaxis_title='sigma',\n",
    "                  #xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = [1000, 9000]\n",
    "sa = stats.binom.rvs(p=pa, n=npoints)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints)\n",
    "npoints = np.cumsum(npoints)\n",
    "sa = np.cumsum(sa)\n",
    "sb = np.cumsum(sb)\n",
    "\n",
    "xaxis_min = 0.05\n",
    "xaxis_max = 0.17\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sa[-1], npoints[-1]).pdf(x), \n",
    "                         line_color='red', opacity=0.8, name=f'А, N={npoints[-1]}'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sa[0], npoints[0]).pdf(x), \n",
    "                         line_color='red', opacity=0.3, name=f'А, N={npoints[0]}'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sb[-1], npoints[-1]).pdf(x), \n",
    "                         line_color='blue', opacity=0.8, name=f'B, N={npoints[-1]}'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sb[0], npoints[0]).pdf(x), \n",
    "                         line_color='blue', opacity=0.3, name=f'B, N={npoints[0]}'))\n",
    "fig.update_layout(title='Апостериорные распределения',\n",
    "                  xaxis_title='$p$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c84163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c11520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def posterior_binom_approx_95pdi(post_dist):\n",
    "    lower = post_dist.ppf(0.025)\n",
    "    upper = post_dist.ppf(0.975)\n",
    "    return lower, upper\n",
    "\n",
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = 1000\n",
    "nstep = 150\n",
    "sa = stats.binom.rvs(p=pa, n=npoints, size=nstep)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints, size=nstep)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['npoints'] = [npoints] * nstep\n",
    "df['sa_step'] = sa\n",
    "df['sb_step'] = sb\n",
    "df['N'] = df['npoints'].cumsum()\n",
    "df['sa'] = df['sa_step'].cumsum()\n",
    "df['sb'] = df['sb_step'].cumsum()\n",
    "df['pa'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).mean(), axis=1)\n",
    "df[['pa_lower', 'pa_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sa'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb'] = df.apply(lambda r: posterior_dist_binom(r['sb'], r['N']).mean(), axis=1)\n",
    "df[['pb_lower', 'pb_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sb'], r['N'])), axis=1, result_type=\"expand\")\n",
    "\n",
    "\n",
    "xaxis_min = 0.05\n",
    "xaxis_max = 0.17\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(df[df['N'] == 10000]['sa'], 10000).pdf(x), \n",
    "                         line_color='red', opacity=0.8, name=f'А, N=10000'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(df[df['N'] == 1000]['sa'], 1000).pdf(x), \n",
    "                         line_color='red', opacity=0.3, name=f'А, N=1000'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(df[df['N'] == 10000]['sb'], 10000).pdf(x), \n",
    "                         line_color='blue', opacity=0.8, name=f'B, N=10000'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(df[df['N'] == 1000]['sb'], 1000).pdf(x), \n",
    "                         line_color='blue', opacity=0.3, name=f'B, N=1000'))\n",
    "fig.update_layout(title='Апостериорные распределения',\n",
    "                  xaxis_title='$p$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pa'], name='$p_A$',\n",
    "                         line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pa_upper']) + list(reversed(df['pa_lower'])),\n",
    "                         fill=\"toself\", name='$p_A, \\, \\mbox{95% PDI}$', marker_color='red', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb'], name='$p_B$',\n",
    "                         line_color='blue'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pb_upper']) + list(reversed(df['pb_lower'])),\n",
    "                         fill=\"toself\", name='$p_B, \\, \\mbox{95% PDI}$', marker_color='blue', opacity=0.2))\n",
    "fig.update_layout(title='$p_A, p_B$',\n",
    "                  yaxis_tickformat = ',.1%',\n",
    "                  xaxis_title='N',\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe22324",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = 1000\n",
    "sa = 100\n",
    "nb = 1000\n",
    "sb = 110\n",
    "\n",
    "p_dist_a = stats.beta(a=sa+1, b=na-sa+1)\n",
    "p_dist_b = stats.beta(a=sb+1, b=nb-sb+1)\n",
    "\n",
    "approx_diff_dist = stats.norm(loc=p_dist_b.mean() - p_dist_a.mean(), \n",
    "                              scale=np.sqrt(p_dist_b.std()**2 + p_dist_a.std()**2))\n",
    "\n",
    "a, b = -np.inf, (0 - approx_diff_dist.mean()) / approx_diff_dist.std()\n",
    "tr_loss = stats.truncnorm(a=a, b=b, loc=approx_diff_dist.mean(), scale=approx_diff_dist.std())\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "                         line_color='black', name='Diff'))\n",
    "fig.add_trace(go.Scatter(x=x, y=tr_loss.pdf(x), \n",
    "                         line_color='red', name='Loss'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "dN = 100\n",
    "\n",
    "res = []\n",
    "for N in range(na+nb, 100_000, dN):\n",
    "    mu = approx_diff_dist.mean()\n",
    "    s = approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N)\n",
    "    new_diff_dist = stats.norm(loc=approx_diff_dist.mean(), scale=s)\n",
    "    p = 1 - new_diff_dist.cdf(0)\n",
    "    a, b = -np.inf, (0 - new_diff_dist.mean()) / new_diff_dist.std()\n",
    "    tr_loss = stats.truncnorm(a=a, b=b, loc=new_diff_dist.mean(), scale=new_diff_dist.std())\n",
    "    mean_loss = tr_loss.mean() * new_diff_dist.cdf(0)\n",
    "    s2 = approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N+dN)\n",
    "    new_diff_dist2 = stats.norm(loc=approx_diff_dist.mean(), scale=s2)\n",
    "    a2, b2 = -np.inf, (0 - new_diff_dist2.mean()) / new_diff_dist2.std()\n",
    "    tr_loss2 = stats.truncnorm(a=a2, b=b2, loc=new_diff_dist2.mean(), scale=new_diff_dist2.std())\n",
    "    mean_loss2 = tr_loss2.mean() * new_diff_dist2.cdf(0)\n",
    "    d_loss = (mean_loss2 - mean_loss) / dN\n",
    "    loss_diff = new_diff_dist.pdf(0) * s**2 / (2 * N)\n",
    "    #loss_diff = stats.norm.pdf(mu/s) * s / (2 * N)\n",
    "    res.append((N, mu, s, p, mean_loss, d_loss, loss_diff))\n",
    "    \n",
    "#res = [(N, approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N)) for N in range(na+nb, 1000000, 100)]\n",
    "\n",
    "df_res = pd.DataFrame(res, columns=['N', 'mu', 'std', 'p', 'mean_loss', 'd_loss', 'loss_diff'])\n",
    "df_res\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "#fig.add_trace(go.Scatter(x=df['N'], y=df['std'] * 100, \n",
    "#                         line_color='blue', name='std * 100'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['p'], \n",
    "                         line_color='black', name='p'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['mean_loss'] * 100, \n",
    "                         line_color='red', name='mean_loss * 100'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['mu']*10, \n",
    "                         line_color='yellow', name='mu*10'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['d_loss'] * 1000000, \n",
    "                         line_color='green', name='d_loss * 1000000'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['loss_diff'] * 1000000, \n",
    "                         line_color='purple', name='loss_diff * 1000000'))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
