{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee15c77",
   "metadata": {},
   "source": [
    "# Критерии остановки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159af27",
   "metadata": {},
   "source": [
    "Можно останавливать эксперимент при достижении 95% уверенности, что целевая метрики одной группы лучше других.  \n",
    "Отметка 95% произвольна. Можно останавливать при 90%. Можно рассмотреть более объективный критерий остановки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a272606",
   "metadata": {},
   "source": [
    "Можно перевести вероятности в ожидаемый эффект.  \n",
    "Но выбор порога остается.   \n",
    "Более удобный вопрос - есть ли смысл продолжать дальше?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65bc3f",
   "metadata": {},
   "source": [
    "Качественные соображения:  \n",
    "Каждый день эксперимента - потери за счет попадания в худшую группу.  \n",
    "Так же потери времени и усложнение поддержки/разработки (сложно оценить).  \n",
    "\n",
    "Каждый день эксперимента - новые данные и уточнение оценок метрик.  \n",
    "Ценность данных с течением времени неодинакова.  \n",
    "Добавление первых 100 точек дает много информации, добавление 100 точек к 10 млн. ничего не меняет в оценке.  \n",
    "\n",
    "Решение об остановке должно учитывать последствия выбора.    \n",
    "При тестировании лекарств нужна большая уверенность в отсутствии побочек. Высока стоимость ошибки.  \n",
    "В веб-сервисах выбранных вариант продержится, например, год до повторного или следующего эксперимента.  \n",
    "  \n",
    "\n",
    "В итоге цена поддержания эксперимента постоянна, ценность новых данных падает.  \n",
    "Когда ценность новых данных падает ниже стоимости поддержания эксперимента и выгоды/потерь после прекращения,\n",
    "эксперимент пора останавливать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574c98f",
   "metadata": {},
   "source": [
    "Конкретная реализация зависит от рассматриваемых метрик.  \n",
    "Пример для конверсий.  \n",
    "Правдоподобие удобно задавать биномиальным распределением, априорное распределение - бета-распределением.  \n",
    "Тогда апостериорное также будет бета-распределением. \n",
    "\n",
    "$$\n",
    "P(\\mathcal{H} | \\mathcal{D}) \\propto P(\\mathcal{D} | \\mathcal{H}) P(\\mathcal{H})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{D} | \\mathcal{H}) = P(n_s, N | p) = \\mbox{Binom}(n_s, N | p) = C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H}) = P(p) = \\mbox{Beta}(p; \\alpha, \\beta) = \n",
    "\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} p^{\\alpha-1}(1-p)^{\\beta-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H} | \\mathcal{D}) = P(p | n_s, N) = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mbox{Beta}(x; \\alpha, \\beta) \\equiv \\frac{x^{\\alpha-1} (1 - x)^{\\beta-1}}{\\int_0^1 dx x^{\\alpha-1} (1 - x)^{\\beta-1}}\n",
    " = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1 - x)^{\\beta-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23595f3a",
   "metadata": {},
   "source": [
    "Разность приближенно можно считать нормальным распределением."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39582556",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "P(p_B > p_A) & = P(p_B - p_A > 0)\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_A}(x) = \\mbox{Beta}(x; n_{s_A} + \\alpha, N_A - n_{s_A} + \\beta)\n",
    "& \\approx \\mbox{Norm}(x; \\mu_A, \\sigma_A^2),\n",
    "\\quad\n",
    "\\mu_A = (n_{s_A} + \\alpha - 1) /N_A, \n",
    "\\,\n",
    "\\sigma_A^2 = \\mu_A (1 - \\mu_A) / N_A,\n",
    "\\quad\n",
    "N_A \\gg n_{s_A} \\gg 1\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B}(x) = \\mbox{Beta}(x; n_{s_B} + \\alpha, N_B - n_{s_B} + \\beta)\n",
    "& \\approx \\mbox{Norm}(x; \\mu_B, \\sigma_B^2),\n",
    "\\quad\n",
    "\\mu_B = (n_{s_B} + \\alpha - 1)/N_B, \n",
    "\\,\n",
    "\\sigma_B^2 = \\mu_B (1 - \\mu_B) / N_B,\n",
    "\\quad\n",
    "N_B \\gg n_{s_B} \\gg 1\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B - p_A}(x) = \n",
    "\\int_{-\\infty}^{\\infty} dy P_{p_B}(y) P_{p_A}(y-x)\n",
    "& \\approx \\mbox{Norm}\\left(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2\\right),\n",
    "\\quad\n",
    "\\mbox{Norm}(x ; \\mu, \\sigma^2) \\equiv \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\tfrac{(x-\\mu)^2}{2 \\sigma^2} }\n",
    "\\\\\n",
    "\\\\\n",
    "P(p_B - p_A > 0) & = 1 - F_{p_B - p_A}(0)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c225229",
   "metadata": {},
   "source": [
    "По мере набора данных апостериорные распределения сужаются.  \n",
    "То же для разности.  \n",
    "На графике полные распределения при N=1000 и 10000.  \n",
    "Также средние и 95% области наибольшей плотности вероятности по мере набора N.  \n",
    "На графиках полных распределений графики при N=1000 шире N=10000.  \n",
    "По мере набора данных 95% области наибольшей плотности вероятности сужается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e252b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "def posterior_binom_approx_95pdi(post_dist):\n",
    "    lower = post_dist.ppf(0.025)\n",
    "    upper = post_dist.ppf(0.975)\n",
    "    return lower, upper\n",
    "\n",
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = 1000\n",
    "nstep = 150\n",
    "sa = stats.binom.rvs(p=pa, n=npoints, size=nstep)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints, size=nstep)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['npoints'] = [npoints] * nstep\n",
    "df['sa_step'] = sa\n",
    "df['sb_step'] = sb\n",
    "df['N'] = df['npoints'].cumsum()\n",
    "df['sa'] = df['sa_step'].cumsum()\n",
    "df['sb'] = df['sb_step'].cumsum()\n",
    "df['pa'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).mean(), axis=1)\n",
    "df[['pa_lower', 'pa_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sa'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb'] = df.apply(lambda r: posterior_dist_binom(r['sb'], r['N']).mean(), axis=1)\n",
    "df[['pb_lower', 'pb_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sb'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb_gt_pa'] = df.apply(lambda r: prob_pb_gt_pa(posterior_dist_binom(r['sa'], r['N']), posterior_dist_binom(r['sb'], r['N']), post_samp=10_000), axis=1)\n",
    "df['diff_mu'] = df.apply(lambda r: r['pb'] - r['pa'], axis=1)\n",
    "df['diff_s'] = df.apply(lambda r: np.sqrt(posterior_dist_binom(r['sa'], r['N']).std()**2 + posterior_dist_binom(r['sb'], r['N']).std()**2), axis=1)\n",
    "df[['diff_lower', 'diff_upper']] = df.apply(lambda r: (r['diff_mu'] - 2*r['diff_s'], r['diff_mu'] + 2*r['diff_s']), axis=1, result_type=\"expand\")\n",
    "#todo: loss\n",
    "\n",
    "xaxis_min = -0.05\n",
    "xaxis_max = 0.15  \n",
    "#x = np.linspace(0, xaxis_max, 1000)\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "for N, o in [(1000, 0.3), (10000, 1)]:\n",
    "    dist_a = posterior_dist_binom(df[df['N'] == N]['sa'], N)\n",
    "    dist_b = posterior_dist_binom(df[df['N'] == N]['sb'], N)\n",
    "    fig.add_trace(go.Scatter(x=x, y=dist_a.pdf(x), line_color='red', opacity=o, name=f'А, N={N}'))\n",
    "    fig.add_trace(go.Scatter(x=x, y=dist_b.pdf(x), line_color='blue', opacity=o, name=f'Б, N={N}'))\n",
    "    #\n",
    "    diff = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "    fig.add_trace(go.Scatter(x=x, y=diff.pdf(x), line_color='black', opacity=o, name=f'Diff, N={N}'))\n",
    "    fig.update_layout(title='Апостериорные распределения',\n",
    "                      xaxis_title='$p$',\n",
    "                      yaxis_title='Плотность вероятности',\n",
    "                      xaxis_range=[xaxis_min, xaxis_max],\n",
    "                      hovermode=\"x\",\n",
    "                      height=500)\n",
    "#     fig.update_layout(title='Апостериорные распределения',\n",
    "#                       xaxis_title='$p$',\n",
    "#                       yaxis_title='Плотность вероятности',\n",
    "#                       xaxis_range=[0, xaxis_max],\n",
    "#                       hovermode=\"x\",\n",
    "#                       height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# xaxis_min = -0.05\n",
    "# xaxis_max = 0.15    \n",
    "# x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "# fig = go.Figure()\n",
    "# for N in [1000, 10000]:\n",
    "#     diff = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "#     fig.add_trace(go.Scatter(x=x, y=diff.pdf(x), line_color='black', name=f'Diff, N={N}'))\n",
    "#     fig.update_layout(title='Апостериорные распределения',\n",
    "#                       xaxis_title='$p$',\n",
    "#                       yaxis_title='Плотность вероятности',\n",
    "#                       xaxis_range=[xaxis_min, xaxis_max],\n",
    "#                       hovermode=\"x\",\n",
    "#                       height=500)\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pa'], name='A',\n",
    "                         line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pa_upper']) + list(reversed(df['pa_lower'])),\n",
    "                         fill=\"toself\", name='A, 95% PDI', marker_color='red', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb'], name='B',\n",
    "                         line_color='blue'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pb_upper']) + list(reversed(df['pb_lower'])),\n",
    "                         fill=\"toself\", name='B, 95% PDI', marker_color='blue', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_mu'], name='Diff',\n",
    "                         line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['diff_lower']) + list(reversed(df['diff_upper'])),\n",
    "                         fill=\"toself\", name='A, 95% PDI', marker_color='black', opacity=0.2))\n",
    "fig.update_layout(title='$p_A, p_B$',\n",
    "                  yaxis_tickformat = ',.1%',\n",
    "                  xaxis_title='N',\n",
    "                  height=700)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=df['N'], y=df['diff_mu'], name='$p_B - p_A$',\n",
    "#                          line_color='black'))\n",
    "# fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "#                          y=list(df['diff_lower']) + list(reversed(df['diff_upper'])),\n",
    "#                          fill=\"toself\", name='$p_B - p_A, \\mbox{ 95% PDI}$', marker_color='black', opacity=0.2))\n",
    "# fig.update_layout(title='$p_B - p_A$',\n",
    "#                   yaxis_tickformat = ',.1%',\n",
    "#                   xaxis_title='N')\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'], name='P(pb > pa)',\n",
    "#                          line_color='black'))\n",
    "# fig.update_layout(title='$P(p_B > p_A)$',\n",
    "#                   yaxis_range=[0, 1],\n",
    "#                   xaxis_title='N')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db11181",
   "metadata": {},
   "source": [
    "Дисперсия бета-распределения $Beta(x; \\alpha, \\beta)$:\n",
    "\n",
    "$$\n",
    "Var(Beta(x; \\alpha, \\beta)) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}\n",
    "$$\n",
    "\n",
    "При $N > n_s \\gg \\alpha_0, \\beta_0$:\n",
    "\n",
    "$$\n",
    "\\alpha \\approx n_s, \\qquad \\beta \\approx N - n_s, \\qquad n_s \\approx p N\n",
    "\\\\\n",
    "Var(Beta(x; \\alpha, \\beta)) = \\frac{n_s (N - n_s)}{N^3} = \\frac{p (1 - p)}{N}\n",
    "$$\n",
    "\n",
    "Приближенно $Var(Beta) \\sim 1/N$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s'],\n",
    "                         line_color='black', name='sigma'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s'][0] * np.sqrt(df['N'][0] / df['N']), \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='sigma0 * sqrt(N0/N)'))\n",
    "fig.update_layout(title='Стандартное отклонение pB - pA',\n",
    "                  xaxis_title='$N$',\n",
    "                  #yaxis_title='sigma',\n",
    "                  #xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852a486b",
   "metadata": {},
   "source": [
    "По мере набора данных:  \n",
    "-Средние в выборках стремятся к точному среднему  \n",
    "-Дисперсии сужаются ~1/N  \n",
    "-Разность средних стремится к точной разности  \n",
    "-Дисперсия разности сужается ~1/N  \n",
    "-Растет P(pb>pa)  \n",
    "-Уменьшаются ожидаемые потери.  \n",
    "-Стоимость данных остается постоянной.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51db89e",
   "metadata": {},
   "source": [
    "Пусть на текущий момент есть N точек и оценки апостериорных распределений.  \n",
    "-Можно считать, что pb-pa не изменится. На самом деле оно будет меняться, но нельзя сказать как. \n",
    "Е[pb-pa] = pb-pa не изменится, можно использовать его.  \n",
    "-Дисперсия будет убывать ~1/N.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf7b53d",
   "metadata": {},
   "source": [
    "Ожидаемая разность не меняется, поэтому оценка эффекта после остановки тоже не меняется.  \n",
    "Уменьшение дисперсии дает снижение возможных потерь при том же среднем эффекте.  \n",
    "На графике вероятность pb>pa - площадь правее нуля, ожидаемые потери - среднее в части меньше нуля.\n",
    "\n",
    "Можно посчитать изменение P(pb>pa) и ожидаемых потерь.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c166e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 5000\n",
    "approx_diff_dist = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "\n",
    "\n",
    "# x = np.linspace(-0.3, 0.3, 1000)\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "#                          line_color='black', name='$\\mbox{Аналитическое приближение}$'))\n",
    "# # fig.add_trace(go.Scatter(x=[approx_diff_dist.mean()[0], approx_diff_dist.mean()[0]], \n",
    "# #                          y=[0, max(approx_diff_dist.pdf(x))], \n",
    "# #                          line_color='black', mode='lines', name='mean'))\n",
    "# fig.add_trace(go.Scatter(x=x[x<0], y=approx_diff_dist.pdf(x[x<0]), fill='tozeroy',\n",
    "#                          line_color='black', opacity=0.3, name='loss'))\n",
    "# # fig.add_trace(go.Scatter(x=x[x>=0], y=approx_diff_dist.pdf(x[x>=0]), \n",
    "# #                          line_color='black', fillcolor='white', name='gain', fill='tozeroy'))\n",
    "# fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "#                          line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "# fig.update_layout(title='$p_B - p_A$',\n",
    "#                   xaxis_title='$x$',\n",
    "#                   yaxis_title='Плотность вероятности',\n",
    "#                   xaxis_range=[-0.1, 0.1],\n",
    "#                   hovermode=\"x\",\n",
    "#                   height=500)\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "mu = pb - pa\n",
    "N = 5000\n",
    "s = np.sqrt((pb*(1-pb)/N) + (pa*(1-pa)/N))\n",
    "d = stats.norm(loc=mu, scale=s)\n",
    "fig.add_trace(go.Scatter(x=x, y=d.pdf(x), \n",
    "                         line_color='black', name=f'N={N}'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(d.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=d.pdf(x[x<0]), fill='tozeroy',\n",
    "                         line_color='black', opacity=0.3, name='loss', showlegend=False))\n",
    "N = 1000\n",
    "s = np.sqrt((pb*(1-pb)/N) + (pa*(1-pa)/N))\n",
    "d = stats.norm(loc=mu, scale=s)\n",
    "fig.add_trace(go.Scatter(x=x, y=d.pdf(x), \n",
    "                         line_color='black', opacity=0.3, name=f'N={N}'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=d.pdf(x[x<0]), fill='tozeroy',\n",
    "                         line_color='black', opacity=0.3, name='loss'))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.05, 0.05],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#plot for fixed mu with N=1000, N=5000 \n",
    "\n",
    "\n",
    "mu = pb - pa\n",
    "s = np.sqrt((pb*(1-pb)/df['N']) + (pa*(1-pa)/df['N']))\n",
    "pbgtpa = [1-stats.norm(loc=mu, scale=s).cdf(0) for s in s]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s']*10,\n",
    "                         line_color='red', name='s*10, simulated'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=s*10,\n",
    "                         line_color='black', line_dash='dash', name='s*10, fixed mean'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'],\n",
    "                         line_color='red', name='pb_gt_pa, simulated'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=pbgtpa,\n",
    "                         line_color='black', line_dash='dash', name='pb_gt_pa, fixed mean'))\n",
    "#todo: loss\n",
    "fig.update_layout(title='Стандартное отклонение pB - pA',\n",
    "                  xaxis_title='$N$',\n",
    "                  #yaxis_title='sigma',\n",
    "                  #xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e542f",
   "metadata": {},
   "source": [
    "При одинаковом среднем меньше ожидаемых потерь лучше.  \n",
    "\n",
    "Останавливать, если:  \n",
    "Ожидаемые потери на след. шаге - Ожидаемые потери сейчас < Стоимости данных  \n",
    "\n",
    "Стоимость данных - ожидаемые потери из-за попадания части пользователей в худшую группу.  \n",
    "\n",
    "Потери на след. шаге и стоимость данных можно оценить исходя из того, что дисперсия будет уменьшаться 1/N при том же среднем.\n",
    "\n",
    "Ожидаемые потери должны учитывать количество пользователей, на которых будут раскатываться изменения, и LTV. \n",
    "\n",
    "$$\n",
    "E[L(p_B - p_A | N + \\Delta N)] - E[L(p_B - p_A | N)] < Cost(\\Delta N)\n",
    "\\\\\n",
    "\\begin{split}\n",
    "E[L(p_B - p_A | N)] & = LTV * M \\int_{-\\infty}^0 x P_{p_B - p_A}(x) dx\n",
    "\\\\\n",
    "& \\approx LTV * M \\int_{-\\infty}^0 x Norm(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2 | N) dx\n",
    "\\\\\n",
    "& = LTV * M * I(N)\n",
    "\\end{split}\n",
    "\\\\\n",
    "Cost(\\Delta N) \\approx LTV * w_A \\Delta N * E[P_{p_B - p_A}]  = LTV * w_A (\\mu_B - \\mu_A) \\Delta N\n",
    "$$\n",
    "\n",
    "$$\n",
    "LTV * M (I(N+\\Delta N) - I(N)) < LTV w_A (\\mu_B - \\mu_A) \\Delta N\n",
    "\\\\\n",
    "\\frac{I(N+\\Delta N) - I(N)}{\\Delta N} < \\frac{w_A}{M} (\\mu_B - \\mu_A)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = 1000\n",
    "sa = 100\n",
    "nb = 1000\n",
    "sb = 110\n",
    "\n",
    "p_dist_a = stats.beta(a=sa+1, b=na-sa+1)\n",
    "p_dist_b = stats.beta(a=sb+1, b=nb-sb+1)\n",
    "\n",
    "approx_diff_dist = stats.norm(loc=p_dist_b.mean() - p_dist_a.mean(), \n",
    "                              scale=np.sqrt(p_dist_b.std()**2 + p_dist_a.std()**2))\n",
    "\n",
    "a, b = -np.inf, (0 - approx_diff_dist.mean()) / approx_diff_dist.std()\n",
    "tr_loss = stats.truncnorm(a=a, b=b, loc=approx_diff_dist.mean(), scale=approx_diff_dist.std())\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "                         line_color='black', name='Diff'))\n",
    "fig.add_trace(go.Scatter(x=x, y=tr_loss.pdf(x), \n",
    "                         line_color='red', name='Loss'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "dN = 100\n",
    "\n",
    "res = []\n",
    "for N in range(na+nb, 100_000, dN):\n",
    "    mu = approx_diff_dist.mean()\n",
    "    s = approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N)\n",
    "    new_diff_dist = stats.norm(loc=approx_diff_dist.mean(), scale=s)\n",
    "    p = 1 - new_diff_dist.cdf(0)\n",
    "    a, b = -np.inf, (0 - new_diff_dist.mean()) / new_diff_dist.std()\n",
    "    tr_loss = stats.truncnorm(a=a, b=b, loc=new_diff_dist.mean(), scale=new_diff_dist.std())\n",
    "    mean_loss = tr_loss.mean() * new_diff_dist.cdf(0)\n",
    "    s2 = approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N+dN)\n",
    "    new_diff_dist2 = stats.norm(loc=approx_diff_dist.mean(), scale=s2)\n",
    "    a2, b2 = -np.inf, (0 - new_diff_dist2.mean()) / new_diff_dist2.std()\n",
    "    tr_loss2 = stats.truncnorm(a=a2, b=b2, loc=new_diff_dist2.mean(), scale=new_diff_dist2.std())\n",
    "    mean_loss2 = tr_loss2.mean() * new_diff_dist2.cdf(0)\n",
    "    d_loss = (mean_loss2 - mean_loss) / dN\n",
    "    loss_diff = new_diff_dist.pdf(0) * s**2 / (2 * N)\n",
    "    #loss_diff = stats.norm.pdf(mu/s) * s / (2 * N)\n",
    "    res.append((N, mu, s, p, mean_loss, d_loss, loss_diff))\n",
    "    \n",
    "#res = [(N, approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N)) for N in range(na+nb, 1000000, 100)]\n",
    "\n",
    "df_res = pd.DataFrame(res, columns=['N', 'mu', 'std', 'p', 'mean_loss', 'd_loss', 'loss_diff'])\n",
    "df_res\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "#fig.add_trace(go.Scatter(x=df['N'], y=df['std'] * 100, \n",
    "#                         line_color='blue', name='std * 100'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['p'], \n",
    "                         line_color='black', name='p'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['mean_loss'] * 100, \n",
    "                         line_color='red', name='mean_loss * 100'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['mu']*10, \n",
    "                         line_color='yellow', name='mu*10'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['d_loss'] * 1000000, \n",
    "                         line_color='green', name='d_loss * 1000000'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['loss_diff'] * 1000000, \n",
    "                         line_color='purple', name='loss_diff * 1000000'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a7e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f21e392f",
   "metadata": {},
   "source": [
    "Ожидаемые потери аналитически \n",
    "$$\n",
    "\\frac{d I(N)}{dN} < \\frac{w_A}{M} (\\mu_B - \\mu_A)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "I(N) &= \\int_{-\\infty}^{0} x \\mathcal N(x; m, \\sigma^2) dx\n",
    "  = \\int_{-\\infty}^{0} \\big(x + m - m\\big) \\mathcal N(x;m,\\sigma^2) dx \n",
    "  \\\\\n",
    "  & = m \\int_{-\\infty}^{0} \\mathcal N(x;m,\\sigma^2) dx + \\int_{-\\infty}^{0} (x-m) \\mathcal N(x;m,\\sigma^2) dx \n",
    "  \\\\\n",
    "  &= m \\Phi \\left(\\tfrac{0-m}{\\sigma}\\right) + \\sigma \\int_{-\\infty}^{(0-m)/\\sigma} t \\varphi(t) dt \n",
    "  = m \\Phi \\left(-\\tfrac{m}{\\sigma}\\right) - \\sigma \\varphi \\left(-\\tfrac{m}{\\sigma}\\right)\n",
    "  \\\\\n",
    "  & = m \\Phi \\left(-\\tfrac{m}{\\sigma}\\right) - \\sigma \\varphi \\left(\\tfrac{m}{\\sigma}\\right)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "При $\\sigma(N) = \\sigma_0 \\sqrt{N_0 / N}$:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "I(N) &= m\\,\\Phi\\!\\left(-\\tfrac{m}{\\sigma(N)}\\right) \\;-\\; \\sigma(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right), \\\\[6pt]\n",
    "\\frac{dI}{dN}\n",
    "&= m\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\\cdot\\frac{m\\,\\sigma'(N)}{\\sigma(N)^2}\n",
    "\\;-\\;\\Big[\\sigma'(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "+ \\sigma(N)\\,\\varphi'\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\\cdot\\frac{dz}{dN}\\Big], \\\\[6pt]\n",
    "&= \\frac{m^2\\sigma'(N)}{\\sigma(N)^2}\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "- \\sigma'(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "- \\frac{m^2\\sigma'(N)}{\\sigma(N)^2}\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right), \\\\[6pt]\n",
    "&= -\\,\\sigma'(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right).\n",
    "\\end{split}\n",
    "\\\\\n",
    "\\sigma'(N) = -\\sigma(N) / 2 N \n",
    "\\\\\n",
    "\\frac{dI}{dN} \\;=\\; \\frac{\\sigma(N)}{2N}\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "= \\frac{\\sigma(N)^2}{2N} Norm\\left(0; \\mu_B - \\mu_A, \\sigma^2 \\right)\n",
    "$$\n",
    "\n",
    "Условие остановки\n",
    "$$\n",
    "\\frac{\\sigma(N)^2}{2N} Norm\\left(0; \\mu_B - \\mu_A, \\sigma^2 \\right) < \\frac{w_A}{M} (\\mu_B - \\mu_A)\n",
    "\\\\\n",
    "Norm\\left(0; \\mu_B - \\mu_A, \\sigma^2 \\right) < 2 w_A \\frac{N}{M} \\frac{(\\mu_B - \\mu_A)}{\\sigma(N)^2}\n",
    "\\\\\n",
    "\\phi(z) < 2 w_A \\frac{N}{M} z, \\quad z = \\frac{\\mu_B - \\mu_A}{\\sigma}, \\quad \\phi(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e924289",
   "metadata": {},
   "source": [
    "Асимптотика хвостов нормального распределения https://en.wikipedia.org/wiki/Mills_ratio .  \n",
    "Т.к. $u/z \\ge 1, u \\in [z, \\infty)$\n",
    "\n",
    "$$\n",
    "\\Phi(-z) \n",
    "= \\frac{1}{\\sqrt{2\\pi}}\\int_{z}^{\\infty} e^{-u^{2}/2}\\,du\n",
    "\\;\\le\\; \\frac{1}{\\sqrt{2\\pi}}\\int_{z}^{\\infty} \\frac{u}{z} e^{-u^{2}/2}\\,du\n",
    "= \\frac{1}{z\\sqrt{2\\pi}} e^{-z^{2}/2}\n",
    "= \\frac{\\varphi(z)}{z}, \\qquad z>0 .\n",
    "$$\n",
    "\n",
    "Условие остановки: вероятность группа B хуже (левый хвост) ограничена сверху $Norm(x)/x$ меньше $2w_A N/M$. \n",
    "\n",
    "$$\n",
    "F(0; \\mu_B - \\mu_A, \\sigma^2) < \\frac{\\phi(z)}{z} < 2w_A \\frac{N}{M}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80943ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45ac51cb",
   "metadata": {},
   "source": [
    "Считать время на изменение решения.  \n",
    "Готовы ли держать еще столько времени?  \n",
    "Это способ оценить расходы на поддержание эксперимента на глаз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4533f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f66cabfe",
   "metadata": {},
   "source": [
    "Оценки длительности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa8f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41c357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80045465",
   "metadata": {},
   "source": [
    "Проверки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b057736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ae8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8824aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fd3ad3d",
   "metadata": {},
   "source": [
    "Ссылки\n",
    "\n",
    "https://en.wikipedia.org/wiki/Expected_value_of_sample_information  \n",
    "\n",
    "https://en.wikipedia.org/wiki/Truncated_normal_distribution  \n",
    "\n",
    "https://en.wikipedia.org/wiki/Mills_ratio\n",
    "\n",
    "https://en.wikipedia.org/wiki/Conjugate_prior\n",
    "\n",
    "https://en.wikipedia.org/wiki/Posterior_predictive_distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Beta-binomial_distribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
