{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee15c77",
   "metadata": {},
   "source": [
    "# Критерии остановки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159af27",
   "metadata": {},
   "source": [
    "Можно останавливать эксперимент при достижении 95% уверенности, что целевая метрики одной группы лучше других.  \n",
    "Отметка 95% произвольна. Можно останавливать при 90%. Можно рассмотреть более объективный критерий остановки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a272606",
   "metadata": {},
   "source": [
    "Можно перевести вероятности в ожидаемый эффект.  \n",
    "Но выбор порога остается.   \n",
    "Более удобный вопрос - есть ли смысл продолжать дальше?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65bc3f",
   "metadata": {},
   "source": [
    "Качественные соображения:  \n",
    "Каждый день эксперимента - потери за счет попадания в худшую группу.  \n",
    "Так же потери времени и усложнение поддержки/разработки (сложно оценить).  \n",
    "\n",
    "Каждый день эксперимента - новые данные и уточнение оценок метрик.  \n",
    "Ценность данных с течением времени неодинакова.  \n",
    "Добавление первых 100 точек дает много информации, добавление 100 точек к 10 млн. ничего не меняет в оценке.  \n",
    "\n",
    "Решение об остановке должно учитывать последствия выбора.    \n",
    "При тестировании лекарств нужна большая уверенность в отсутствии побочек. Высока стоимость ошибки.  \n",
    "В веб-сервисах выбранных вариант продержится, например, год до повторного или следующего эксперимента.  \n",
    "  \n",
    "\n",
    "В итоге цена поддержания эксперимента постоянна, ценность новых данных падает.  \n",
    "Когда ценность новых данных падает ниже стоимости поддержания эксперимента и выгоды/потерь после прекращения,\n",
    "эксперимент пора останавливать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574c98f",
   "metadata": {},
   "source": [
    "Конкретная реализация зависит от рассматриваемых метрик.  \n",
    "Пример для конверсий.  \n",
    "Правдоподобие удобно задавать биномиальным распределением, априорное распределение - бета-распределением.  \n",
    "Тогда апостериорное также будет бета-распределением. \n",
    "\n",
    "$$\n",
    "P(\\mathcal{H} | \\mathcal{D}) \\propto P(\\mathcal{D} | \\mathcal{H}) P(\\mathcal{H})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{D} | \\mathcal{H}) = P(n_s, N | p) = \\mbox{Binom}(n_s, N | p) = C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H}) = P(p) = \\mbox{Beta}(p; \\alpha, \\beta) = \n",
    "\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} p^{\\alpha-1}(1-p)^{\\beta-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H} | \\mathcal{D}) = P(p | n_s, N) = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mbox{Beta}(x; \\alpha, \\beta) \\equiv \\frac{x^{\\alpha-1} (1 - x)^{\\beta-1}}{\\int_0^1 dx x^{\\alpha-1} (1 - x)^{\\beta-1}}\n",
    " = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1 - x)^{\\beta-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23595f3a",
   "metadata": {},
   "source": [
    "Разность приближенно можно считать нормальным распределением."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39582556",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "P(p_B > p_A) & = P(p_B - p_A > 0)\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_A}(x) = \\mbox{Beta}(x; n_{s_A} + 1, N_A - n_{s_A} + 1)\n",
    "& \\approx \\mbox{Norm}(x; \\mu_A, \\sigma_A^2),\n",
    "\\quad\n",
    "\\mu_A = n_{s_A}/N_A, \n",
    "\\,\n",
    "\\sigma_A^2 = \\mu_A (1 - \\mu_A) / N_A,\n",
    "\\quad\n",
    "N_A \\gg n_{s_A} \\gg 1\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B}(x) = \\mbox{Beta}(x; n_{s_B} + 1, N_B - n_{s_B} + 1)\n",
    "& \\approx \\mbox{Norm}(x; \\mu_B, \\sigma_B^2),\n",
    "\\quad\n",
    "\\mu_B = n_{s_B}/N_B, \n",
    "\\,\n",
    "\\sigma_B^2 = \\mu_B (1 - \\mu_B) / N_B,\n",
    "\\quad\n",
    "N_B \\gg n_{s_B} \\gg 1\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B - p_A}(x) = \n",
    "\\int_{-\\infty}^{\\infty} dy P_{p_B}(y) P_{p_A}(y-x)\n",
    "& \\approx \\mbox{Norm}\\left(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2\\right),\n",
    "\\quad\n",
    "\\mbox{Norm}(x ; \\mu, \\sigma^2) \\equiv \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\tfrac{(x-\\mu)^2}{2 \\sigma^2} }\n",
    "\\\\\n",
    "\\\\\n",
    "P(p_B - p_A > 0) & = 1 - F_{p_B - p_A}(0)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c225229",
   "metadata": {},
   "source": [
    "По мере набора данных апостериорные распределения сужаются.  \n",
    "То же для разности.  \n",
    "На графике полные распределения при N=1000 и 10000.  \n",
    "Также средние и 95% области наибольшей плотности вероятности по мере набора N.  \n",
    "На графиках полных распределений графики при N=1000 шире N=10000.  \n",
    "По мере набора данных 95% области наибольшей плотности вероятности сужается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e252b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "def posterior_binom_approx_95pdi(post_dist):\n",
    "    lower = post_dist.ppf(0.025)\n",
    "    upper = post_dist.ppf(0.975)\n",
    "    return lower, upper\n",
    "\n",
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = 1000\n",
    "nstep = 150\n",
    "sa = stats.binom.rvs(p=pa, n=npoints, size=nstep)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints, size=nstep)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['npoints'] = [npoints] * nstep\n",
    "df['sa_step'] = sa\n",
    "df['sb_step'] = sb\n",
    "df['N'] = df['npoints'].cumsum()\n",
    "df['sa'] = df['sa_step'].cumsum()\n",
    "df['sb'] = df['sb_step'].cumsum()\n",
    "df['pa'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).mean(), axis=1)\n",
    "df[['pa_lower', 'pa_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sa'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb'] = df.apply(lambda r: posterior_dist_binom(r['sb'], r['N']).mean(), axis=1)\n",
    "df[['pb_lower', 'pb_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sb'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb_gt_pa'] = df.apply(lambda r: prob_pb_gt_pa(posterior_dist_binom(r['sa'], r['N']), posterior_dist_binom(r['sb'], r['N']), post_samp=10_000), axis=1)\n",
    "df['diff_mu'] = df.apply(lambda r: r['pb'] - r['pa'], axis=1)\n",
    "df['diff_s'] = df.apply(lambda r: np.sqrt(posterior_dist_binom(r['sa'], r['N']).std()**2 + posterior_dist_binom(r['sb'], r['N']).std()**2), axis=1)\n",
    "df[['diff_lower', 'diff_upper']] = df.apply(lambda r: (r['diff_mu'] - 2*r['diff_s'], r['diff_mu'] + 2*r['diff_s']), axis=1, result_type=\"expand\")\n",
    "#todo: loss\n",
    "\n",
    "xaxis_min = -0.05\n",
    "xaxis_max = 0.15  \n",
    "#x = np.linspace(0, xaxis_max, 1000)\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "for N, o in [(1000, 0.3), (10000, 1)]:\n",
    "    dist_a = posterior_dist_binom(df[df['N'] == N]['sa'], N)\n",
    "    dist_b = posterior_dist_binom(df[df['N'] == N]['sb'], N)\n",
    "    fig.add_trace(go.Scatter(x=x, y=dist_a.pdf(x), line_color='red', opacity=o, name=f'А, N={N}'))\n",
    "    fig.add_trace(go.Scatter(x=x, y=dist_b.pdf(x), line_color='blue', opacity=o, name=f'Б, N={N}'))\n",
    "    #\n",
    "    diff = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "    fig.add_trace(go.Scatter(x=x, y=diff.pdf(x), line_color='black', opacity=o, name=f'Diff, N={N}'))\n",
    "    fig.update_layout(title='Апостериорные распределения',\n",
    "                      xaxis_title='$p$',\n",
    "                      yaxis_title='Плотность вероятности',\n",
    "                      xaxis_range=[xaxis_min, xaxis_max],\n",
    "                      hovermode=\"x\",\n",
    "                      height=500)\n",
    "#     fig.update_layout(title='Апостериорные распределения',\n",
    "#                       xaxis_title='$p$',\n",
    "#                       yaxis_title='Плотность вероятности',\n",
    "#                       xaxis_range=[0, xaxis_max],\n",
    "#                       hovermode=\"x\",\n",
    "#                       height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# xaxis_min = -0.05\n",
    "# xaxis_max = 0.15    \n",
    "# x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "# fig = go.Figure()\n",
    "# for N in [1000, 10000]:\n",
    "#     diff = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "#     fig.add_trace(go.Scatter(x=x, y=diff.pdf(x), line_color='black', name=f'Diff, N={N}'))\n",
    "#     fig.update_layout(title='Апостериорные распределения',\n",
    "#                       xaxis_title='$p$',\n",
    "#                       yaxis_title='Плотность вероятности',\n",
    "#                       xaxis_range=[xaxis_min, xaxis_max],\n",
    "#                       hovermode=\"x\",\n",
    "#                       height=500)\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pa'], name='A',\n",
    "                         line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pa_upper']) + list(reversed(df['pa_lower'])),\n",
    "                         fill=\"toself\", name='A, 95% PDI', marker_color='red', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb'], name='B',\n",
    "                         line_color='blue'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pb_upper']) + list(reversed(df['pb_lower'])),\n",
    "                         fill=\"toself\", name='B, 95% PDI', marker_color='blue', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_mu'], name='Diff',\n",
    "                         line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['diff_lower']) + list(reversed(df['diff_upper'])),\n",
    "                         fill=\"toself\", name='A, 95% PDI', marker_color='black', opacity=0.2))\n",
    "fig.update_layout(title='$p_A, p_B$',\n",
    "                  yaxis_tickformat = ',.1%',\n",
    "                  xaxis_title='N',\n",
    "                  height=700)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=df['N'], y=df['diff_mu'], name='$p_B - p_A$',\n",
    "#                          line_color='black'))\n",
    "# fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "#                          y=list(df['diff_lower']) + list(reversed(df['diff_upper'])),\n",
    "#                          fill=\"toself\", name='$p_B - p_A, \\mbox{ 95% PDI}$', marker_color='black', opacity=0.2))\n",
    "# fig.update_layout(title='$p_B - p_A$',\n",
    "#                   yaxis_tickformat = ',.1%',\n",
    "#                   xaxis_title='N')\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'], name='P(pb > pa)',\n",
    "#                          line_color='black'))\n",
    "# fig.update_layout(title='$P(p_B > p_A)$',\n",
    "#                   yaxis_range=[0, 1],\n",
    "#                   xaxis_title='N')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db11181",
   "metadata": {},
   "source": [
    "Дисперсия бета-распределения $Beta(x; \\alpha, \\beta)$:\n",
    "\n",
    "$$\n",
    "Var(Beta(x; \\alpha, \\beta)) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}\n",
    "$$\n",
    "\n",
    "При $N > n_s \\gg \\alpha_0, \\beta_0$:\n",
    "\n",
    "$$\n",
    "\\alpha \\approx n_s, \\qquad \\beta \\approx N - n_s, \\qquad n_s \\approx p N\n",
    "\\\\\n",
    "Var(Beta(x; \\alpha, \\beta)) = \\frac{n_s (N - n_s)}{N^3} = \\frac{p (1 - p)}{N}\n",
    "$$\n",
    "\n",
    "Приближенно $Var(Beta) \\sim 1/N$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s'],\n",
    "                         line_color='black', name='sigma'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s'][0] * np.sqrt(df['N'][0] / df['N']), \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='sigma0 * sqrt(N0/N)'))\n",
    "fig.update_layout(title='Стандартное отклонение pB - pA',\n",
    "                  xaxis_title='$N$',\n",
    "                  #yaxis_title='sigma',\n",
    "                  #xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852a486b",
   "metadata": {},
   "source": [
    "По мере набора данных:  \n",
    "-Средние в выборках стремятся к точному среднему  \n",
    "-Дисперсии сужаются ~1/N  \n",
    "-Разность средних стремится к точной разности  \n",
    "-Дисперсия разности сужается ~1/N  \n",
    "-Растет P(pb>pa)  \n",
    "-Уменьшаются ожидаемые потери.  \n",
    "-Стоимость данных остается постоянной.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51db89e",
   "metadata": {},
   "source": [
    "Пусть на текущий момент есть N точек и оценки апостериорных распределений.  \n",
    "-Можно считать, что pb-pa не изменится. На самом деле оно будет меняться, но нельзя сказать как. \n",
    "Е[pb-pa] = pb-pa не изменится, можно использовать его.  \n",
    "-Дисперсия будет убывать ~1/N.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf7b53d",
   "metadata": {},
   "source": [
    "Ожидаемая разность не меняется, поэтому оценка эффекта после остановки тоже не меняется.  \n",
    "Уменьшение дисперсии дает снижение возможных потерь при том же среднем эффекте.  \n",
    "На графике вероятность pb>pa - площадь правее нуля, ожидаемые потери - среднее в части меньше нуля.\n",
    "\n",
    "Можно посчитать изменение P(pb>pa) и ожидаемых потерь.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c166e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "approx_diff_dist = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "                         line_color='black', name='$\\mbox{Аналитическое приближение}$'))\n",
    "# fig.add_trace(go.Scatter(x=[approx_diff_dist.mean()[0], approx_diff_dist.mean()[0]], \n",
    "#                          y=[0, max(approx_diff_dist.pdf(x))], \n",
    "#                          line_color='black', mode='lines', name='mean'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=approx_diff_dist.pdf(x[x<0]), fill='tozeroy',\n",
    "                         line_color='black', opacity=0.3, name='loss'))\n",
    "# fig.add_trace(go.Scatter(x=x[x>=0], y=approx_diff_dist.pdf(x[x>=0]), \n",
    "#                          line_color='black', fillcolor='white', name='gain', fill='tozeroy'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s']*10,\n",
    "                         line_color='black', name='diff_sigma*10'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'],\n",
    "                         line_color='black', name='pb_gt_pa'))\n",
    "#todo: loss\n",
    "fig.update_layout(title='Стандартное отклонение pB - pA',\n",
    "                  xaxis_title='$N$',\n",
    "                  #yaxis_title='sigma',\n",
    "                  #xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e542f",
   "metadata": {},
   "source": [
    "При одинаковом среднем меньше ожидаемых потерь лучше.  \n",
    "\n",
    "Останавливать, если:  \n",
    "Ожидаемые потери на след. шаге - Ожидаемые потери сейчас < Стоимости данных  \n",
    "\n",
    "Стоимость данных - ожидаемые потери из-за попадания части пользователей в худшую группу.  \n",
    "\n",
    "Потери на след. шаге и стоимость данных можно оценить исходя из того, что дисперсия будет уменьшаться 1/N при том же среднем.\n",
    "\n",
    "Ожидаемые потери должны учитывать количество пользователей, на которых будут раскатываться изменения, и LTV. \n",
    "\n",
    "$$\n",
    "E[L(p_B - p_A | N + \\Delta N)] - E[L(p_B - p_A | N)] < Cost(\\Delta N)\n",
    "\\\\\n",
    "\\begin{split}\n",
    "E[L(p_B - p_A | N)] & = LTV * M \\int_{-\\infty}^0 x P_{p_B - p_A}(x) dx\n",
    "\\\\\n",
    "& \\approx LTV * M \\int_{-\\infty}^0 x Norm(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2 | N) dx\n",
    "\\\\\n",
    "& = LTV * M * I(N)\n",
    "\\end{split}\n",
    "\\\\\n",
    "Cost(\\Delta N) \\approx LTV * w_A E[P_{p_B - p_A}] \\Delta N = LTV * w_A (\\mu_B - \\mu_A) \\Delta N\n",
    "$$\n",
    "\n",
    "$$\n",
    "LTV * M (I(N+\\Delta N) - I(N)) < LTV w_A (\\mu_B - \\mu_A) \\Delta N\n",
    "\\\\\n",
    "(I(N+\\Delta N) - I(N)) / \\Delta N < w_A (\\mu_B - \\mu_A) / M\n",
    "\\\\\n",
    "d I(N) / dN < w_A (\\mu_B - \\mu_A) / M \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = 1000\n",
    "sa = 100\n",
    "nb = 1000\n",
    "sb = 110\n",
    "\n",
    "p_dist_a = stats.beta(a=sa+1, b=na-sa+1)\n",
    "p_dist_b = stats.beta(a=sb+1, b=nb-sb+1)\n",
    "\n",
    "approx_diff_dist = stats.norm(loc=p_dist_b.mean() - p_dist_a.mean(), \n",
    "                              scale=np.sqrt(p_dist_b.std()**2 + p_dist_a.std()**2))\n",
    "\n",
    "a, b = -np.inf, (0 - approx_diff_dist.mean()) / approx_diff_dist.std()\n",
    "tr_loss = stats.truncnorm(a=a, b=b, loc=approx_diff_dist.mean(), scale=approx_diff_dist.std())\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "                         line_color='black', name='Diff'))\n",
    "fig.add_trace(go.Scatter(x=x, y=tr_loss.pdf(x), \n",
    "                         line_color='red', name='Loss'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "dN = 100\n",
    "\n",
    "res = []\n",
    "for N in range(na+nb, 100_000, dN):\n",
    "    mu = approx_diff_dist.mean()\n",
    "    s = approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N)\n",
    "    new_diff_dist = stats.norm(loc=approx_diff_dist.mean(), scale=s)\n",
    "    p = 1 - new_diff_dist.cdf(0)\n",
    "    a, b = -np.inf, (0 - new_diff_dist.mean()) / new_diff_dist.std()\n",
    "    tr_loss = stats.truncnorm(a=a, b=b, loc=new_diff_dist.mean(), scale=new_diff_dist.std())\n",
    "    mean_loss = tr_loss.mean() * new_diff_dist.cdf(0)\n",
    "    s2 = approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N+dN)\n",
    "    new_diff_dist2 = stats.norm(loc=approx_diff_dist.mean(), scale=s2)\n",
    "    a2, b2 = -np.inf, (0 - new_diff_dist2.mean()) / new_diff_dist2.std()\n",
    "    tr_loss2 = stats.truncnorm(a=a2, b=b2, loc=new_diff_dist2.mean(), scale=new_diff_dist2.std())\n",
    "    mean_loss2 = tr_loss2.mean() * new_diff_dist2.cdf(0)\n",
    "    d_loss = (mean_loss2 - mean_loss) / dN\n",
    "    res.append((N, mu, s, p, mean_loss, d_loss))\n",
    "    \n",
    "#res = [(N, approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N)) for N in range(na+nb, 1000000, 100)]\n",
    "\n",
    "df_res = pd.DataFrame(res, columns=['N', 'mu', 'std', 'p', 'mean_loss', 'd_loss'])\n",
    "df_res\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "#fig.add_trace(go.Scatter(x=df['N'], y=df['std'] * 100, \n",
    "#                         line_color='blue', name='std * 100'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['p'], \n",
    "                         line_color='black', name='p'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['mean_loss'] * 100, \n",
    "                         line_color='red', name='mean_loss * 100'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['mu']*10, \n",
    "                         line_color='yellow', name='mu*10'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['d_loss'] * 1000000, \n",
    "                         line_color='green', name='d_loss * 1000000'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a7e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f21e392f",
   "metadata": {},
   "source": [
    "Ожидаемые потери можно посчитать аналитически \n",
    "$$\n",
    "\\begin{split}\n",
    "I &= \\int_{-\\infty}^{0} x \\mathcal N(x; m, \\sigma^2) dx\n",
    "  = \\int_{-\\infty}^{0} \\big(x + m - m\\big) \\mathcal N(x;m,\\sigma^2) dx \n",
    "  \\\\\n",
    "  & = m \\int_{-\\infty}^{0} \\mathcal N(x;m,\\sigma^2) dx + \\int_{-\\infty}^{0} (x-m) \\mathcal N(x;m,\\sigma^2) dx \n",
    "  \\\\\n",
    "  &= m \\Phi \\left(\\tfrac{0-m}{\\sigma}\\right) + \\sigma \\int_{-\\infty}^{(0-m)/\\sigma} t \\varphi(t) dt \n",
    "  = m \\Phi \\left(-\\tfrac{m}{\\sigma}\\right) - \\sigma \\varphi \\left(-\\tfrac{m}{\\sigma}\\right)\n",
    "  \\\\\n",
    "  & = m \\Phi \\left(-\\tfrac{m}{\\sigma}\\right) - \\sigma \\varphi \\left(\\tfrac{m}{\\sigma}\\right)\n",
    "\\end{split}\n",
    "$$\n",
    "$$\n",
    "\\begin{split}\n",
    "I(N) &= m\\,\\Phi\\!\\left(-\\tfrac{m}{\\sigma(N)}\\right) \\;-\\; \\sigma(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right), \n",
    "\\quad \\sigma(N)=\\tfrac{\\sigma_0}{N}, \\\\[6pt]\n",
    "a &:= \\tfrac{m}{\\sigma_0} \\;\\;\\Rightarrow\\;\\; \\tfrac{m}{\\sigma(N)} = aN, \\\\[6pt]\n",
    "\\frac{dI}{dN} \n",
    "&= m\\frac{d}{dN}\\Phi(-aN) - \\frac{d}{dN}\\!\\left(\\tfrac{\\sigma_0}{N}\\varphi(aN)\\right) \\\\[6pt]\n",
    "&= m(-a)\\varphi(aN) - \\sigma_0\\Big(-N^{-2}\\varphi(aN) + N^{-1}\\,\\varphi'(aN)\\,a\\Big) \\\\[6pt]\n",
    "&= -ma\\,\\varphi(aN) - \\sigma_0\\Big(-N^{-2}\\varphi(aN) + N^{-1}(-aN\\varphi(aN))\\,a\\Big) \\\\[6pt]\n",
    "&= -ma\\,\\varphi(aN) - \\sigma_0\\Big(-N^{-2}\\varphi(aN) - a^2\\varphi(aN)\\Big) \\\\[6pt]\n",
    "&= \\varphi(aN)\\Big(-ma + \\tfrac{\\sigma_0}{N^{2}} + \\sigma_0 a^2\\Big).\n",
    "\\end{split}\n",
    "\\\\\n",
    "\\frac{dI}{dN} \\;=\\; \\frac{\\sigma_0}{N^{2}} \\,\\varphi\\!\\left(\\tfrac{mN}{\\sigma_0}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac51cb",
   "metadata": {},
   "source": [
    "Считать время на изменение решения.  \n",
    "Готовы ли держать еще столько времени?  \n",
    "Это способ оценить расходы на поддержание эксперимента на глаз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4533f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7df55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fd3ad3d",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Expected_value_of_sample_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa0b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12c92959",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0298104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a7e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee5f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf6eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89c4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d735fb6",
   "metadata": {},
   "source": [
    "Пусть $P(p_B > p_A) \\equiv P_B$ - вероятность метрика $B$ больше $A$.  \n",
    "$G$ - дополнительная выгода при выборе $B$ и группа $B$ на самом деле лучше.  \n",
    "$L$ - потери при выборе $B$ если группа $B$ на самом деле хуже.\n",
    "\n",
    "$E[U | B]$ - ожидаемая выгода при выборе $B$.\n",
    "\n",
    "$$\n",
    "E[U ∣ B]= P_B G - (1-P_B) L \n",
    "$$\n",
    "\n",
    "\n",
    "При выборе $A$ ничего не меняется\n",
    "$$\n",
    "E[U | A] = 0\n",
    "$$\n",
    "\n",
    "Можно выбирать $B$ если \n",
    "$$\n",
    "P_B G - (1-P_B) L > 0\n",
    "\\\\\n",
    "P_B (G + L) > L\n",
    "\\\\\n",
    "P_B > \\frac{L}{G + L}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f18684",
   "metadata": {},
   "source": [
    "Как оценить L и G?\n",
    "Для конверсий в оплату:  \n",
    "$$\n",
    "G = E[p_B - p_A | p_B > p_A] * LTV * N  \n",
    "\\\\\n",
    "L = E[-(p_B - p_A) | p_B < p_A] * LTV * N  \n",
    "$$\n",
    "\n",
    "$$\n",
    "P_B > \\frac{E[-(p_B - p_A) | p_B < p_A] }{E[p_B - p_A | p_B > p_A] + E[-(p_B - p_A) | p_B < p_A]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07123562",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = 1000\n",
    "sa = 100\n",
    "nb = 1000\n",
    "sb = 110\n",
    "\n",
    "p_dist_a = stats.beta(a=sa+1, b=na-sa+1)\n",
    "p_dist_b = stats.beta(a=sb+1, b=nb-sb+1)\n",
    "\n",
    "approx_diff_dist = stats.norm(loc=p_dist_b.mean() - p_dist_a.mean(), \n",
    "                              scale=np.sqrt(p_dist_b.std()**2 + p_dist_a.std()**2))\n",
    "\n",
    "\n",
    "a, b = (0 - approx_diff_dist.mean()) / approx_diff_dist.std(), np.inf\n",
    "tr_gain = stats.truncnorm(a=a, b=b, loc=approx_diff_dist.mean(), scale=approx_diff_dist.std())\n",
    "\n",
    "a, b = -np.inf, (0 - approx_diff_dist.mean()) / approx_diff_dist.std()\n",
    "tr_loss = stats.truncnorm(a=a, b=b, loc=approx_diff_dist.mean(), scale=approx_diff_dist.std())\n",
    "\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "                         line_color='black', name='$\\mbox{Аналитическое приближение}$'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x, y=tr_gain.pdf(x), \n",
    "                         line_color='black', name='tr-gain'))\n",
    "fig.add_trace(go.Scatter(x=x, y=tr_loss.pdf(x), \n",
    "                         line_color='black', name='tr-loss'))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "dist_p_b_gt_a = 1 - approx_diff_dist.cdf(0)\n",
    "print(f'pb > pa: {dist_p_b_gt_a}')\n",
    "\n",
    "e_gain = tr_gain.mean() * dist_p_b_gt_a\n",
    "print(f'Egain: {e_gain}')\n",
    "\n",
    "e_loss = tr_loss.mean() * (1 - dist_p_b_gt_a)\n",
    "print(f'Eloss: {e_loss}')\n",
    "\n",
    "c = -tr_loss.mean() / (tr_gain.mean() + -tr_loss.mean())\n",
    "print(f'Threshold: {c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055e4d7",
   "metadata": {},
   "source": [
    "Сравниваются площади.  \n",
    "Сравниваются средние в кусках распределения.  \n",
    "Они же связаны. Странно.    \n",
    "\n",
    "Соотношение\n",
    "$$\n",
    "P_B G - (1-P_B) L > 0\n",
    "$$\n",
    "ведь то же, что \n",
    "$$\n",
    "E[p] > 0\n",
    "$$\n",
    "\n",
    "Поэтому выполнено при любых sigma.  \n",
    "\n",
    "Нужно учитывать внешние факторы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedfcb05",
   "metadata": {},
   "source": [
    "Как меняется в зависимости от sigma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ede0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = 1000\n",
    "sa = 100\n",
    "nb = 1000\n",
    "sb = 110\n",
    "\n",
    "p_dist_a = stats.beta(a=sa+1, b=na-sa+1)\n",
    "p_dist_b = stats.beta(a=sb+1, b=nb-sb+1)\n",
    "\n",
    "\n",
    "dplt = []\n",
    "for s in np.arange(0.001, 10, 0.01):\n",
    "    approx_diff_dist = stats.norm(loc=p_dist_b.mean() - p_dist_a.mean(), \n",
    "                                  scale=s)\n",
    "    a, b = (0 - approx_diff_dist.mean()) / approx_diff_dist.std(), np.inf\n",
    "    tr_gain = stats.truncnorm(a=a, b=b, loc=approx_diff_dist.mean(), scale=approx_diff_dist.std())\n",
    "    a, b = -np.inf, (0 - approx_diff_dist.mean()) / approx_diff_dist.std()\n",
    "    tr_loss = stats.truncnorm(a=a, b=b, loc=approx_diff_dist.mean(), scale=approx_diff_dist.std())\n",
    "    dist_p_b_gt_a = 1 - approx_diff_dist.cdf(0)\n",
    "    #print(f'pb > pa: {dist_p_b_gt_a}')\n",
    "    #e_gain = tr_gain.mean() * dist_p_b_gt_a\n",
    "    #print(f'Egain: {e_gain}')\n",
    "    #e_loss = tr_loss.mean() * (1 - dist_p_b_gt_a)\n",
    "    #print(f'Eloss: {e_loss}')\n",
    "    c = -tr_loss.mean() / (tr_gain.mean() + -tr_loss.mean())\n",
    "    #print(f'Threshold: {c}')\n",
    "    dplt.append((s, dist_p_b_gt_a, c))\n",
    "\n",
    "df = pd.DataFrame(dplt, columns=['s', 'pba', 'c'])\n",
    "df\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['s'], y=df['pba'], \n",
    "                         line_color='blue', name='pba'))\n",
    "fig.add_trace(go.Scatter(x=df['s'], y=df['c'], \n",
    "                         line_color='black', name='c'))\n",
    "fig.add_trace(go.Scatter(x=df['s'], y=1 - df['c'], \n",
    "                         line_color='green', name='1-c'))\n",
    "# fig.update_layout(title='$p_B - p_A$',\n",
    "#                   xaxis_title='$x$',\n",
    "#                   yaxis_title='Плотность вероятности',\n",
    "#                   xaxis_range=[-0.1, 0.1],\n",
    "#                   hovermode=\"x\",\n",
    "#                   height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943d76f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0453cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5aaad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31220b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdd8d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc2a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e4143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78723e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ad9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe50d002",
   "metadata": {},
   "source": [
    "Критерий остановки  \n",
    "Ожидаемая выгода при остановке > Ожидаемая выгодна на след. шаге - Цена шага. \n",
    "\n",
    "$$\n",
    "E[U(\\delta | N)] > E[U(\\delta | N + \\Delta N)] - Cost(\\Delta N)\n",
    "\\\\\n",
    "E[U(\\delta | N)] = LTV * M \\int dx \\max(0, P_{\\delta(N)}(x)) = LTV * M \\int_0^{\\infty} P_{\\delta(N)}(x) dx\n",
    "\\approx LTV * M \\int_0^{\\infty} Norm(x; \\mu_B(N) - \\mu_A(N), \\sigma_A^2(N) + \\sigma_B^2(N)) dx\n",
    "\\\\\n",
    "Cost(\\Delta N) \\approx  E[U(\\delta | N)] \\Delta N / M\n",
    "$$\n",
    "(учесть долю трафика в cost(dN))\n",
    "\n",
    "\n",
    "$$\n",
    "E[U(\\delta | N)] > E[U(\\delta | N + \\Delta N)] - E[U(\\delta | N)] \\Delta N / M\n",
    "\\\\\n",
    "E[U(\\delta | N)] / M > (E[U(\\delta | N + \\Delta N)] - E[U(\\delta | N)]) / \\Delta N\n",
    "\\\\\n",
    "E[U(\\delta | N)] > M (E[U(\\delta | N)])' \n",
    "\\\\\n",
    "E[TrNorm(N)] > M E[TrNorm(N)]'\n",
    "$$\n",
    "\n",
    "Аналитика  \n",
    "https://en.wikipedia.org/wiki/Truncated_normal_distribution  \n",
    "$$\n",
    "E[TrNorm(N)] = \n",
    "\\\\\n",
    "E[TrNorm(N)]' = \n",
    "$$\n",
    "\n",
    "Что-то не то со знаками.  \n",
    "Еще вариант.  \n",
    "Остановка, если улучшение оценки выгоды меньше стоимости данных.  \n",
    "$$\n",
    "E[U(\\delta | N + \\Delta N)] - E[U(\\delta | N)] < Cost(\\Delta N)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = 1000\n",
    "sa = 100\n",
    "nb = 1000\n",
    "sb = 110\n",
    "\n",
    "p_dist_a = stats.beta(a=sa+1, b=na-sa+1)\n",
    "p_dist_b = stats.beta(a=sb+1, b=nb-sb+1)\n",
    "\n",
    "approx_diff_dist = stats.norm(loc=p_dist_b.mean() - p_dist_a.mean(), \n",
    "                              scale=np.sqrt(p_dist_b.std()**2 + p_dist_a.std()**2))\n",
    "\n",
    "a, b = (0 - approx_diff_dist.mean()) / approx_diff_dist.std(), np.inf\n",
    "tr_gain = stats.truncnorm(a=a, b=b, loc=approx_diff_dist.mean(), scale=approx_diff_dist.std())\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "                         line_color='black', name='Diff'))\n",
    "fig.add_trace(go.Scatter(x=x, y=tr_gain.pdf(x), \n",
    "                         line_color='red', name='Gain'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# pa = sa / na\n",
    "# pb = sb / nb\n",
    "\n",
    "# for N in range(0, 10e6, 1000):\n",
    "#     na_mod = na + N\n",
    "#     nb_mod = nb + N\n",
    "#     sa_mod = sa + int(pa * N)\n",
    "#     sb_mod = sb + int(pb * N)\n",
    "#     a_mod = stats.beta(a=sa_mod, b=na_mod - sa_mod)\n",
    "#     b_mod = stats.beta(a=sb_mod, b=nb_mod - sb_mod)\n",
    "#     diff_mod = stats.norm(loc=p_dist_b.mean() - p_dist_a.mean(), \n",
    "#                               scale=np.sqrt(p_dist_b.std()**2 + p_dist_a.std()**2))\n",
    "\n",
    "dN = 100\n",
    "\n",
    "res = []\n",
    "for N in range(na+nb, 100_000, dN):\n",
    "    s = approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N)\n",
    "    new_diff_dist = stats.norm(loc=approx_diff_dist.mean(), scale=s)\n",
    "    p = 1 - new_diff_dist.cdf(0)\n",
    "    a, b = (0 - new_diff_dist.mean()) / new_diff_dist.std(), np.inf\n",
    "    tr_gain = stats.truncnorm(a=a, b=b, loc=new_diff_dist.mean(), scale=new_diff_dist.std())\n",
    "    mean_gain = tr_gain.mean()\n",
    "    s2 = approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N+dN)\n",
    "    new_diff_dist2 = stats.norm(loc=approx_diff_dist.mean(), scale=s2)\n",
    "    a2, b2 = (0 - new_diff_dist2.mean()) / new_diff_dist2.std(), np.inf\n",
    "    tr_gain2 = stats.truncnorm(a=a2, b=b2, loc=new_diff_dist2.mean(), scale=new_diff_dist2.std())\n",
    "    mean_gain2 = tr_gain2.mean()\n",
    "    d_gain = (mean_gain2 - mean_gain) / dN\n",
    "    res.append((N, s, p, mean_gain, d_gain))\n",
    "    \n",
    "#res = [(N, approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N)) for N in range(na+nb, 1000000, 100)]\n",
    "\n",
    "df = pd.DataFrame(res, columns=['N', 'std', 'p', 'mean_gain', 'd_gain'])\n",
    "df\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['std'] * 100, \n",
    "                         line_color='blue', name='std * 100'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['p'], \n",
    "                         line_color='black', name='p'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['mean_gain'] * 100, \n",
    "                         line_color='red', name='mean_gain * 100'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=-df['d_gain'] * 10000000, \n",
    "                         line_color='green', name='-d_gain * 10000000'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f759fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75373cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b07e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863797d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa51dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa9e33a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24852ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = 1000\n",
    "sa = 100\n",
    "nb = 1000\n",
    "sb = 110\n",
    "\n",
    "p_dist_a = stats.beta(a=sa+1, b=na-sa+1)\n",
    "p_dist_b = stats.beta(a=sb+1, b=nb-sb+1)\n",
    "\n",
    "approx_diff_dist = stats.norm(loc=p_dist_b.mean() - p_dist_a.mean(), \n",
    "                              scale=np.sqrt(p_dist_b.std()**2 + p_dist_a.std()**2))\n",
    "dist_p_b_gt_a = 1 - approx_diff_dist.cdf(0)\n",
    "\n",
    "npost = 50000\n",
    "samp_a = p_dist_a.rvs(size=npost)\n",
    "samp_b = p_dist_b.rvs(size=npost)\n",
    "samp_p_b_gt_a = np.sum(samp_b > samp_a) / npost\n",
    "\n",
    "\n",
    "xaxis_max = 0.2\n",
    "x = np.linspace(0, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=p_dist_a.pdf(x), line_color='black', name='А'))\n",
    "fig.add_trace(go.Scatter(x=x, y=p_dist_b.pdf(x), line_color='black', opacity=0.3, name='Б'))\n",
    "fig.update_layout(title='Апостериорные распределения',\n",
    "                  xaxis_title='$p$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[0, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch2_conv_cmp_example.png\", scale=2)\n",
    "#Апостериорные распределения конверсий в обеих группах задаются бета-распределениями.\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "                         line_color='black', name='$\\mbox{Аналитическое приближение}$'))\n",
    "fig.add_trace(go.Histogram(x=samp_b - samp_a, histnorm='probability density', \n",
    "                           name='$\\mbox{Разность апостериорных выборок}$', nbinsx=500,\n",
    "                           marker_color='black', opacity=0.3))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch2_conv_cmp_diff.png\", scale=2)\n",
    "#Конверсия группы Б выше А с вероятностью 77%.\n",
    "\n",
    "print(f\"P(p_b > p_a) diff dist: {dist_p_b_gt_a}\")\n",
    "print(f\"P(p_b > p_a) post samples: {samp_p_b_gt_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1d908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a0ea5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aba888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be34f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165343bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "    \n",
    "p = 0.1\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist = stats.bernoulli(p=p)\n",
    "data = exact_dist.rvs(nsample)\n",
    "post_dist = posterior_dist_binom(ns=np.sum(data), ntotal=len(data))\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist.pdf(x), line_color='black', name='Апостериорное'))\n",
    "fig.add_trace(go.Scatter(x=[data.mean(), data.mean()], y=[0, max(post_dist.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist.mean(), exact_dist.mean()], y=[0, max(post_dist.pdf(x))*1.05], \n",
    "                         line_color='red', mode='lines', line_dash='dash', name='Точное p'))\n",
    "fig.update_layout(title='Апостериорное распределение',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[p-0.1, p+0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch3_postdist.png\", scale=2)\n",
    "#Мода апостериорного распределения конверсии близка точному значению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc7203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "p_A = 0.1\n",
    "p_B = p_A * 1.05\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist_A = stats.bernoulli(p=p_A)\n",
    "exact_dist_B = stats.bernoulli(p=p_B)\n",
    "data_A = exact_dist_A.rvs(nsample)\n",
    "data_B = exact_dist_B.rvs(nsample)\n",
    "\n",
    "post_dist_A = posterior_dist_binom(ns=np.sum(data_A), ntotal=len(data_A))\n",
    "post_dist_B = posterior_dist_binom(ns=np.sum(data_B), ntotal=len(data_B))\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist_A.pdf(x), line_color='black', name='A'))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist_B.pdf(x), line_color='black', opacity=0.2, name='Б'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_A.mean(), exact_dist_A.mean()], y=[0, max(post_dist_A.pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', name='Точное A'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_B.mean(), exact_dist_B.mean()], y=[0, max(post_dist_A.pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', opacity=0.2, name='Точное Б'))\n",
    "fig.update_layout(title='Апостериорные распределения',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[p_A/2, p_A*2],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "#fig.write_image(\"./figs/ch3_groups_cmp.png\", scale=2)\n",
    "#Апостериорные распределения конверсии в группах. Конверсия группы Б выше А с вероятностью 84%.\n",
    "\n",
    "print(f'P(pB > pA): {prob_pb_gt_pa(post_dist_A, post_dist_B)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bfab8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585010cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bacc116",
   "metadata": {},
   "source": [
    "Оценка при продолжении.  \n",
    "Вначале посчитать распределение ожидаемых новых точек.  \n",
    "Это апострериорное предиктивное распределение.  \n",
    "Потом использовать это распределение как функцию правдоподобия в соотн. Байеса.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55133dca",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Conjugate_prior\n",
    "\n",
    "https://en.wikipedia.org/wiki/Posterior_predictive_distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Beta-binomial_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346c35f",
   "metadata": {},
   "source": [
    "Апостериорное предиктивное для биномиального и бета - бета-биномиальное.\n",
    "\n",
    "Вероятность, что будет еще 1 успех:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3ef36",
   "metadata": {},
   "source": [
    "$$\n",
    "P(N_2, n_{s_2} | N, n_s) = \\int dp Binom(n_{s_2}, N_2; p) Beta(p; \\alpha + n_s, \\beta + N - n_s)\n",
    "\\\\\n",
    "=  C^{n_{s_2}}_{N_2} \\frac{1}{B(n_s + \\alpha - 1, N - n_s + \\beta - 1)} \\int dp p^{n_{s_2}} (1-p)^{N_2-n_{s_2}} p^{n_s + \\alpha - 1} (1-p)^{N - n_s + \\beta - 1}\n",
    "\\\\\n",
    "=  C^{n_{s_2}}_{N_2} \n",
    "\\frac{B(n_{s_2} + n_s + \\alpha - 1, N_2-n_{s_2} + N - n_s + \\beta - 1)}{B(n_s + \\alpha - 1, N - n_s + \\beta - 1)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb898de",
   "metadata": {},
   "source": [
    "После интегрирования по p перестает зависеть от p.  \n",
    "Как обновлять оценки параметров не ясно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141bece4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94698756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd813d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e82b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b084616",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "P(\\mathcal{D} | \\mathcal{H}) = P(n_s, N | p) & = \\mbox{Binom}(n_s, N; p) = C^{n_s}_{N} p^{n_s} (1 - p)^{N-n_s}\n",
    "\\\\\n",
    "\\\\\n",
    "P(\\mathcal{H}) = P(p) & = \\mbox{Unif}(0, 1) = 1\n",
    "\\\\\n",
    "\\\\\n",
    "P(\\mathcal{H} | \\mathcal{D}) = P(p | n_s, N) \n",
    "& = \\frac{P(n_s, N | p) P(p)}{P(n_s, N)}\n",
    "= \\frac{P(n_s, N | p) P(p)}{\\int_0^1 d p P(n_s, N | p) P(p)}\n",
    "\\\\\n",
    "& = \\frac{p^{n_s} (1 - p)^{N-n_s}}{\\int_0^1 d p (1 - p)^{N-n_s} p^{n_s} }\n",
    "= \\mbox{Beta}(p; n_s + 1, N - n_s + 1)\n",
    "\\\\\n",
    "\\\\\n",
    "\\mbox{Beta}(x; \\alpha, \\beta) & \\equiv \\frac{x^{\\alpha-1} (1 - x)^{\\beta-1}}{\\int_0^1 dx x^{\\alpha-1} (1 - x)^{\\beta-1}}\n",
    " = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1 - x)^{\\beta-1}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed119b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fa8f841",
   "metadata": {},
   "source": [
    "$$\n",
    "P(\\mathcal{H} | \\mathcal{D}) \\propto P(\\mathcal{D} | \\mathcal{H}) P(\\mathcal{H})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{D} | \\mathcal{H}) = P(n_s, N | p) = \\mbox{Binom}(n_s, N | p) = C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H}) = P(p) = \\mbox{Beta}(p; \\alpha, \\beta) = \n",
    "\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} p^{\\alpha-1}(1-p)^{\\beta-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(\\mathcal{H} | \\mathcal{D}) & = P(p | n_s, N) \n",
    "\\\\\n",
    "& \\propto \\mbox{Binom}(n_s, N | p) \\mbox{Beta}(p; \\alpha, \\beta)\n",
    "\\\\\n",
    "& \\propto C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} p^{\\alpha-1}(1-p)^{\\beta-1}\n",
    "\\\\\n",
    "& \\propto p^{n_s + \\alpha - 1} (1-p)^{N - n_s + \\beta - 1}\n",
    "\\\\\n",
    "& = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)\n",
    "\\end{split}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
