{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee15c77",
   "metadata": {},
   "source": [
    "# Критерии остановки и оценка длительности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159af27",
   "metadata": {},
   "source": [
    "В предыдущих примерах эксперименты останавливались при достижении 95% вероятности целевой метрики одной группы больше других. Порог 95% произволен - возможны 80%, 99%, другие значения. Удобен объективный критерий остановки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65bc3f",
   "metadata": {},
   "source": [
    "Качественные закономерности следующие. С одной стороны, продолжение эксперимента дает новые данные и уточняет метрики. С другой, часть пользователей попадает в неоптимальную группу, что ведет к потерям. Поддержка эксперимента также связана с потерями из-за усложнения разработки, хотя этот эффект тяжело оценить. Ценность новых данных убывает по мере их накопления - первые 100 точек сильнее влияют на решение, чем дополнительные 100 точек к 10 млн. Наконец, решение об остановке должно учитывать последствия выбора. Чем выше цена ошибки, тем большая нужна уверенность в одном из вариантов. Например, при тестировании лекарств нужна бОльшая уверенность в отсутствии побочек. В веб-сервисах выбранных вариант продержится, например, год до следующего эксперимента.  \n",
    "  \n",
    "\n",
    "Таким образом, цена поддержания эксперимента постоянна, ценность новых данных падает. Когда ценность новых данных падает ниже стоимости поддержания эксперимента, эксперимент пора останавливать. Ценность данных должна учитывать последствия выбора."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d50668",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../figs/ab_data_value.png\" alt=\"ab_data_value\" width=\"600\"/>\n",
    "    \n",
    "<em>Цена поддержания эксперимента постоянна, ценность новых данных падает. Эксперимент пора останавливать при ценности новых данных ниже их стоимости. Ценность данных должна учитывать последствия выбора одного из вариантов. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574c98f",
   "metadata": {},
   "source": [
    "Реализация этих закономерностей зависит от конкретных метрик. Далее будут рассматриваться конверсии. Для оценки вероятности успеха $p$ в серии $N$ испытаний с $n_s$ успехами правдоподобие удобно задавать биномиальным распределением $P(\\mathcal{D} | \\mathcal{H}) = \\mbox{Binom}(n_s, N | p)$, априорное распределение - бета-распределением $P(\\mathcal{H}) = \\mbox{Beta}(p; \\alpha, \\beta)$ с параметрами $\\alpha, \\beta$. Тогда апостериорная вероятность также будет бета-распределением с обновленными параметрами $P(\\mathcal{H} | \\mathcal{D}) = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)$. При достаточно большом количестве данных $N \\gg n_s \\gg \\alpha, \\beta$ бета-распределение близко нормальному $\\mbox{Beta}(x; \\alpha + n_s, \\beta + N - n_s) \\approx \\mbox{Norm}(x; \\mu, \\sigma^2), \\, \\mu = n_s / N, \\, \\sigma^2 = \\mu (1 - \\mu) / N$.\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H} | \\mathcal{D}) \\propto P(\\mathcal{D} | \\mathcal{H}) P(\\mathcal{H})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{D} | \\mathcal{H}) = P(n_s, N | p) = \\mbox{Binom}(n_s, N | p)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H}) = P(p) = \\mbox{Beta}(p; \\alpha, \\beta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\mathcal{H} | \\mathcal{D}) = P(p | n_s, N) = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "N \\gg n_s \\gg \\alpha, \\beta: \\quad\n",
    "\\mbox{Beta}(x; \\alpha + n_s, \\beta + N - n_s) \n",
    "\\approx \\mbox{Norm}(x; \\mu, \\sigma^2),\n",
    "\\quad\n",
    "\\mu = n_s / N, \n",
    "\\,\n",
    "\\sigma^2 = \\mu (1 - \\mu) / N\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{Binom}(n_s, N | p) = C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "\\qquad\n",
    "\\mbox{Beta}(x; \\alpha, \\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1 - x)^{\\beta-1}\n",
    "\\qquad\n",
    "\\mbox{Norm}(x ; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\tfrac{(x-\\mu)^2}{2 \\sigma^2} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a552c",
   "metadata": {},
   "source": [
    "По мере набора данных средние в выборках будут приближаться к точным средним, а апостериорные распределения сужаются. То же для разности.  \n",
    "Задано две группы, конверсия в одной $p_A = 10\\%$, в другой на 5% больше $p_B = 10.5\\%$. В этих группах набираются данные с шагом 1000 точек. На первом графике показаны апостериорные распределения при 1000 и 10000 точек в каждой группе. Видно, что распределения при большем количестве точек уже. На втором графике показаны средние и 95% области наибольшей плотности вероятности по мере набора N. По мере набора данных средние в выборках приближаются к точным средним, а 95% области наибольшей плотности вероятности сужаются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aee051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = [1000, 9000]\n",
    "sa = stats.binom.rvs(p=pa, n=npoints)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints)\n",
    "npoints = np.cumsum(npoints)\n",
    "sa = np.cumsum(sa)\n",
    "sb = np.cumsum(sb)\n",
    "\n",
    "xaxis_min = 0.05\n",
    "xaxis_max = 0.15  \n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sa[-1], npoints[-1]).pdf(x), \n",
    "                         line_color='red', opacity=0.8, name=f'А, N={npoints[-1]}'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sa[0], npoints[0]).pdf(x), \n",
    "                         line_color='red', opacity=0.3, name=f'А, N={npoints[0]}'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sb[-1], npoints[-1]).pdf(x), \n",
    "                         line_color='blue', opacity=0.8, name=f'B, N={npoints[-1]}'))\n",
    "fig.add_trace(go.Scatter(x=x, y=posterior_dist_binom(sb[0], npoints[0]).pdf(x), \n",
    "                         line_color='blue', opacity=0.3, name=f'B, N={npoints[0]}'))\n",
    "fig.update_layout(title='Апостериорные распределения',\n",
    "                  xaxis_title='$p$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad40479e",
   "metadata": {},
   "source": [
    "Разность приближенно можно считать нормальным распределением."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906dd7ba",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{gather}\n",
    "P_{p_A} = \\mbox{Beta}(x; \\alpha + n_{s_A}, \\beta + N_A - n_{s_A}),\n",
    "\\quad\n",
    "P_{p_B} = \\mbox{Beta}(x; \\alpha + n_{s_B}, \\beta + N_B - n_{s_B})\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B - p_A}(x) = \n",
    "\\int_{-\\infty}^{\\infty} dy P_{p_B}(y) P_{p_A}(y-x)\n",
    "\\approx \\mbox{Norm}\\left(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2\\right)\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c225229",
   "metadata": {},
   "source": [
    "По мере набора данных средние в выборках будут приближаться к точным средним, а апостериорные распределения сужаются. То же для разности.  \n",
    "Задано две группы, конверсия в одной $p_A = 10\\%$, в другой на 5% больше $p_B = 10.5\\%$. В этих группах набираются данные с шагом 1000 точек. На первом графике показаны апостериорные распределения при 1000 и 10000 точек в каждой группе. Видно, что распределения при большем количестве точек уже. На втором графике показаны средние и 95% области наибольшей плотности вероятности по мере набора N. По мере набора данных средние в выборках приближаются к точным средним, а 95% области наибольшей плотности вероятности сужаются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e252b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "def posterior_binom_approx_95pdi(post_dist):\n",
    "    lower = post_dist.ppf(0.025)\n",
    "    upper = post_dist.ppf(0.975)\n",
    "    return lower, upper\n",
    "\n",
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = 1000\n",
    "nstep = 150\n",
    "sa = stats.binom.rvs(p=pa, n=npoints, size=nstep)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints, size=nstep)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['npoints'] = [npoints] * nstep\n",
    "df['sa_step'] = sa\n",
    "df['sb_step'] = sb\n",
    "df['N'] = df['npoints'].cumsum()\n",
    "df['sa'] = df['sa_step'].cumsum()\n",
    "df['sb'] = df['sb_step'].cumsum()\n",
    "df['pa'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).mean(), axis=1)\n",
    "df[['pa_lower', 'pa_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sa'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb'] = df.apply(lambda r: posterior_dist_binom(r['sb'], r['N']).mean(), axis=1)\n",
    "df[['pb_lower', 'pb_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sb'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb_gt_pa'] = df.apply(lambda r: prob_pb_gt_pa(posterior_dist_binom(r['sa'], r['N']), posterior_dist_binom(r['sb'], r['N']), post_samp=10_000), axis=1)\n",
    "df['diff_mu'] = df.apply(lambda r: r['pb'] - r['pa'], axis=1)\n",
    "df['diff_s'] = df.apply(lambda r: np.sqrt(posterior_dist_binom(r['sa'], r['N']).std()**2 + posterior_dist_binom(r['sb'], r['N']).std()**2), axis=1)\n",
    "df[['diff_lower', 'diff_upper']] = df.apply(lambda r: (r['diff_mu'] - 2*r['diff_s'], r['diff_mu'] + 2*r['diff_s']), axis=1, result_type=\"expand\")\n",
    "#todo: loss\n",
    "\n",
    "xaxis_min = -0.05\n",
    "xaxis_max = 0.15  \n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "for N, o in [(1000, 0.3), (10000, 1)]:\n",
    "    dist_a = posterior_dist_binom(df[df['N'] == N]['sa'], N)\n",
    "    dist_b = posterior_dist_binom(df[df['N'] == N]['sb'], N)\n",
    "    fig.add_trace(go.Scatter(x=x, y=dist_a.pdf(x), line_color='red', opacity=o, name=f'А, N={N}'))\n",
    "    fig.add_trace(go.Scatter(x=x, y=dist_b.pdf(x), line_color='blue', opacity=o, name=f'Б, N={N}'))\n",
    "    #\n",
    "    diff = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "    fig.add_trace(go.Scatter(x=x, y=diff.pdf(x), line_color='black', opacity=o, name=f'Diff, N={N}'))\n",
    "    fig.update_layout(title='Апостериорные распределения',\n",
    "                      xaxis_title='$p$',\n",
    "                      yaxis_title='Плотность вероятности',\n",
    "                      xaxis_range=[xaxis_min, xaxis_max],\n",
    "                      hovermode=\"x\",\n",
    "                      height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pa'], name='A',\n",
    "                         line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pa_upper']) + list(reversed(df['pa_lower'])),\n",
    "                         fill=\"toself\", name='A, 95% PDI', marker_color='red', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb'], name='B',\n",
    "                         line_color='blue'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pb_upper']) + list(reversed(df['pb_lower'])),\n",
    "                         fill=\"toself\", name='B, 95% PDI', marker_color='blue', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_mu'], name='Diff',\n",
    "                         line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['diff_lower']) + list(reversed(df['diff_upper'])),\n",
    "                         fill=\"toself\", name='A, 95% PDI', marker_color='black', opacity=0.2))\n",
    "fig.update_layout(title='$p_A, p_B$',\n",
    "                  yaxis_tickformat = ',.1%',\n",
    "                  xaxis_title='N',\n",
    "                  height=700)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db11181",
   "metadata": {},
   "source": [
    "Дисперсия бета-распределения убывает пропорционально $1/N$. Это видно как из точного выражения для дисперсии бета-распределения, так и из приближения нормальным распределением. То же для дисперсии разности. \n",
    "\n",
    "$$\n",
    "Var(\\mbox{Beta}(x; \\alpha, \\beta)) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}\n",
    "\\\\\n",
    "N > n_s \\gg \\alpha, \\beta:\n",
    "\\qquad\n",
    "\\alpha \\approx n_s, \\qquad \\beta \\approx N - n_s, \\qquad n_s \\approx p N\n",
    "\\\\\n",
    "Var(\\mbox{Beta}(x; \\alpha, \\beta)) = \\frac{n_s (N - n_s)}{N^3} = \\frac{p (1 - p)}{N}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a71f148",
   "metadata": {},
   "source": [
    "На графике показано стандартное отклонение разности по сэмплам и величина $\\sigma_0 \\sqrt{N_0/N}$, где $\\sigma_0$ и $N_0$ - стандартное отклонение и количество точек на первом шаге набора данных. Величины близки.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s'],\n",
    "                         line_color='black', name='sigma'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s'][0] * np.sqrt(df['N'][0] / df['N']), \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='sigma0 * sqrt(N0/N)'))\n",
    "fig.update_layout(title='Стандартное отклонение pB - pA',\n",
    "                  xaxis_title='$N$',\n",
    "                  #yaxis_title='sigma',\n",
    "                  #xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852a486b",
   "metadata": {},
   "source": [
    "Таким образом, по мере набора данных средние в выборках стремятся к точному среднему, разность средних стремится к точной разности. Дисперсии распределений и разности сужаются пропорционально $1/N$. Растет уверенность в лучшей группе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51db89e",
   "metadata": {},
   "source": [
    "Для записи критерия остановки можно рассмотреть момент, когда в каждой группе уже собрано N точек и построены оценки апостериорных распределений. Что произойдет при продолжении эксперимента? Ожидаемое значение разности средних $p_B - p_A$ изменится непредсказуемым образом. На основе текущих данных нельзя сказать, как именно оно изменится. При этом можно ожидать, что ожидаемое значение будет таким же, как и по имеющимся данным $E[p_B-p_A | N + \\Delta N] \\approx E[p_B -p_A | N]$. На самом деле это не так. Дисперсия будет убывать $1/N$. Т.е. распределение станет немного уже при том же среднем. Ожидаемая разность не меняется, поэтому оценка эффекта после остановки тоже не меняется. Уменьшение дисперсии дает снижение возможных потерь при том же среднем эффекте. На графике вероятность pb>pa - площадь правее нуля, ожидаемые потери - среднее в части меньше нуля.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c166e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "mu = pb - pa\n",
    "N = 5000\n",
    "s = np.sqrt((pb*(1-pb)/N) + (pa*(1-pa)/N))\n",
    "d = stats.norm(loc=mu, scale=s)\n",
    "fig.add_trace(go.Scatter(x=x, y=d.pdf(x), \n",
    "                         line_color='black', name=f'N={N}'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(d.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=d.pdf(x[x<0]), fill='tozeroy',\n",
    "                         line_color='black', opacity=0.3, name='loss', showlegend=False))\n",
    "N = 1000\n",
    "s = np.sqrt((pb*(1-pb)/N) + (pa*(1-pa)/N))\n",
    "d = stats.norm(loc=mu, scale=s)\n",
    "fig.add_trace(go.Scatter(x=x, y=d.pdf(x), \n",
    "                         line_color='black', opacity=0.3, name=f'N={N}'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=d.pdf(x[x<0]), fill='tozeroy',\n",
    "                         line_color='black', opacity=0.3, name='loss'))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.05, 0.05],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e542f",
   "metadata": {},
   "source": [
    "При одинаковом среднем меньше ожидаемых потерь лучше.  \n",
    "\n",
    "Останавливать, если:  \n",
    "Ожидаемые потери на след. шаге - Ожидаемые потери сейчас < Стоимости данных  \n",
    "\n",
    "Стоимость данных - ожидаемые потери из-за попадания части пользователей в худшую группу.  \n",
    "\n",
    "Потери на след. шаге и стоимость данных можно оценить исходя из того, что дисперсия будет уменьшаться 1/N при том же среднем.\n",
    "\n",
    "Ожидаемые потери должны учитывать количество пользователей, на которых будут раскатываться изменения, и LTV. \n",
    "\n",
    "$$\n",
    "E[L(p_B - p_A | N + \\Delta N)] - E[L(p_B - p_A | N)] < Cost(\\Delta N)\n",
    "\\\\\n",
    "\\begin{split}\n",
    "E[L(p_B - p_A | N)] & = LTV * M \\int_{-\\infty}^0 x P_{p_B - p_A}(x) dx\n",
    "\\\\\n",
    "& \\approx LTV * M \\int_{-\\infty}^0 x Norm(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2 | N) dx\n",
    "\\\\\n",
    "& = LTV * M * I(N)\n",
    "\\end{split}\n",
    "\\\\\n",
    "Cost(\\Delta N) \\approx LTV * w_A \\Delta N * E[P_{p_B - p_A}]  = LTV * w_A (\\mu_B - \\mu_A) \\Delta N\n",
    "$$\n",
    "\n",
    "$$\n",
    "LTV * M (I(N+\\Delta N) - I(N)) < LTV w_A (\\mu_B - \\mu_A) \\Delta N\n",
    "\\\\\n",
    "\\frac{I(N+\\Delta N) - I(N)}{\\Delta N} < \\frac{w_A}{M} (\\mu_B - \\mu_A)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = 1000\n",
    "sa = 100\n",
    "nb = 1000\n",
    "sb = 110\n",
    "\n",
    "p_dist_a = stats.beta(a=sa+1, b=na-sa+1)\n",
    "p_dist_b = stats.beta(a=sb+1, b=nb-sb+1)\n",
    "\n",
    "approx_diff_dist = stats.norm(loc=p_dist_b.mean() - p_dist_a.mean(), \n",
    "                              scale=np.sqrt(p_dist_b.std()**2 + p_dist_a.std()**2))\n",
    "\n",
    "a, b = -np.inf, (0 - approx_diff_dist.mean()) / approx_diff_dist.std()\n",
    "tr_loss = stats.truncnorm(a=a, b=b, loc=approx_diff_dist.mean(), scale=approx_diff_dist.std())\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "                         line_color='black', name='Diff'))\n",
    "fig.add_trace(go.Scatter(x=x, y=tr_loss.pdf(x), \n",
    "                         line_color='red', name='Loss'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "dN = 100\n",
    "\n",
    "res = []\n",
    "for N in range(na+nb, 100_000, dN):\n",
    "    mu = approx_diff_dist.mean()\n",
    "    s = approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N)\n",
    "    new_diff_dist = stats.norm(loc=approx_diff_dist.mean(), scale=s)\n",
    "    p = 1 - new_diff_dist.cdf(0)\n",
    "    a, b = -np.inf, (0 - new_diff_dist.mean()) / new_diff_dist.std()\n",
    "    tr_loss = stats.truncnorm(a=a, b=b, loc=new_diff_dist.mean(), scale=new_diff_dist.std())\n",
    "    mean_loss = tr_loss.mean() * new_diff_dist.cdf(0)\n",
    "    s2 = approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N+dN)\n",
    "    new_diff_dist2 = stats.norm(loc=approx_diff_dist.mean(), scale=s2)\n",
    "    a2, b2 = -np.inf, (0 - new_diff_dist2.mean()) / new_diff_dist2.std()\n",
    "    tr_loss2 = stats.truncnorm(a=a2, b=b2, loc=new_diff_dist2.mean(), scale=new_diff_dist2.std())\n",
    "    mean_loss2 = tr_loss2.mean() * new_diff_dist2.cdf(0)\n",
    "    d_loss = (mean_loss2 - mean_loss) / dN\n",
    "    loss_diff = new_diff_dist.pdf(0) * s**2 / (2 * N)\n",
    "    #loss_diff = stats.norm.pdf(mu/s) * s / (2 * N)\n",
    "    res.append((N, mu, s, p, mean_loss, d_loss, loss_diff))\n",
    "    \n",
    "#res = [(N, approx_diff_dist.std() * np.sqrt(na+nb) / np.sqrt(N)) for N in range(na+nb, 1000000, 100)]\n",
    "\n",
    "df_res = pd.DataFrame(res, columns=['N', 'mu', 'std', 'p', 'mean_loss', 'd_loss', 'loss_diff'])\n",
    "df_res\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "#fig.add_trace(go.Scatter(x=df['N'], y=df['std'] * 100, \n",
    "#                         line_color='blue', name='std * 100'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['p'], \n",
    "                         line_color='black', name='p'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['mean_loss'] * 100, \n",
    "                         line_color='red', name='mean_loss * 100'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['mu']*10, \n",
    "                         line_color='yellow', name='mu*10'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['d_loss'] * 1000000, \n",
    "                         line_color='green', name='d_loss * 1000000'))\n",
    "fig.add_trace(go.Scatter(x=df_res['N'], y=df_res['loss_diff'] * 1000000, \n",
    "                         line_color='purple', name='loss_diff * 1000000'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a7e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f21e392f",
   "metadata": {},
   "source": [
    "Ожидаемые потери аналитически \n",
    "$$\n",
    "\\frac{d I(N)}{dN} < \\frac{w_A}{M} (\\mu_B - \\mu_A)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "I(N) &= \\int_{-\\infty}^{0} x \\mathcal N(x; m, \\sigma^2) dx\n",
    "  = \\int_{-\\infty}^{0} \\big(x + m - m\\big) \\mathcal N(x;m,\\sigma^2) dx \n",
    "  \\\\\n",
    "  & = m \\int_{-\\infty}^{0} \\mathcal N(x;m,\\sigma^2) dx + \\int_{-\\infty}^{0} (x-m) \\mathcal N(x;m,\\sigma^2) dx \n",
    "  \\\\\n",
    "  &= m \\Phi \\left(\\tfrac{0-m}{\\sigma}\\right) + \\sigma \\int_{-\\infty}^{(0-m)/\\sigma} t \\varphi(t) dt \n",
    "  = m \\Phi \\left(-\\tfrac{m}{\\sigma}\\right) - \\sigma \\varphi \\left(-\\tfrac{m}{\\sigma}\\right)\n",
    "  \\\\\n",
    "  & = m \\Phi \\left(-\\tfrac{m}{\\sigma}\\right) - \\sigma \\varphi \\left(\\tfrac{m}{\\sigma}\\right)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "При $\\sigma(N) = \\sigma_0 \\sqrt{N_0 / N}$:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "I(N) &= m\\,\\Phi\\!\\left(-\\tfrac{m}{\\sigma(N)}\\right) \\;-\\; \\sigma(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right), \\\\[6pt]\n",
    "\\frac{dI}{dN}\n",
    "&= m\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\\cdot\\frac{m\\,\\sigma'(N)}{\\sigma(N)^2}\n",
    "\\;-\\;\\Big[\\sigma'(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "+ \\sigma(N)\\,\\varphi'\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\\cdot\\frac{dz}{dN}\\Big], \\\\[6pt]\n",
    "&= \\frac{m^2\\sigma'(N)}{\\sigma(N)^2}\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "- \\sigma'(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "- \\frac{m^2\\sigma'(N)}{\\sigma(N)^2}\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right), \\\\[6pt]\n",
    "&= -\\,\\sigma'(N)\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right).\n",
    "\\end{split}\n",
    "\\\\\n",
    "\\sigma'(N) = -\\sigma(N) / 2 N \n",
    "\\\\\n",
    "\\frac{dI}{dN} \\;=\\; \\frac{\\sigma(N)}{2N}\\,\\varphi\\!\\left(\\tfrac{m}{\\sigma(N)}\\right)\n",
    "= \\frac{\\sigma(N)^2}{2N} Norm\\left(0; \\mu_B - \\mu_A, \\sigma^2 \\right)\n",
    "$$\n",
    "\n",
    "Условие остановки\n",
    "$$\n",
    "\\frac{\\sigma(N)^2}{2N} Norm\\left(0; \\mu_B - \\mu_A, \\sigma^2 \\right) < \\frac{w_A}{M} (\\mu_B - \\mu_A)\n",
    "\\\\\n",
    "Norm\\left(0; \\mu_B - \\mu_A, \\sigma^2 \\right) < 2 w_A \\frac{N}{M} \\frac{(\\mu_B - \\mu_A)}{\\sigma(N)^2}\n",
    "\\\\\n",
    "\\phi(z) < 2 w_A \\frac{N}{M} z, \\quad z = \\frac{\\mu_B - \\mu_A}{\\sigma}, \\quad \\phi(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e924289",
   "metadata": {},
   "source": [
    "Ограничение хвостов нормального распределения https://en.wikipedia.org/wiki/Mills_ratio .  \n",
    "Т.к. $u/z \\ge 1, u \\in [z, \\infty)$\n",
    "\n",
    "$$\n",
    "\\Phi(-z) \n",
    "= \\frac{1}{\\sqrt{2\\pi}}\\int_{z}^{\\infty} e^{-u^{2}/2}\\,du\n",
    "\\;\\le\\; \\frac{1}{\\sqrt{2\\pi}}\\int_{z}^{\\infty} \\frac{u}{z} e^{-u^{2}/2}\\,du\n",
    "= \\frac{1}{z\\sqrt{2\\pi}} e^{-z^{2}/2}\n",
    "= \\frac{\\varphi(z)}{z}, \\qquad z>0 .\n",
    "$$\n",
    "\n",
    "Условие остановки: вероятность группа B хуже (левый хвост) ограничена сверху $Norm(x)/x$ меньше $2w_A N/M$. \n",
    "\n",
    "$$\n",
    "F(0; \\mu_B - \\mu_A, \\sigma^2) < \\frac{\\phi(z)}{z} < 2w_A \\frac{N}{M}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80943ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45ac51cb",
   "metadata": {},
   "source": [
    "Считать время на изменение решения.  \n",
    "Готовы ли держать еще столько времени?  \n",
    "Это способ оценить расходы на поддержание эксперимента на глаз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4533f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f66cabfe",
   "metadata": {},
   "source": [
    "Оценки длительности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3343773",
   "metadata": {},
   "source": [
    "Есть оценка распределения. Или априорное распределение. Как оценить длительность эксп?\n",
    "\n",
    "При остановке по достижении вероятности:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pb - pa\n",
    "s = np.sqrt((pb*(1-pb)/df['N']) + (pa*(1-pa)/df['N']))\n",
    "pbgtpa = [1-stats.norm(loc=mu, scale=s).cdf(0) for s in s]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'],\n",
    "                         line_color='red', name='pb_gt_pa, simulated'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=pbgtpa,\n",
    "                         line_color='black', line_dash='dash', name='pb_gt_pa, fixed mean'))\n",
    "fig.update_layout(title='P(pB > pA)',\n",
    "                  xaxis_title='$N$',\n",
    "                  yaxis_range=[0, 1.05],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80045465",
   "metadata": {},
   "source": [
    "Проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a370a4",
   "metadata": {},
   "source": [
    "Фиксированный эффект.  \n",
    "Оценивается длительность.  \n",
    "Сравнивается с фактической в неск. эксп.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ae8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pb - pa\n",
    "N = np.arange(1000, 150000, 1000)\n",
    "s = [np.sqrt((pb*(1-pb)/n) + (pa*(1-pa)/n)) for n in N]\n",
    "pbgtpa = np.array([1-stats.norm(loc=mu, scale=s).cdf(0) for s in s])\n",
    "\n",
    "Ndr = N[pbgtpa > 0.95][0]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=N, y=pbgtpa,\n",
    "                         line_color='black', line_dash='dash', name='pb_gt_pa, fixed mean'))\n",
    "fig.add_vline(Ndr)\n",
    "fig.update_layout(title='P(pB > pA)',\n",
    "                  xaxis_title='$N$',\n",
    "                  yaxis_range=[0, 1.05],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d41bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 0.1\n",
    "pb = pa * 1.03\n",
    "p_stop = 0.95\n",
    "nmax = 5000000\n",
    "nstep = 100\n",
    "\n",
    "nexp = 1000\n",
    "\n",
    "won = []\n",
    "nstop = []\n",
    "for ne in range(nexp):\n",
    "    N = np.arange(nstep, nmax + nstep, nstep)\n",
    "    sa = stats.binom.rvs(p=pa, n=nstep, size=nmax//nstep)\n",
    "    sb = stats.binom.rvs(p=pb, n=nstep, size=nmax//nstep)\n",
    "    Sa = sa.cumsum()\n",
    "    Sb = sb.cumsum()\n",
    "    Pa = Sa / N\n",
    "    Pb = Sb / N\n",
    "    #for n, pa_n, pb_n in zip(N, Pa, Pb):\n",
    "        #mu = pb_n - pa_n\n",
    "        #sigma = np.sqrt((pb_n*(1-pb_n)/n) + (pa_n*(1-pa_n)/n))\n",
    "    for n, sa_n, sb_n in zip(N, Sa, Sb):\n",
    "        post_a = posterior_dist_binom(sa_n, n)\n",
    "        post_b = posterior_dist_binom(sb_n, n)\n",
    "        mu = post_b.mean() - post_a.mean()\n",
    "        sigma = np.sqrt(post_a.std()**2 + post_b.std()**2)\n",
    "        pbgtpa = 1 - stats.norm(loc=mu, scale=sigma).cdf(0)\n",
    "        pbest = np.maximum(pbgtpa, 1-pbgtpa)\n",
    "        if pbest > p_stop:\n",
    "            #nstop.append(np.argmax(pbest > p_stop))\n",
    "            nstop.append(n)\n",
    "            #won.append('B' if pb_n > pa_n else 'A')\n",
    "            won.append('B' if sb_n > sa_n else 'A')\n",
    "            break\n",
    "#nstop\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_histogram(x=nstop, xbins={'start':0, 'size':nstep, 'end':nmax})\n",
    "fig.add_vline(Ndr)\n",
    "fig.show()\n",
    "\n",
    "vals, counts = np.unique(won, return_counts=True)\n",
    "print('Best gr: ', dict(zip(vals, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57446b1",
   "metadata": {},
   "source": [
    "Много ошибок из-за ранних остановок.   \n",
    "Чем меньше nstep, тем больше ошибок.  \n",
    "Чем больше nstep, тем ближе доля ошибок к заявленной.  \n",
    "\n",
    "Попробовать выставлять минимальное время для эксп.  \n",
    "Но основании ожидаемого эффекта.  \n",
    "Скажем, треть времени.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4597bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_histogram(x=nstop, xbins={'start':0, 'size':nstep, 'end':nmax})\n",
    "fig.add_vline(Ndr)\n",
    "fig.show()\n",
    "\n",
    "vals, counts = np.unique(won, return_counts=True)\n",
    "print('Best gr: ', dict(zip(vals, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266a3d1",
   "metadata": {},
   "source": [
    "Разброс непредсказуемый.  \n",
    "Даже если угадать эффект, сделанная оценка длительности говорит не ясно о чем. \n",
    "\n",
    "Вместо точной оценки может хватить оценки сверху.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f0e5d3",
   "metadata": {},
   "source": [
    "В реальности эффект заранее неизвестен.   \n",
    "Корректировать оценку при появлении данных.  \n",
    "- Предположить эффект.  \n",
    "- Оценить длительность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776434e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "951d82f3",
   "metadata": {},
   "source": [
    "Что будет, если использовать другой критерий остановки?  \n",
    "Какая будет точность?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05cd1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30040e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fd3ad3d",
   "metadata": {},
   "source": [
    "Ссылки\n",
    "\n",
    "https://en.wikipedia.org/wiki/Expected_value_of_sample_information  \n",
    "\n",
    "https://en.wikipedia.org/wiki/Truncated_normal_distribution  \n",
    "\n",
    "https://en.wikipedia.org/wiki/Mills_ratio\n",
    "\n",
    "https://en.wikipedia.org/wiki/Conjugate_prior\n",
    "\n",
    "https://en.wikipedia.org/wiki/Posterior_predictive_distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Beta-binomial_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b39d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42b843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc393572",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "P_{p_A}(x) = \\mbox{Beta}(x; n_{s_A} + \\alpha, N_A - n_{s_A} + \\beta)\n",
    "& \\approx \\mbox{Norm}(x; \\mu_A, \\sigma_A^2),\n",
    "\\quad\n",
    "\\mu_A = (n_{s_A} + \\alpha - 1) /N_A, \n",
    "\\,\n",
    "\\sigma_A^2 = \\mu_A (1 - \\mu_A) / N_A,\n",
    "\\quad\n",
    "N_A \\gg n_{s_A} \\gg 1\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B}(x) = \\mbox{Beta}(x; n_{s_B} + \\alpha, N_B - n_{s_B} + \\beta)\n",
    "& \\approx \\mbox{Norm}(x; \\mu_B, \\sigma_B^2),\n",
    "\\quad\n",
    "\\mu_B = (n_{s_B} + \\alpha - 1)/N_B, \n",
    "\\,\n",
    "\\sigma_B^2 = \\mu_B (1 - \\mu_B) / N_B,\n",
    "\\quad\n",
    "N_B \\gg n_{s_B} \\gg 1\n",
    "\\\\\n",
    "\\\\\n",
    "P_{p_B - p_A}(x) = \n",
    "\\int_{-\\infty}^{\\infty} dy P_{p_B}(y) P_{p_A}(y-x)\n",
    "& \\approx \\mbox{Norm}\\left(x; \\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2\\right),\n",
    "\\quad\n",
    "\\mbox{Norm}(x ; \\mu, \\sigma^2) \\equiv \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\tfrac{(x-\\mu)^2}{2 \\sigma^2} }\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aba197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1489e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06289424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "def posterior_binom_approx_95pdi(post_dist):\n",
    "    lower = post_dist.ppf(0.025)\n",
    "    upper = post_dist.ppf(0.975)\n",
    "    return lower, upper\n",
    "\n",
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "npoints = 1000\n",
    "nstep = 150\n",
    "sa = stats.binom.rvs(p=pa, n=npoints, size=nstep)\n",
    "sb = stats.binom.rvs(p=pb, n=npoints, size=nstep)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['npoints'] = [npoints] * nstep\n",
    "df['sa_step'] = sa\n",
    "df['sb_step'] = sb\n",
    "df['N'] = df['npoints'].cumsum()\n",
    "df['sa'] = df['sa_step'].cumsum()\n",
    "df['sb'] = df['sb_step'].cumsum()\n",
    "df['pa'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).mean(), axis=1)\n",
    "df[['pa_lower', 'pa_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sa'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb'] = df.apply(lambda r: posterior_dist_binom(r['sb'], r['N']).mean(), axis=1)\n",
    "df[['pb_lower', 'pb_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sb'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb_gt_pa'] = df.apply(lambda r: prob_pb_gt_pa(posterior_dist_binom(r['sa'], r['N']), posterior_dist_binom(r['sb'], r['N']), post_samp=10_000), axis=1)\n",
    "df['diff_mu'] = df.apply(lambda r: r['pb'] - r['pa'], axis=1)\n",
    "df['diff_s'] = df.apply(lambda r: np.sqrt(posterior_dist_binom(r['sa'], r['N']).std()**2 + posterior_dist_binom(r['sb'], r['N']).std()**2), axis=1)\n",
    "df[['diff_lower', 'diff_upper']] = df.apply(lambda r: (r['diff_mu'] - 2*r['diff_s'], r['diff_mu'] + 2*r['diff_s']), axis=1, result_type=\"expand\")\n",
    "#todo: loss\n",
    "\n",
    "xaxis_min = -0.05\n",
    "xaxis_max = 0.15  \n",
    "#x = np.linspace(0, xaxis_max, 1000)\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "for N, o in [(1000, 0.3), (10000, 1)]:\n",
    "    dist_a = posterior_dist_binom(df[df['N'] == N]['sa'], N)\n",
    "    dist_b = posterior_dist_binom(df[df['N'] == N]['sb'], N)\n",
    "    fig.add_trace(go.Scatter(x=x, y=dist_a.pdf(x), line_color='red', opacity=o, name=f'А, N={N}'))\n",
    "    fig.add_trace(go.Scatter(x=x, y=dist_b.pdf(x), line_color='blue', opacity=o, name=f'Б, N={N}'))\n",
    "    #\n",
    "    diff = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "    fig.add_trace(go.Scatter(x=x, y=diff.pdf(x), line_color='black', opacity=o, name=f'Diff, N={N}'))\n",
    "    fig.update_layout(title='Апостериорные распределения',\n",
    "                      xaxis_title='$p$',\n",
    "                      yaxis_title='Плотность вероятности',\n",
    "                      xaxis_range=[xaxis_min, xaxis_max],\n",
    "                      hovermode=\"x\",\n",
    "                      height=500)\n",
    "#     fig.update_layout(title='Апостериорные распределения',\n",
    "#                       xaxis_title='$p$',\n",
    "#                       yaxis_title='Плотность вероятности',\n",
    "#                       xaxis_range=[0, xaxis_max],\n",
    "#                       hovermode=\"x\",\n",
    "#                       height=500)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# xaxis_min = -0.05\n",
    "# xaxis_max = 0.15    \n",
    "# x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "# fig = go.Figure()\n",
    "# for N in [1000, 10000]:\n",
    "#     diff = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "#     fig.add_trace(go.Scatter(x=x, y=diff.pdf(x), line_color='black', name=f'Diff, N={N}'))\n",
    "#     fig.update_layout(title='Апостериорные распределения',\n",
    "#                       xaxis_title='$p$',\n",
    "#                       yaxis_title='Плотность вероятности',\n",
    "#                       xaxis_range=[xaxis_min, xaxis_max],\n",
    "#                       hovermode=\"x\",\n",
    "#                       height=500)\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pa'], name='A',\n",
    "                         line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pa_upper']) + list(reversed(df['pa_lower'])),\n",
    "                         fill=\"toself\", name='A, 95% PDI', marker_color='red', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb'], name='B',\n",
    "                         line_color='blue'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pb_upper']) + list(reversed(df['pb_lower'])),\n",
    "                         fill=\"toself\", name='B, 95% PDI', marker_color='blue', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_mu'], name='Diff',\n",
    "                         line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['diff_lower']) + list(reversed(df['diff_upper'])),\n",
    "                         fill=\"toself\", name='A, 95% PDI', marker_color='black', opacity=0.2))\n",
    "fig.update_layout(title='$p_A, p_B$',\n",
    "                  yaxis_tickformat = ',.1%',\n",
    "                  xaxis_title='N',\n",
    "                  height=700)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=df['N'], y=df['diff_mu'], name='$p_B - p_A$',\n",
    "#                          line_color='black'))\n",
    "# fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "#                          y=list(df['diff_lower']) + list(reversed(df['diff_upper'])),\n",
    "#                          fill=\"toself\", name='$p_B - p_A, \\mbox{ 95% PDI}$', marker_color='black', opacity=0.2))\n",
    "# fig.update_layout(title='$p_B - p_A$',\n",
    "#                   yaxis_tickformat = ',.1%',\n",
    "#                   xaxis_title='N')\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'], name='P(pb > pa)',\n",
    "#                          line_color='black'))\n",
    "# fig.update_layout(title='$P(p_B > p_A)$',\n",
    "#                   yaxis_range=[0, 1],\n",
    "#                   xaxis_title='N')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbd502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "approx_diff_dist = stats.norm(loc=df[df['N'] == N]['diff_mu'], scale=df[df['N'] == N]['diff_s'])\n",
    "\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=approx_diff_dist.pdf(x), \n",
    "                         line_color='black', name='$\\mbox{Аналитическое приближение}$'))\n",
    "# fig.add_trace(go.Scatter(x=[approx_diff_dist.mean()[0], approx_diff_dist.mean()[0]], \n",
    "#                          y=[0, max(approx_diff_dist.pdf(x))], \n",
    "#                          line_color='black', mode='lines', name='mean'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=approx_diff_dist.pdf(x[x<0]), fill='tozeroy',\n",
    "                         line_color='black', opacity=0.3, name='loss'))\n",
    "# fig.add_trace(go.Scatter(x=x[x>=0], y=approx_diff_dist.pdf(x[x>=0]), \n",
    "#                          line_color='black', fillcolor='white', name='gain', fill='tozeroy'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(approx_diff_dist.pdf(x))*1.05], \n",
    "                         line_color='black', mode='lines', line_dash='dash', showlegend=False))\n",
    "fig.update_layout(title='$p_B - p_A$',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9df690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28575a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pb - pa\n",
    "s = np.sqrt((pb*(1-pb)/df['N']) + (pa*(1-pa)/df['N']))\n",
    "pbgtpa = [1-stats.norm(loc=mu, scale=s).cdf(0) for s in s]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['diff_s']*10,\n",
    "                         line_color='red', name='s*10, simulated'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=s*10,\n",
    "                         line_color='black', line_dash='dash', name='s*10, fixed mean'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'],\n",
    "                         line_color='red', name='pb_gt_pa, simulated'))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=pbgtpa,\n",
    "                         line_color='black', line_dash='dash', name='pb_gt_pa, fixed mean'))\n",
    "#todo: loss\n",
    "fig.update_layout(title='Стандартное отклонение pB - pA',\n",
    "                  xaxis_title='$N$',\n",
    "                  #yaxis_title='sigma',\n",
    "                  #xaxis_range=[-0.1, 0.1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)  \n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
