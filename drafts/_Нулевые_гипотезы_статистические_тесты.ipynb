{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91cab33",
   "metadata": {},
   "source": [
    "# Нулевые гипотезы, статистические тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a519a4",
   "metadata": {},
   "source": [
    "В проверках нулевых гипотез формулируют гипотезу $H_0$ о данных $\\mathcal{D}$. Выбирают статистический тест $T$ - случайную величину с известным распределением $P_{T}(x | H_0)$ в предположении $H_0$. Считают реализацию величины $T$ в данных - тестовую статистику $x_{0}$ [[TestStat](https://en.wikipedia.org/wiki/Test_statistic)]. Вероятность получить фактическое или более экстремальное значение тестовой статистики называют $p$-значением $p = P_{T}(x \\ge x_{0} | H_0)$ [[PVal](https://en.wikipedia.org/wiki/P-value), [TailedTests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests)]. Если вероятность «достаточно мала», гипотезу $H_0$ «отвергают», если нет - «оставляют»."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d41335",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../figs/null_hypothesis.png\" alt=\"null_hypothesis\" width=\"800\"/>\n",
    "<em> В проверках нулевых гипотез формулируют гипотезу $H_0$ и выбирают статистический тест $T$ - случайную величину с известным распределением $P_{T}(x | H_0)$ в предположении $H_0$. Считают реализацию величины $T$ в данных - тестовую статистику $x_{0}$. Вероятность получить фактическое или более экстремальное значение тестовой статистики называют $p$-значением $p = P_{T}(x \\ge x_{0} | H_0)$. Если вероятность «достаточно мала», гипотезу $H_0$ «отвергают», если нет - «оставляют». </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46499a53",
   "metadata": {},
   "source": [
    "Основная проблема метода - решение принимается по $p$-значению $p = P_{T}(x \\ge x_{0} | H_0)$, тогда как для оценки гипотезы нужна вероятность $P(H_0 | x_0)$. По соотношению Байеса $P(H_0 | x_0) \\propto P_{T}(x = x_{0} | H_0) P(H_0)$. Т.е. для выбора гипотезы нужно посчитать вероятности получить данные в рамках конкурирующих гипотез и сравнить друг с другом с учетом априорных вероятностей.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97cba49",
   "metadata": {},
   "source": [
    "В А/Б-тестах нужно выбрать группу с большим значением целевой метрики. Распространенные применения проверок нулевых гипотез к А/Б-тестам включают $t$-тест для средних, $\\chi^2$-тест пропорций и $U$-критерий Манна-Уитни. Для них $p$-значение численно близко вероятности метрик одной группы больше другой, хотя отличается по определению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e63c00",
   "metadata": {},
   "source": [
    "## Т-тест"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a120f",
   "metadata": {},
   "source": [
    "Средние могут сравнивать $t$-тестами [[TTest](https://en.wikipedia.org/wiki/Student%27s_t-test)]. Пусть есть выборки размера $N_A, N_B$ из двух случайных величин $A, B$. По выборочным средним $\\mu_A, \\mu_B$ и дисперсиям $s_A^2, s_B^2$ оценивают среднее и дисперсию разности $\\mu_{\\Delta} = \\mu_B - \\mu_A$, $s^2_{\\Delta} = s_A^2/N_A + s_B^2/N_B$. Считают отношение $x_0 = \\mu_{\\Delta}/s_{\\Delta}$. Предполагают, что средние в группах одинаковы. Тогда для отношения $\\mu_{\\Delta}/s_{\\Delta}$ ожидают $t$-распределение. При достаточно большом количестве данных оно близко стандартному нормальному $\\text{Norm}(0, 1)$ [[WelchT](https://en.wikipedia.org/wiki/Welch%27s_t-test)]. Вычисляют вероятность получить фактическое $x_0$ или более экстремальное отношение - $p$-значение $P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)$. Если оно \"достаточно мало\", считают средние в группах неравными.\n",
    "\n",
    "$$\n",
    "x_0 = \\frac{\\mu_{\\Delta}}{s_{\\Delta}},\n",
    "\\quad\n",
    "\\mu_{\\Delta} = \\mu_B - \\mu_A,\n",
    "\\quad\n",
    "s^2_{\\Delta} = \\frac{s_A^2}{N_A} + \\frac{s_B^2}{N_B}\n",
    "\\\\\n",
    "P_{\\mu_{\\Delta}/s_{\\Delta}}(x | \\mu_A = \\mu_B) \\approx \\text{Norm}(x; 0, 1)\n",
    "\\\\\n",
    "p = P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e3130",
   "metadata": {},
   "source": [
    "В А/Б-тесте нужно выбрать группу с большим средним. Поэтому вместо $p$-значения $P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)$ интересна вероятность среднего $B$ больше $A$ при условии собранных данных $P(\\mu_B > \\mu_A | x_0 )$. Эту вероятность можно оценить байесовским моделированием. В пренебрежении априорными значениями приближенно $\\mu_B - \\mu_A \\sim \\text{Norm}(\\mu_{\\Delta}, s^2_{\\Delta})$. Поэтому $P(\\mu_B > \\mu_A | x_0 ) \\approx P(\\text{Norm}(x < 0 | x_0, 1))$. В общем случае связь $p$-значения с этой вероятностью не очевидна. Для $t$-тестов по симметрии нормального распределения $P(\\text{Norm}(x > x_0 | 0, 1)) =  P(\\text{Norm}(x < 0 | x_0, 1))$. Поэтому $p$-значение одностороннего $t$-теста близко вероятности среднего одной группы больше другой.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)\n",
    "& = P(\\text{Norm}(x > x_0 | 0, 1)) \n",
    "\\\\\n",
    "& =  P(\\text{Norm}(x < 0 | x_0, 1)) \n",
    "\\approx P(\\mu_B > \\mu_A | x_0 )\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5614ef",
   "metadata": {},
   "source": [
    "На графике ниже 2 нормальных распределения. Одно с центром в точке 0, другое в точке $x_0 = 2$. Вероятность \n",
    "$P(x > x_0 | \\mu_A = \\mu_B)$ p-значение закрашено темным, $P(\\mu_B > \\mu_A | x_0 )$ закрашено светлым. По свойствам нормального распределения площади этих областей совпадают. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mud = 2\n",
    "s = 1\n",
    "\n",
    "xaxis_min = -7\n",
    "xaxis_max = 7\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name=f'$Norm(0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[mud, mud], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$x_0$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>mud], y=stats.norm.pdf(x[x>mud], loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name=f'$P(x > x_0 | \\Delta \\mu=0)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mud, scale=s), \n",
    "                         line_color='black', opacity=0.3, name=f'$Norm(x_0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '0'], textposition=\"top center\", \n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=stats.norm.pdf(x[x<0], loc=mud, scale=s), \n",
    "                         line_color=\"rgba(128, 128, 128, 0.3)\", name=f'$P(x < 0 | \\Delta \\mu / s_\\Delta = x_0)$', fill=\"tozeroy\", fillcolor=\"rgba(128, 128, 128, 0.3)\"))\n",
    "fig.update_layout(title='P-значение и вероятность среднего одной группы больше другой',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d8603",
   "metadata": {},
   "source": [
    "Т.е. $p$-значение одностороннего $t$-теста близко байесовской оценке вероятности, что среднее одной группы больше другой. Ниже заданы два распределения Бернулли с разными конверсиями. Из них делается выборка. По выброрке строится байесовская оценка вероятности $P(p_B > p_A)$ и вычисляется $t$-тест. $T$-тест задается односторонний с разными дисперсиями групп (параметры `equal_var=False, alternative='greater'`). Видно, что p-значение близко байесовской оценке вероятности. При этом стоит помнить, что они не совпадают в точности - у них разные определения, также p-значение игнорирует априорные вероятности гипотез. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "pA = 0.1\n",
    "pB = pA * 1.05\n",
    "\n",
    "exactA = stats.bernoulli(pA)\n",
    "exactB = stats.bernoulli(pB)\n",
    "\n",
    "N = 30000\n",
    "sampA = exactA.rvs(size=N)\n",
    "sampB = exactB.rvs(size=N)\n",
    "\n",
    "post_dist_A = posterior_dist_binom(ns=np.sum(sampA), ntotal=N)\n",
    "post_dist_B = posterior_dist_binom(ns=np.sum(sampB), ntotal=N)\n",
    "pb_gt_pa = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "\n",
    "# p_diff = sampB.mean() - sampA.mean()\n",
    "# s_diff = np.sqrt(sampA.std()**2 / N + sampB.std()**2 / N)\n",
    "# diff = stats.norm(loc=p_diff, scale=s_diff)\n",
    "# pb_gt_pa = diff.cdf(0)\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(sampA, sampB, equal_var=False, alternative='greater')\n",
    "\n",
    "print(f'P(pb > pa): {pb_gt_pa}')\n",
    "print(f'p-value P(x>x0 | pa=pb): {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c419d18",
   "metadata": {},
   "source": [
    "Интерпретацию $p$-значения $t$-теста можно проверить по количеству правильно угаданных вариантов с большим значением конверсии в серии экспериментов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p-val'])\n",
    "\n",
    "p = 0.1\n",
    "nexps = 300\n",
    "cmp['A'] = [p] * nexps\n",
    "cmp['B'] = p * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 3_000_000\n",
    "n_samp_step = 10_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    pA = cmp.at[i, 'A']\n",
    "    pB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.bernoulli(p=pA)\n",
    "    exact_dist_B = stats.bernoulli(p=pB)\n",
    "    n_samp_total = 0\n",
    "    ns_A = 0\n",
    "    ns_B = 0\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA = exact_dist_A.rvs(n_samp_step)\n",
    "        dB = exact_dist_B.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        ns_A = ns_A + np.sum(dA)\n",
    "        ns_B = ns_B + np.sum(dB)\n",
    "        T_A = np.zeros(n_samp_total)\n",
    "        T_A[:ns_A] = 1\n",
    "        T_B = np.zeros(n_samp_total)\n",
    "        T_B[:ns_B] = 1\n",
    "        t_stat, p_value = stats.ttest_ind(T_A, T_B, equal_var=False, alternative='greater')\n",
    "        best_gr = 'B' if p_value >= prob_stop else 'A' if (1 - p_value) >= prob_stop else None\n",
    "        if best_gr:\n",
    "            post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "            post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "            pb_gt_pa_bayes = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "            cmp.at[i, 'A_exp'] = ns_A / n_samp_total\n",
    "            cmp.at[i, 'B_exp'] = ns_B / n_samp_total\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p-val'] = max(p_value, 1 - p_value)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, Bayes P(b>a) {pb_gt_pa_bayes:.4f}, T-test p-val {p_value:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3ec00",
   "metadata": {},
   "source": [
    "## Тест $\\chi^2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf2192",
   "metadata": {},
   "source": [
    "Хи-квадрат - сумма квадратов нормальных случайных величин."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad30ce",
   "metadata": {},
   "source": [
    "$$\n",
    "X \\sim \\text{Binomial}(n,p), \\quad O = x, \\quad E = np\n",
    "\\\\\n",
    "\\chi^2\n",
    "=\n",
    "\\frac{(x - np)^2}{np}\n",
    "+\n",
    "\\frac{((n - x) - n(1-p))^2}{n(1-p)}\n",
    "=\n",
    "\\frac{(x - np)^2}{np(1-p)}\n",
    "\\\\\n",
    "Z = \\frac{x - np}{\\sqrt{np(1-p)}}, \\quad \\chi^2 = Z^2, \\quad \\chi^2 \\sim \\chi^2_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ee6e9",
   "metadata": {},
   "source": [
    "Для конверсий 2 групп эквивалентен расчету разности средних.  \n",
    "В итоге $p$-значение близко вероятности одной группы больше другой.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1e211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "726f9f73",
   "metadata": {},
   "source": [
    "## U-критерий Манна-Уитни"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607868a8",
   "metadata": {},
   "source": [
    "$U$- статистика - попарное сравнение элементов в выборках"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcceca1",
   "metadata": {},
   "source": [
    "$$\n",
    "U_A = \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_B} I(X_i > Y_j) \n",
    "      + \\frac{1}{2} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_B} I(X_i = Y_j)\n",
    "\\\\\n",
    "\\text{where } I(\\text{condition}) =\n",
    "\\begin{cases} \n",
    "1 & \\text{if condition is true} \\\\ \n",
    "0 & \\text{if condition is false} \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9962e4eb",
   "metadata": {},
   "source": [
    "Можно записать через сумму рангов\n",
    "\n",
    "$$\n",
    "U_A = R_A - \\frac{n_A (n_A + 1)}{2}\n",
    "\\\\\n",
    "\\text{where } \n",
    "R_A = \\sum_{i=1}^{n_A} \\text{rank}(X_i)\n",
    "\\text{ is the sum of ranks of group A in the combined dataset.}\n",
    "$$\n",
    "\n",
    "$n_A (n_A + 1)/2$ - минимальный ранг если все элементы A меньше B, считается как арифметическая прогрессия.\n",
    "Если наибольший элемент A больше $n$ элементов B, то $U_A = n$ и $R_A = n_A (n_A + 1)/2 + n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09c462",
   "metadata": {},
   "source": [
    "Интерпретация $U$-статистики: $U_A / n_A n_B$ - вероятность элемента выборки A больше B. $U_A$ - число элементов A больше B, $n_A n_B$ - общее количество пар.\n",
    "\n",
    "$$\n",
    "\\frac{U_A}{n_A n_B} = P(X > Y) + \\frac{1}{2} P(X = Y)\n",
    "\\\\\n",
    "\\text{where } \n",
    "X \\sim \\text{an observation from group A}, \\quad\n",
    "Y \\sim \\text{an observation from group B}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a25600",
   "metadata": {},
   "source": [
    "$U/n_A n_B$ интерпретируется как вероятность элемента A больше B.  \n",
    "Сравниваются не средние, а все распределение.  \n",
    "Вероятность $U/n_A n_B$ может не доходить до 1.   \n",
    "Будет набираться дольше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6f75f",
   "metadata": {},
   "source": [
    "Нулевая гипотеза - выборки A и B из одинакового распределения. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b91fd9",
   "metadata": {},
   "source": [
    "$$\n",
    "Z = \\frac{U - E[U]}{\\sqrt{\\text{Var}(U)}} \\sim N(0,1)\n",
    "\\\\\n",
    "\\text{where } \n",
    "E[U] = \\frac{n_A n_B}{2}, \\quad\n",
    "\\text{Var}(U) = \\frac{n_A n_B (n_A + n_B + 1)}{12}\n",
    "\\\\\n",
    "n_A, n_B \\gg 10\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76adf428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "mu1, sigma1 = 0, 1\n",
    "mu2, sigma2 = 0.005, 1\n",
    "exactA = stats.norm(loc=mu1, scale=sigma1)\n",
    "exactB = stats.norm(loc=mu2, scale=sigma2)\n",
    "\n",
    "p_b_gt_a_norm = stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "\n",
    "nstep = 1000\n",
    "nmax = 100000\n",
    "u_norm_values = []\n",
    "p_values = []\n",
    "n = []\n",
    "sampA = np.array([])\n",
    "sampB = np.array([])\n",
    "\n",
    "for ntotal in range(nstep, nmax, nstep):\n",
    "    dA = exactA.rvs(nstep)\n",
    "    dB = exactB.rvs(nstep)\n",
    "    sampA = np.concatenate([sampA, dA])\n",
    "    sampB = np.concatenate([sampB, dB])\n",
    "    U, p = mannwhitneyu(sampA, sampB, alternative='less')\n",
    "    n.append(ntotal)\n",
    "    u_norm_values.append(U / (ntotal * ntotal))\n",
    "    p_values.append(p)\n",
    "\n",
    "    \n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactA.pdf(x),\n",
    "    mode='lines', name='A'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactB.pdf(x),\n",
    "    mode='lines', name='B'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"A, B\",\n",
    "    template=\"plotly_white\",\n",
    "    yaxis_range=[0,1.1]\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n, y=u_norm_values,\n",
    "    mode='lines+markers',\n",
    "    name='Normalized U (U / n^2)'\n",
    "))\n",
    "fig.add_trace(go.Scatter(x=[n[0], n[-1]], y=[p_b_gt_a_norm, p_b_gt_a_norm], name='P(B>A) exact'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n, y=p_values,\n",
    "    mode='lines+markers',\n",
    "    name='p-values'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"Mann-Whitney U Statistic vs Sample Size\",\n",
    "    xaxis_title=\"Sample size (n_A = n_B)\",\n",
    "    yaxis_title=\"Normalized U\",\n",
    "    legend_title=\"Metric\",\n",
    "    template=\"plotly_white\",\n",
    "    yaxis_range=[0,1.1]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd28d39",
   "metadata": {},
   "source": [
    "Аналитическое значение P(X > Y): интеграл по всем x от плотности вероятности f_X(x) * функцию распределения F_Y(x) * dx (конкретное x * вероятность выпадения в X * вероятность выпадения такого или меньшего значения в Y).\n",
    "\n",
    "Для нормальных A, B аналитически: $P(B>A) = F_{B-A}(0) = \\Phi(0, \\mu_B - \\mu_A, s_A^2 + s_B^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6701a784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b5455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220bb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d0c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6674ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c46af69",
   "metadata": {},
   "source": [
    "Важна формулировка гипотезы. В качестве нулевой гипотезы $H_0$ часто предполагают равенство групп (нулевой эффект). В А/Б-тестах нужно проверить не равенство групп, а выбрать группу с большим значением целевой метрики. Поэтому вместо гипотез вида $H_0: p_A = p_B$ нужны $H: p_A > p_B$.\n",
    "\n",
    "В общем случае использовать $p$-значение для оценки гипотез некорректно. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1929a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "015cd718",
   "metadata": {},
   "source": [
    "В распространных применениях проверок нулевых гипотез к А/Б-тестам $p$-значение оказывается численно близко вероятности метрик одной группы больше другой. Ниже рассмотрены $t$-теста, $\\chi^2$-теста для двух пропорций и $U$-критерия Манна-Уитни."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1157cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fc37b5c",
   "metadata": {},
   "source": [
    "В проверках нулевых гипотез используют статистическую значимость $\\alpha$ и мощность $1-\\beta$. Они определяют вероятность P(Выбор !H0 \\cap H0) и P(Выбор H0 \\cap !H0). Их также называют ошибками первого и второго рода. Задание $\\alpha$ и $\\beta$ не достаточно для задания вероятности корректного определения гипотезы. Она также зависит от качества гипотезы $P(H_0)$. Также полезно подумать о дальнейших действиях: в А/Б - тесте оставляют вариант со значимой разницей. Т.е. нужно оставлять P(выбор !H0 \\cap H0) + P(выбор !H0 \\cap !H0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_ttest_conv_pval(sa, na, sb, nb):\n",
    "    pa = sa / na\n",
    "    pb = sb / nb\n",
    "    stderr_a = np.sqrt(pa * (1 - pa) / na)\n",
    "    stderr_b = np.sqrt(pb * (1 - pb) / nb)\n",
    "    diff = pb - pa\n",
    "    diff_stderr = np.sqrt(stderr_a**2 + stderr_b**2)\n",
    "    pval = stats.norm.cdf(0, diff, diff_stderr)\n",
    "    return pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0d80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e400f19e",
   "metadata": {},
   "source": [
    "Основная проблема метода - решение принимается по $p$-значению $p = P_{T}(x \\ge x_{0} | H_0)$, тогда как для оценки гипотезы нужна вероятность $P(H_0 | x_0)$. Ее можно получить по соотношению Байеса $P(H_0 | x_0) \\propto P_{T}(x = x_{0} | H_0) P(H_0)$. Т.е. посчитать вероятности получить данные в рамках конкурирующих гипотез и сравнить друг с другом с учетом априорных вероятностей. В общем случае $p$-значение не позволяет делать корректных выводов о рассматриваемой гипотезе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae5860",
   "metadata": {},
   "source": [
    "Если приходится иметь дело с проверками нулевых гипотез, важно обращать внимание на формулировку гипотезы. В качестве $H_0$ часто предполагают равенство групп (нулевой эффект). В А/Б-тестах нужно проверить не равенство групп, а выбрать группу с большим значением целевой метрики. Поэтому вместо гипотез вида $H_0: p_A = p_B$ нужны $H: p_A > p_B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866745b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8f5dc16",
   "metadata": {},
   "source": [
    "Для анализа А/Б-тестов используют метод проверки статистических гипотез [[StTest](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing)]. Чаще всего в таком подходе предполагают, что между вариантами нет разницы, после чего смотрят, насколько такое предположение объясняет экспериментальные данные. Если вероятность получить данные мала, считают, что предположение можно отвергнуть и между группами есть значимая разница.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634b22f1",
   "metadata": {},
   "source": [
    "Есть экспериментальные данные $\\mathcal{D}$ и гипотеза $H_0$ о данных. Выбирают «статистический тест» $T$ - случайную величину с известным распределением $P_{T}(x | H_0)$ в предположении $H_0$. По данным считают «тестовую статистику»  $x_{0}$ [[TestStat](https://en.wikipedia.org/wiki/Test_statistic)]. Вероятность получить «фактическое или более экстремальное» значение тестовой статистики называют «$p$-значением» [[PVal](https://en.wikipedia.org/wiki/P-value)]. В зависимости от контекста $p = P_{T}(x \\ge x_{0} | H_0)$, $p = P_{T}(x \\le x_{0} | H_0)$ или $p = P_{T}(|x - x_{0}| \\ge 0 | H_0)$ [[TailedTests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests)]. Если вероятность «достаточно мала», гипотезу $H_0$ «отвергают», если нет - «не отвергают»."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
