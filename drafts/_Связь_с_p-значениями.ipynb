{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059d7c01",
   "metadata": {},
   "source": [
    "# Байесовские А/Б-тесты: связь с $p$-значениями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b4a7a6",
   "metadata": {},
   "source": [
    "*Для $p$-значений $t$-теста, $\\chi^2$-теста и $U$-критерия Манна-Уитни в А/Б-тестах показана связь с байесовскими вероятностями параметров одной группы больше другой. При большом количестве данных $P$-значения численно близки байесовским вероятностям несмотря на различия в определениях.*\n",
    "\n",
    "*- [$P$-значения](#$P$-значения)*  \n",
    "*- [Т-тест](#Т-тест)*  \n",
    "*- [Тест $\\chi^2$](#Тест-$\\chi^2$)*  \n",
    "*- [U-критерий Манна-Уитни](#U-критерий-Манна-Уитни)*  \n",
    "*- [Ссылки](#Ссылки)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6b5af",
   "metadata": {},
   "source": [
    "## $P$-значения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a519a4",
   "metadata": {},
   "source": [
    "$P$-значения используют для принятия решения в проверках нулевых гипотез. В проверках нулевых гипотез формулируют гипотезу $H_0$ о данных $\\mathcal{D}$. Выбирают статистический тест $T$ - случайную величину с известным распределением $P_{T}(x | H_0)$ в предположении $H_0$. Считают реализацию величины $T$ в данных - тестовую статистику $x_{0}$ [[TestStat](https://en.wikipedia.org/wiki/Test_statistic)]. Вероятность получить фактическое или более экстремальное значение тестовой статистики называют $p$-значением $p = P_{T}(x \\ge x_{0} | H_0)$ [[PVal](https://en.wikipedia.org/wiki/P-value), [TailedTests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests)]. Если вероятность «достаточно мала», гипотезу $H_0$ «отвергают», если нет - «оставляют»."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d41335",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../figs/null_hypothesis.png\" alt=\"null_hypothesis\" width=\"800\"/>\n",
    "<em> В предположении гипотезы $H_0$ распределение тестовой статистики $P_{T}(x | H_0)$. Вероятность получить фактическое $x_0$ или более экстремальное значение тестовой статистики называют $p$-значением $p = P_{T}(x \\ge x_{0} | H_0)$. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46499a53",
   "metadata": {},
   "source": [
    "Проблема метода - решение принимается по $p$-значению $p = P_{T}(x \\ge x_{0} | H_0)$, тогда как для оценки гипотезы нужна вероятность $P(H_0 | x_0)$. По соотношению Байеса $P(H_0 | x_0) \\propto P_{T}(x = x_{0} | H_0) P(H_0)$. Т.е. для выбора гипотезы нужно посчитать вероятности получить данные в рамках конкурирующих гипотез и сравнить друг с другом с учетом априорных вероятностей.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97cba49",
   "metadata": {},
   "source": [
    "В А/Б-тестах нужно выбрать группу с большим значением целевой метрики. Распространенные применения проверок нулевых гипотез к А/Б-тестам включают $t$-тест средних, $\\chi^2$-тест пропорций и $U$-критерий Манна-Уитни. Для $t$- и $\\chi^2$-тестов $p$-значение численно близко вероятности метрик одной группы больше другой, хотя отличается по определению. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e63c00",
   "metadata": {},
   "source": [
    "## Т-тест"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a120f",
   "metadata": {},
   "source": [
    "Средние сравнивают $t$-тестами [[TTest](https://en.wikipedia.org/wiki/Student%27s_t-test)]. Пусть есть выборки размера $N_A, N_B$ из двух случайных величин $A, B$. По выборочным средним $\\mu_A, \\mu_B$ и дисперсиям $s_A^2, s_B^2$ оценивают среднее и дисперсию разности $\\mu_{\\Delta} = \\mu_B - \\mu_A$, $s^2_{\\Delta} = s_A^2/N_A + s_B^2/N_B$. Считают отношение $x_0 = \\mu_{\\Delta}/s_{\\Delta}$. Предполагают, что средние в группах одинаковы. Тогда для отношения $\\mu_{\\Delta}/s_{\\Delta}$ ожидают $t$-распределение [[WelchT](https://en.wikipedia.org/wiki/Welch%27s_t-test)]. При достаточно большом количестве данных оно близко стандартному нормальному $\\text{Norm}(0, 1)$ [[TDist](https://en.wikipedia.org/wiki/Student%27s_t-distribution)]. Вычисляют вероятность получить фактическое $x_0$ или более экстремальное отношение - $p$-значение $P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)$. Если оно \"достаточно мало\", считают средние в группах неравными.\n",
    "\n",
    "$$\n",
    "x_0 = \\frac{\\mu_{\\Delta}}{s_{\\Delta}},\n",
    "\\quad\n",
    "\\mu_{\\Delta} = \\mu_B - \\mu_A,\n",
    "\\quad\n",
    "s^2_{\\Delta} = \\frac{s_A^2}{N_A} + \\frac{s_B^2}{N_B}\n",
    "\\\\\n",
    "P_{\\mu_{\\Delta}/s_{\\Delta}}(x | \\mu_A = \\mu_B) \\approx \\text{Norm}(x; 0, 1)\n",
    "\\\\\n",
    "p = P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e3130",
   "metadata": {},
   "source": [
    "В А/Б-тесте нужно выбрать группу с большим средним. Поэтому вместо $p$-значения $P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)$ интересна вероятность среднего $B$ больше $A$ при условии собранных данных $P(\\mu_B > \\mu_A | x_0 )$. Эту вероятность можно оценить байесовским моделированием. В пренебрежении априорными значениями $\\mu_B - \\mu_A \\sim \\text{Norm}(\\mu_{\\Delta}, s^2_{\\Delta})$. Поэтому $P(\\mu_B > \\mu_A | x_0 ) = P(\\mu_{\\Delta} > 0 | x_0 )  \\approx 1 - P(\\text{Norm}(x < 0 | x_0, 1))$. В общем случае связь $p$-значения с этой вероятностью не очевидна. Для $t$-тестов по симметрии нормального распределения $P(\\text{Norm}(x > x_0 | 0, 1)) =  P(\\text{Norm}(x < 0 | x_0, 1))$. Поэтому $p$-значение одностороннего $t$-теста близко вероятности среднего одной группы больше другой.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "p = P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)\n",
    "& = P(\\text{Norm}(x > x_0 | 0, 1)) \n",
    "\\\\\n",
    "& =  P(\\text{Norm}(x < 0 | x_0, 1)) \n",
    "\\approx 1 - P(\\mu_B > \\mu_A | x_0 )\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5614ef",
   "metadata": {},
   "source": [
    "На графике ниже 2 нормальных распределения. Одно с центром в точке 0, другое в точке $x_0 = 2$. Вероятность \n",
    "$p = P(x > x_0 | \\mu_A = \\mu_B)$ закрашена темным, $P(\\text{Norm}(x < 0 | x_0, 1)) \\approx 1 - P(\\mu_B > \\mu_A | x_0 )$ закрашена светлым. По свойствам нормального распределения площади этих областей совпадают. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: norm(0, 1); use x0 = mud/s\n",
    "mud = 2\n",
    "s = 1\n",
    "\n",
    "xaxis_min = -7\n",
    "xaxis_max = 7\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name=f'$Norm(0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[mud, mud], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$x_0$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>mud], y=stats.norm.pdf(x[x>mud], loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name=f'$P(x > x_0 | \\Delta \\mu=0)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mud, scale=s), \n",
    "                         line_color='black', line_dash='solid', opacity=0.2, name=f'$Norm(x_0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '0'], textposition=\"top center\", \n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=stats.norm.pdf(x[x<0], loc=mud, scale=s), \n",
    "                         line_color=\"rgba(128, 128, 128, 0.2)\", name=f'$P(x < 0 | \\Delta \\mu / s_\\Delta = x_0)$', fill=\"tozeroy\", fillcolor=\"rgba(128, 128, 128, 0.2)\"))\n",
    "fig.update_layout(title='P-значение и вероятность среднего одной группы больше другой',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d8603",
   "metadata": {},
   "source": [
    "Таким образом $p$-значение одностороннего $t$-теста близко байесовской оценке вероятности среднего одной группы больше другой. Для демонстрации ниже заданы два распределения Бернулли с разными конверсиями. По выборке байесовская оценка вероятности $P(p_B > p_A)$ сравнивается с $p$-значением $t$-теста. Используется односторонний $t$-тест с разными дисперсиями групп (`equal_var=False`, `alternative`) [[ScipyTTestInd](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)]. Видно, что $p$-значение численно близко байесовской оценке вероятности. Стоит помнить, что они не эквивалентны - у них разные определения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "pA = 0.1\n",
    "pB = pA * 1.05\n",
    "\n",
    "exactA = stats.bernoulli(pA)\n",
    "exactB = stats.bernoulli(pB)\n",
    "\n",
    "N = 30000\n",
    "sampA = exactA.rvs(size=N)\n",
    "sampB = exactB.rvs(size=N)\n",
    "\n",
    "post_dist_A = posterior_dist_binom(ns=np.sum(sampA), ntotal=N)\n",
    "post_dist_B = posterior_dist_binom(ns=np.sum(sampB), ntotal=N)\n",
    "pb_gt_pa = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "\n",
    "a = 'greater' if np.mean(sampA) > np.mean(sampB) else 'less'\n",
    "t_stat, p_value = stats.ttest_ind(sampA, sampB, equal_var=False, alternative=a)\n",
    "\n",
    "print(f'p-value P(x>x0 | pa=pb): {p_value}')\n",
    "print(f'1 - p: {1 - p_value}')\n",
    "print(f'Bayes P(pb > pa): {pb_gt_pa}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c419d18",
   "metadata": {},
   "source": [
    "Численную близость $p$-значения вероятности среднего одной группы больше другой можно проверить по количеству правильно угаданных вариантов с большим значением конверсии в серии экспериментов. В группе А задается фиксированная конверсия `p=0.1`, в Б - случайная в диапазоне $\\pm 5\\%$ от `p`. В группах генерируются данные с шагом `n_samp_step`. На каждом шаге считается $t$-тест. Эксперимент останавливается, если  $p$ или $1-p$ достигает `prob_stop=0.95` или сгенерировано максимальное количество точек `n_samp_max`. Длительность эксперимента не фиксируется заранее. При остановке эксперимента для сравнения с $p$-значением считаются байесовские апострериорные распределения и вероятность $P(p_B > p_A)$. Процедура повторяется `nexps` раз, считается доля правильно угаданных групп во всех экспериментах. Байесовские вероятности близки $p$-значениям. В `nexps = 1000` правильно угадано 927 вариантов. Точность 0.927 близка `prob_stop = 0.95`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p-val'])\n",
    "\n",
    "p = 0.1\n",
    "nexps = 100\n",
    "cmp['A'] = [p] * nexps\n",
    "cmp['B'] = p * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 3_000_000\n",
    "n_samp_step = 10_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    pA = cmp.at[i, 'A']\n",
    "    pB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.bernoulli(p=pA)\n",
    "    exact_dist_B = stats.bernoulli(p=pB)\n",
    "    n_samp_total = 0\n",
    "    ns_A = 0\n",
    "    ns_B = 0\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA = exact_dist_A.rvs(n_samp_step)\n",
    "        dB = exact_dist_B.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        ns_A = ns_A + np.sum(dA)\n",
    "        ns_B = ns_B + np.sum(dB)\n",
    "        T_A = np.zeros(n_samp_total)\n",
    "        T_A[:ns_A] = 1\n",
    "        T_B = np.zeros(n_samp_total)\n",
    "        T_B[:ns_B] = 1\n",
    "        a = 'greater' if np.mean(sampA) > np.mean(sampB) else 'less'\n",
    "        t_stat, p_value = stats.ttest_ind(T_A, T_B, equal_var=False, alternative=a)\n",
    "        p_best_t = 1 - p_value\n",
    "        best_gr = 'B' if p_best_t >= prob_stop else 'A' if (1 - p_best_t) >= prob_stop else None\n",
    "        if best_gr:\n",
    "            post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "            post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "            pb_gt_pa_bayes = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "            cmp.at[i, 'A_exp'] = ns_A / n_samp_total\n",
    "            cmp.at[i, 'B_exp'] = ns_B / n_samp_total\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p-val'] = max(p_value, 1 - p_value)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, Bayes P(b>a) {pb_gt_pa_bayes:.4f}, T-test p-val {p_value:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3ec00",
   "metadata": {},
   "source": [
    "## Тест $\\chi^2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06de92d",
   "metadata": {},
   "source": [
    "Конверсии могут сравнивать $\\chi^2$-тестом [[Chi2Test](https://en.wikipedia.org/wiki/Chi-squared_test)]. Статистика $\\chi^2$ Пирсона [[Chi2Pearson](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)] для мультиномиальных распределений определена $\\chi^2 = \\sum_{i=1}^k (S_i - Np_i)^2/(Np_i)$, где $N$ - общее количество наблюдений, $S_i$ - фактическое количество наблюдений $i$-категории,  $N p_i$ - ожидаемое при доле $i$-категории $p_i$. Для биномиального распределения $\\chi^2=(S - Np)^2/N p (1-p)$. По центральной предельной теореме $(S - Np)/\\sqrt{N p (1-p)}$ стремится к стандартному нормальному распределению. Распределение суммы квадратов $k$ нормальных случайных величин называют $\\chi^2$-распределением с $k$ степенями свободы $\\chi^2_k = \\sum_{i=1}^{k} X_i^2,\\, X_i \\sim \\text{Norm}(0,1)$ [[Chi2Dist](https://en.wikipedia.org/wiki/Chi-squared_distribution)]. Статистика $\\chi^2$ стремится к $\\chi_1^2$-распределению.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\chi^2 & = \n",
    "\\sum_{i=1}^k \\frac{(S_i - Np_i)^2}{N p_i}\n",
    "\\\\\n",
    "& =\n",
    "\\frac{(S - N p)^2}{N p}\n",
    "+\n",
    "\\frac{((N - S) - N (1-p))^2}{N (1-p)}\n",
    "\\\\\n",
    "& =\n",
    "\\frac{(S - Np)^2}{N p (1-p)} \n",
    "\\to \\chi_1^2, \\quad n \\to \\infty\n",
    "\\\\\n",
    "\\chi^2_k & = \\sum_{i=1}^{k} X_i^2,\\, X_i \\sim \\text{Norm}(0,1)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b9d00",
   "metadata": {},
   "source": [
    "Для А/Б-теста конверсий с двумя группами в предположении одинаковых конверсий $p=(S_A + S_B)/(N_A + N_B)$ тестовая статистика $\\chi^2=(S_A - N_A p)^2/N_A p (1-p) + (S_B - N_B p)^2/N_B p (1-p)$. Ее можно привести к виду $\\chi^2 = (p_A - p_B)^2/(s^2 / N_A + s^2 / N_B)$, $s^2 = p (1 - p)$, $p_A = S_A / N_A$, $p_B = S_B / N_B$. При большом количестве точек распределение $\\chi^2$ можно ожидать близим $\\chi_1^2$. $p$-значение $p=P_{\\chi_1^2}(x > \\chi^2)$. Распределение $\\chi^2_1$ получается при возведении в квадрат стандартного нормального распределения. Область $P_{\\chi_1^2}(x > \\chi^2)$ соответствует областям $P_{Norm(0,1)}(x > \\chi \\cup x < -\\chi)$. По симметрии нормального распределения площади $x > \\chi$ и $x < -\\chi$ одинаковы $P_{Norm(0,1)}(x > \\chi \\cup x < -\\chi) = 2 P_{Norm(0,1)}(x > \\chi)$. Байесовская оценка вероятности конверсии одной группы больше другой с учетом собранных данных при использовании априорного бета-распределения $P(\\mu_B > \\mu_A | S_A, S_B, N_A, N_B) \\approx P_{Norm(p_{\\Delta}, s_{\\Delta}^2)}(x > 0)$, $p_{\\Delta} = p_B - p_A$,  $s_{\\Delta} = s_A^2/N_A + s_B^2/N_B$. В пренебрежении априорным распределением $P(\\mu_B > \\mu_A | S_A, S_B) \\approx 1 - P_{Norm(\\chi, 1)}(x < 0)$. По симметрии $P_{Norm(\\chi, 1)}(x < 0) = P_{Norm(0, 1)}(x > \\chi)$ Поэтому $p$-значение $p \\approx 2( 1 - P(\\mu_B > \\mu_A | S_A, S_B))$. Отсюда $P(p_B > p_A | S_A, S_B) \\approx 1 - p/2$.\n",
    "\n",
    "$$\n",
    "p_A = \\frac{S_A}{N_A}, \\quad \n",
    "p_B = \\frac{S_B}{N_B}, \\quad \n",
    "p = \\frac{S_A + S_B}{N_A + N_B},\n",
    "\\quad\n",
    "s^2 = p (1 - p)\n",
    "\\\\\n",
    "\\begin{split}\n",
    "\\chi^2 & = \\frac{(S_A - N_A p)^2}{N_A p (1-p)} + \\frac{(S_B - N_B p)^2}{N_B p (1-p)} \n",
    "\\\\\n",
    "& = \\frac{N_A N_B (p_A - p_B)^2}{(N_A + N_B) p (1-p)}\n",
    "\\\\\n",
    "& = \\frac{(p_A - p_B)^2}{s^2 / N_A + s^2 / N_B}\n",
    "\\\\\n",
    "\\end{split}\n",
    "\\\\\n",
    "p_A = p_B: \\chi^2 \\to \\chi_1^2, \\, n \\to \\infty\n",
    "\\\\\n",
    "\\begin{split}\n",
    "\\text{p-val} & = P_{\\chi_1^2}(x > \\chi^2 | p_A = p_B)\n",
    "\\\\\n",
    "& = P_{Norm(0,1)}(x > \\chi \\cup x < -\\chi | p_A = p_B) \n",
    "\\\\\n",
    "& = 2 P_{Norm(0,1)}(x > \\chi | p_A = p_B)\n",
    "\\\\\n",
    "& \\approx 2 \\left( 1 - P(p_B > p_A | S_A, S_B) \\right)\n",
    "\\end{split}\n",
    "\\\\\n",
    "P(p_B > p_A | S_A, S_B) \\approx 1 - \\text{p-val}/2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8e2b6",
   "metadata": {},
   "source": [
    "Распределение $\\chi^2_1$ на первом графике ниже. Закрашенная область соответствует $p$-значению $p = P_{\\chi_1^2}(x > \\chi^2)$. На втором графике - стандартное нормальное распределение. Закрашенные темные области $x > \\chi$ и $x < - \\chi$ соответствуют $P_{\\chi_1^2}(x > \\chi^2)$ при возведении в квадрат. Серый график - нормальное распределение $Norm(\\chi, 1)$. Закрашенная область серого графика приближенно равна $1 - P(p_B > p_A | S_A, S_B)$. Площади закрашенной серой и каждой из темных областей совпадают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.3\n",
    "#s = p * (1 - p)\n",
    "#todo: N = 10000\n",
    "#s = p * (1 - p) / N\n",
    "s = 1\n",
    "x0 = p / (p * (1 - p))\n",
    "\n",
    "xaxis_min = 0\n",
    "xaxis_max = 5\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.chi.pdf(x, df=1), \n",
    "                         line_color='black', opacity=0.8, name=f'$\\chi^2_1$'))\n",
    "fig.add_trace(go.Scatter(x=[x0**2, x0**2], y=[0, max(stats.chi.pdf(x, df=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$\\chi^2$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>x0**2], y=stats.chi.pdf(x[x>x0**2], df=1), \n",
    "                         line_color='black', opacity=0.8, name='$P_{\\chi_1^2}(x > \\chi^2)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.update_layout(title='Хи-квадрат',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "xaxis_min = -5\n",
    "xaxis_max = 5\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name=f'$Norm(0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '0'], textposition=\"top center\", \n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=[x0, x0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$\\chi$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=[-x0, -x0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$-\\chi$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>x0], y=stats.norm.pdf(x[x>x0], loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name='$P_{Norm(0,1)}(x > \\chi \\cup x < -\\chi | p_A = p_B)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x[x<-x0], y=stats.norm.pdf(x[x<-x0], loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name='$P_{Norm(0,1)}(x > \\chi | p_A = p_B)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\",\n",
    "                         showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=x0, scale=s), \n",
    "                         line_color='black', opacity=0.2, name='$Norm(\\chi, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=stats.norm.pdf(x[x<0], loc=x0, scale=s), \n",
    "                         line_color=\"rgba(128, 128, 128, 0.2)\", name='$P_{Norm(\\chi,1)}(x < 0)$', fill=\"tozeroy\", fillcolor=\"rgba(128, 128, 128, 0.2)\"))\n",
    "fig.update_layout(title='Нормальные распределения',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6110e2",
   "metadata": {},
   "source": [
    "Соотношение $P(p_B > p_A | S_A, S_B) \\approx 1 - p/2$ проверяется по выборке из двух распределений Бернулли с конверсиями $p_A = 0.1$ и $p_B = 0.105$. Данные для $\\chi^2$-теста задаются в виде таблицы со строками $S_A, N_A-S_A$ и $S_B, N_B - S_B$ [[ScipyChi2Con](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html)]. Только $p$-значение не позволяет выбрать между $p_A > p_B$ и $p_B > p_A$, поэтому дополнительно сравниваются конверсии $p_A$, $p_B$. Видно, что связь $p$-значения и байесовской оценки вероятности численно выполняется. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "pA = 0.1\n",
    "pB = pA * 1.05\n",
    "\n",
    "exactA = stats.bernoulli(pA)\n",
    "exactB = stats.bernoulli(pB)\n",
    "\n",
    "N = 30000\n",
    "sampA = exactA.rvs(size=N)\n",
    "sampB = exactB.rvs(size=N)\n",
    "SA = np.sum(sampA)\n",
    "SB = np.sum(sampB)\n",
    "\n",
    "post_dist_A = posterior_dist_binom(ns=SA, ntotal=N)\n",
    "post_dist_B = posterior_dist_binom(ns=SB, ntotal=N)\n",
    "pb_gt_pa_bayes = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "\n",
    "t = np.array([\n",
    "    [SA,     N - SA],\n",
    "    [SB,     N - SB]\n",
    "])\n",
    "chi2_stat, p_value_chi2, dof, expected = stats.chi2_contingency(t, correction=False)\n",
    "p_A_samp = SA / N\n",
    "p_B_samp = SB / N\n",
    "pb_gt_pa_chi = 1 - p_value_chi2 / 2\n",
    "pb_gt_pa_chi = pb_gt_pa_chi if p_B_samp > p_A_samp  else 1 - pb_gt_pa_chi\n",
    "\n",
    "print(f'Bayes P(pb > pa): {pb_gt_pa_bayes:.5g}')\n",
    "print(f\"Chi2: 1-pval/2:   {pb_gt_pa_chi:.5g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a081f",
   "metadata": {},
   "source": [
    "Ниже $p$-значение $\\chi^2$-теста используется для проверки количества правильно угаданных вариантов с большей конверсией в серии экспериментов. В каждом эксперименте 2 группы, конверсия $p_A=0.1$ фиксирована, $p_B$ выбирается случайно в диапазоне $\\pm5\\%$ от $p_A$. В каждой группе добавляются данные по 10000 точек за шаг. На каждом шаге вычисляется $p$-значение $\\chi^2$-теста и $P(p_B > p_A | S_A, S_B) \\approx 1 - p/2$ при $p_B > p_A$ или $P(p_B > p_A | S_A, S_B) \\approx p/2$ при $p_A > p_B$. Эксперимент останавливается, если оценка вероятности конверсии одной группы больше другой превышает `prop_stop` или набрано максимальное количество точек `n_samp_max`. Всего в `nexps=1000` верно угадано 932 варианта. Доля 0.932 близка `prob_stop = 0.95`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a849f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_chi'])\n",
    "\n",
    "p = 0.1\n",
    "nexps = 1000\n",
    "cmp['A'] = [p] * nexps\n",
    "cmp['B'] = p * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 5_000_000\n",
    "n_samp_step = 10_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    pA = cmp.at[i, 'A']\n",
    "    pB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.bernoulli(p=pA)\n",
    "    exact_dist_B = stats.bernoulli(p=pB)\n",
    "    n_samp_total = 0\n",
    "    ns_A = 0\n",
    "    ns_B = 0\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA = exact_dist_A.rvs(n_samp_step)\n",
    "        dB = exact_dist_B.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        ns_A = ns_A + np.sum(dA)\n",
    "        ns_B = ns_B + np.sum(dB)\n",
    "        p_A_samp = ns_A / n_samp_total\n",
    "        p_B_samp = ns_B / n_samp_total\n",
    "        t = np.array([\n",
    "            [ns_A,     n_samp_total - ns_A],\n",
    "            [ns_B,     n_samp_total - ns_B]\n",
    "        ])\n",
    "        chi2_stat, p_value_chi, dof, expected = stats.chi2_contingency(t, correction=False)\n",
    "        #chi2_stat, p_value_chi, dof, expected = stats.chi2_contingency(t, correction=True)\n",
    "        pb_gt_pa_chi = 1 - p_value_chi / 2\n",
    "        pb_gt_pa_chi = pb_gt_pa_chi if p_B_samp > p_A_samp  else 1 - pb_gt_pa_chi\n",
    "        best_gr = 'B' if pb_gt_pa_chi >= prob_stop else 'A' if 1 - pb_gt_pa_chi >= prob_stop else None\n",
    "        if best_gr:\n",
    "            post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "            post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "            pb_gt_pa_bayes = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "            cmp.at[i, 'A_exp'] = p_A_samp\n",
    "            cmp.at[i, 'B_exp'] = p_B_samp\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p_best_chi'] = max(pb_gt_pa_chi, 1 - pb_gt_pa_chi)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P_best Bayes {max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes):.4f}, Chi (1-pval/2): {1 - p_value_chi/2:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f9f73",
   "metadata": {},
   "source": [
    "## U-критерий Манна-Уитни"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607868a8",
   "metadata": {},
   "source": [
    "Для выборок размера $N_A, N_B$ из двух случайных величин $A, B$ статистика Манна-Уитни [[MannWhitneyU](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)] определена через попарное сравнение элементов. Для непрерывных распределений вероятность совпадения элементов в выборках нулевая. В этом случае $U$-статистика определена как количество пар $(A_i, B_j)$, где элемент $A_i$ больше $B_j$: $U_A = \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(A_i > B_j)$. Cтатистику также можно записать в виде $U_A = R_A - N_A (N_A + 1)/2$, где $R_A$ - сумма рангов элементов $А$ в объединенной выборке. Эквивалентность определений можно увидеть следующим образом: слагаемое $N_A (N_A + 1)/2$ соответствует минимальной сумме рангов если все элементы $A$ меньше $B$ и считается как сумма арифметической прогрессии. Если наибольший элемент $A$ больше $n$ элементов $B$, то $U_A = n$ и $R_A = N_A (N_A + 1)/2 + n$, аналогично для других элементов. При большом количестве точек отношение $U_A / N_A N_B$ будет стремиться к вероятности элемента выборки $A$ больше $B$ ($U_A$ - число пар $A$ больше $B$, $N_A N_B$ - общее количество пар)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcceca1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "A, B & - \\text{непрерывные распределения}\n",
    "\\\\\n",
    "U_A & = \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(A_i > B_j),\n",
    "\\quad\n",
    "I(\\cdot) = 1 \\text{ если условие выполнено, иначе } 0 \n",
    "\\\\\n",
    "U_A & = R_A - N_A (N_A + 1)/2, \\quad R_A \\text{- сумма рангов элементов А в объединенной выборке}\n",
    "\\\\\n",
    "\\frac{U_A}{N_A N_B} & \\to P(A > B),\n",
    "\\quad\n",
    "N_A, N_B \\to \\infty\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6f75f",
   "metadata": {},
   "source": [
    "Нулевая гипотеза - распределения $A$ и $B$ одинаковы. Для выборок $N_A, N_B$ из одного распределения можно посчитать среднее $E[U]$ и дисперсию $\\text{Var}(U)$ $U$-статистики. Величина $(U - E[U])/\\sqrt{Var(U)}$ будет стремиться к нормальному распределению [нужна ссылка]. $p$-значение определено как вероятность получить более экстремальное значение $p = P_{Norm(0,1)}(x > u_0)$, $u_0 = (U - E[U])/\\sqrt{\\text{Var}(U)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c54ba2",
   "metadata": {},
   "source": [
    "$$\n",
    "A = B: \n",
    "\\quad\n",
    "E[U] = \\frac{N_A N_B}{2}, \\quad\n",
    "\\text{Var}(U) = \\frac{N_A N_B (N_A + N_B + 1)}{12}\n",
    "\\\\\n",
    "\\frac{U - E[U]}{\\sqrt{\\text{Var}(U)}} \\to Norm(0,1), \\quad N_A, N_B \\to \\infty\n",
    "\\\\\n",
    "p = P_{Norm(0,1)}(x > u_0), \n",
    "\\quad\n",
    "u_0 = \\frac{U - E[U]}{\\sqrt{\\text{Var}(U)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a827a",
   "metadata": {},
   "source": [
    "В байесовском подходе вероятность $P(B>A)$ можно оценить сравнением апостериорных предиктивных распределений. Т.е. нужно предположить модели распределений, построить апостериорные распределения параметров, построть апостериорные предиктивные распределения. По построенным апостериорным предиктивным распределениям можно оценить $P(B>A)$. Это будет точечная оценка, а не распеделение. Такой подход требует предположения распределений.\n",
    "\n",
    "Другой вариант - моделировать вероятность $\\theta = P(B > A)$. Сравнение каждой пары $X_{ij} = I(B_i > A_j)$ - точка. Сумма будет $U$-статистикой. Для правдоподобия можно выбрать биномиальное распределение $P(U | \\theta) = \\text{Binom}(U | \\theta, N_A N_B)$. При сравнении каждой точки $A$ с каждой точкой $B$ результаты в парах с одинаковыми $A_i$ или $B_j$ не будут независимы. Будет использоваться упрощенная модель, в которой каждая точка из $A$ сравнивается только с одной точкой $B$. Можно ожидать более широкой дисперсии, чем в $U$. Тогда пары будут независимы. Как в конверсиях априорное распределение удобно задать бета-распределением. Апостериорное также будет бета-распределением. \n",
    "\n",
    "$$\n",
    "\\theta = P(A > B)\n",
    "\\\\\n",
    "X_{ij} = I(A_i > B_j)\n",
    "\\\\\n",
    "U = \\sum X_{ij}\n",
    "\\\\\n",
    "P(X | \\theta) = \\text{Bernoulli}(\\theta)\n",
    "\\\\\n",
    "P(U | \\theta) = \\text{Binom}(U | \\theta, \\min(N_A, N_B))\n",
    "\\\\\n",
    "P(\\theta) = \\text{Beta}(\\alpha_0, \\beta_0)\n",
    "\\\\\n",
    "P(\\theta | U) = \\text{Beta}(U + \\alpha_0, \\min(N_A, N_B) - U + \\beta_0)\n",
    "\\approx \\text{Norm}(\\mu, s)\n",
    "\\\\\n",
    "\\begin{split}\n",
    "P(A > B) = P(\\theta  > 0.5 | U) & = P(\\text{Norm}(x > 0.5; \\mu, s))\n",
    "\\end{split}\n",
    "\\\\\n",
    "P(B > A) = 1 - P(\\theta  > 0.5 | U)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d74d305",
   "metadata": {},
   "source": [
    "На графике ниже два нормальных распределения. На втором графике - распределение $U$-статистики в предположении эквивалентности распределений и фактическое значение. Закрашенная область соответствует $p$-значению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "mu1, sigma1 = 0, 1\n",
    "mu2, sigma2 = -0.1, 1\n",
    "exactA = stats.norm(loc=mu1, scale=sigma1)\n",
    "exactB = stats.norm(loc=mu2, scale=sigma2)\n",
    "\n",
    "p_b_gt_a_norm = 1 - stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "p_a_gt_b_norm = stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "\n",
    "#U\n",
    "nA = nB = 1500\n",
    "sampA = exactA.rvs(nA)\n",
    "sampB = exactB.rvs(nB)\n",
    "U, p = mannwhitneyu(sampA, sampB, alternative='greater')\n",
    "eu = nA * nB / 2\n",
    "varu = nA * nB * (nA + nB + 1) / 12\n",
    "u0 = (U - eu) / np.sqrt(varu)\n",
    "p_b_gt_a_u = 1 - U / (nA*nB)\n",
    "\n",
    "# Ua = sum(np.sum(a > sampB) for a in sampA)\n",
    "# print(f'Ua:{Ua}, U:{U}')\n",
    "\n",
    "\n",
    "#P(a>b)\n",
    "p_u = stats.norm(loc=eu/(nA*nB), scale=np.sqrt(varu/(nA*nA*nB*nB)))\n",
    "u0_p = U / (nA*nB)\n",
    "print(f'p: {p}, cdf(u0): {stats.norm.cdf(u0)}, cdf(u0p): {p_u.cdf(u0_p)}')\n",
    "\n",
    "\n",
    "#elementwise\n",
    "a0 = 1\n",
    "b0 = 1\n",
    "Ua = np.sum(sampA > sampB)\n",
    "post_u_ewise = stats.beta(a0 + Ua, b0 + nA - Ua)\n",
    "\n",
    "\n",
    "x = np.linspace(-7, 7, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactA.pdf(x),\n",
    "    mode='lines', name='A', line_color='black'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactB.pdf(x),\n",
    "    mode='lines', name='B', line_color='blue', opacity=0.7))\n",
    "fig.update_layout(\n",
    "    title=\"A, B\",\n",
    "    template=\"plotly_white\",\n",
    "    #yaxis_range=[0,1.1]\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "xaxis_min = 0.4\n",
    "xaxis_max = 0.6\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=p_u.pdf(x), \n",
    "                         line_color='black', opacity=0.8, name=f'$U/N_A N_B$'))\n",
    "fig.add_trace(go.Scatter(x=[u0_p, u0_p], y=[0, max(p_u.pdf(x))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$u_0$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "# fig.add_trace(go.Scatter(x=[p_a_gt_b_norm, p_a_gt_b_norm], y=[0, max(p_u.pdf(x))*1.1], \n",
    "#                          line_color='black', \n",
    "#                          mode='lines+text', \n",
    "#                          text=['', '$P(A>B)$'], textposition=\"top center\",\n",
    "#                          line_dash='solid', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>u0_p], y=p_u.pdf(x[x>u0_p]), \n",
    "                         line_color='black', opacity=0.8, name='$P(x > u_0)$', \n",
    "                         fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_u_ewise.pdf(x),\n",
    "                         line_color='black', opacity=0.3, name=f'PostUElementwise'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0.5], y=post_u_ewise.pdf(x[x<0.5]), \n",
    "                         line_color='black', opacity=0.3, name='$P(x < 0.5)$', \n",
    "                         fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.3)\"))\n",
    "fig.update_layout(\n",
    "    title='P(B>A)',\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef141e",
   "metadata": {},
   "source": [
    "Для нормальных распределений [[NormalSum](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables)]\n",
    "\n",
    "$$\n",
    "A \\sim \\text{Norm}(\\mu_A, \\sigma_A^2),\n",
    "\\quad\n",
    "B \\sim \\text{Norm}(\\mu_B, \\sigma_B^2)\n",
    "\\\\\n",
    "B - A \\sim \\text{Norm}(\\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2)\n",
    "\\\\\n",
    "P(B > A) = P_{B - A}(x > 0) = 1 - F_{B-A}(0) \n",
    "$$\n",
    "\n",
    "Сравниваются не средние, а все распределение. Вероятность $U/N_A N_B$ может не доходить до 1. \n",
    "[[ScipyMannWhitneyU](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'pval: {stats.norm.cdf(u0)}')\n",
    "print(f'scipy pval: {p}')\n",
    "print(f'Bayes P(A>B) {1 - post_u_ewise.cdf(0.5)}')\n",
    "print()\n",
    "print(f'P(B>A) exact: {p_b_gt_a_norm}')\n",
    "print(f'P(B>A) U: {p_b_gt_a_u}')\n",
    "print(f'Bayes Mean P(B>A) {1 - post_u_ewise.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bc75e",
   "metadata": {},
   "source": [
    "Проверка количества правильно угаданных вариантов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9388cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_u'])\n",
    "\n",
    "mua = 0.1\n",
    "nexps = 100\n",
    "cmp['A'] = [mua] * nexps\n",
    "cmp['B'] = mua * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 1_000_000\n",
    "n_samp_step = 10000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    mua = cmp.at[i, 'A']\n",
    "    mub = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.norm(loc=mua)\n",
    "    exact_dist_B = stats.norm(loc=mub)\n",
    "    n_samp_total = 0\n",
    "    sampA = exact_dist_A.rvs(n_samp_max)\n",
    "    sampB = exact_dist_B.rvs(n_samp_max)\n",
    "    while n_samp_total < n_samp_max:\n",
    "        n_samp_total += n_samp_step\n",
    "        U, p = mannwhitneyu(sampA[:n_samp_total], sampB[:n_samp_total], alternative='greater')\n",
    "        pb_gt_pa_u = 1 - U / n_samp_total / n_samp_total\n",
    "        best_gr = 'B' if p >= prob_stop else 'A' if 1 - p >= prob_stop else None\n",
    "        if best_gr:\n",
    "            #post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "            #post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "            pb_gt_pa_bayes = None #prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "            cmp.at[i, 'A_exp'] = sampA[:n_samp_total].mean()\n",
    "            cmp.at[i, 'B_exp'] = sampB[:n_samp_total].mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = None #max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p_best_u'] = max(pb_gt_pa_u, 1 - pb_gt_pa_u)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P_best Bayes {None}, U P(B>A): {pb_gt_pa_u:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be6378",
   "metadata": {},
   "source": [
    "Для $p$-значений $t$-теста, $\\chi^2$-теста и $U$-критерия Манна-Уитни показана связь с байесовскими вероятностями параметров одной группы больше другой. $P$-значения численно близки байесовским вероятностям несмотря на различия в определениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247790d6",
   "metadata": {},
   "source": [
    "## Ссылки\n",
    "\n",
    "[Chi2Dist] - [Chi-squared Distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution), *Wikipedia.*  \n",
    "[Chi2Pearson] - [Pearson’s Chi-squared Test](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test), *Wikipedia.*  \n",
    "[Chi2Test] - [Chi-squared Test](https://en.wikipedia.org/wiki/Chi-squared_test), *Wikipedia.*  \n",
    "[MannWhitneyU] - [Mann–Whitney U Test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test), *Wikipedia.*  \n",
    "[NormalSum] - [Sum of Normally Distributed Random Variables](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables), *Wikipedia.*  \n",
    "[PVal] - [P-value](https://en.wikipedia.org/wiki/P-value), *Wikipedia.*  \n",
    "[ScipyChi2Con] - [scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html), *SciPy Reference.*  \n",
    "[ScipyMannWhitneyU] - [scipy.stats.mannwhitneyu](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html), *SciPy Reference.*  \n",
    "[ScipyTTestInd] - [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html), *SciPy Reference.*  \n",
    "[TailedTests] - [One- and Two-tailed Tests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests), *Wikipedia.*  \n",
    "[TDist] - [Student’s t-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution), *Wikipedia.*  \n",
    "[TestStat] - [Test Statistic](https://en.wikipedia.org/wiki/Test_statistic), *Wikipedia.*  \n",
    "[TTest] - [Student’s t-test](https://en.wikipedia.org/wiki/Student%27s_t-test), *Wikipedia.*  \n",
    "[WelchT] - [Welch’s t-test](https://en.wikipedia.org/wiki/Welch%27s_t-test), *Wikipedia.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf3ef93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
