{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059d7c01",
   "metadata": {},
   "source": [
    "# Байесовские А/Б-тесты: связь с $p$-значениями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b4a7a6",
   "metadata": {},
   "source": [
    "*Для $p$-значений $t$-теста, $\\chi^2$-теста и $U$-критерия Манна-Уитни в А/Б-тестах показана связь с байесовскими вероятностями параметров одной группы больше другой. $P$-значения численно близки байесовским вероятностям несмотря на различия в определениях.*\n",
    "\n",
    "*- [$P$-значения](#$P$-значения)*  \n",
    "*- [Т-тест](#Т-тест)*  \n",
    "*- [Тест $\\chi^2$](#Тест-$\\chi^2$)*  \n",
    "*- [U-критерий Манна-Уитни](#U-критерий-Манна-Уитни)*  \n",
    "*- [Ссылки](#Ссылки)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6b5af",
   "metadata": {},
   "source": [
    "## $P$-значения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a519a4",
   "metadata": {},
   "source": [
    "$P$-значения используют для принятия решения в проверках нулевых гипотез. В проверках нулевых гипотез формулируют гипотезу $H_0$ о данных $\\mathcal{D}$. Выбирают статистический тест $T$ - случайную величину с известным распределением $P_{T}(x | H_0)$ в предположении $H_0$. Считают реализацию величины $T$ в данных - тестовую статистику $x_{0}$ [[TestStat](https://en.wikipedia.org/wiki/Test_statistic)]. Вероятность получить фактическое или более экстремальное значение тестовой статистики называют $p$-значением $p = P_{T}(x \\ge x_{0} | H_0)$ [[PVal](https://en.wikipedia.org/wiki/P-value), [TailedTests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests)]. Если вероятность «достаточно мала», гипотезу $H_0$ «отвергают», если нет - «оставляют»."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d41335",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../figs/null_hypothesis.png\" alt=\"null_hypothesis\" width=\"800\"/>\n",
    "<em> В предположении гипотезы $H_0$ распределение тестовой статистики $P_{T}(x | H_0)$. Вероятность получить фактическое $x_0$ или более экстремальное значение тестовой статистики называют $p$-значением $p = P_{T}(x \\ge x_{0} | H_0)$. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46499a53",
   "metadata": {},
   "source": [
    "Проблема метода - решение принимается по $p$-значению $p = P_{T}(x \\ge x_{0} | H_0)$, тогда как для оценки гипотезы нужна вероятность $P(H_0 | x_0)$. По соотношению Байеса $P(H_0 | x_0) \\propto P_{T}(x = x_{0} | H_0) P(H_0)$. Т.е. для выбора гипотезы нужно посчитать вероятности получить данные в рамках конкурирующих гипотез и сравнить друг с другом с учетом априорных вероятностей.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97cba49",
   "metadata": {},
   "source": [
    "В А/Б-тестах нужно выбрать группу с большим значением целевой метрики. Распространенные применения проверок нулевых гипотез к А/Б-тестам включают $t$-тест средних, $\\chi^2$-тест пропорций и $U$-критерий Манна-Уитни. Для $t$- и $\\chi^2$-тестов $p$-значение численно близко вероятности метрик одной группы больше другой, хотя отличается по определению. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e63c00",
   "metadata": {},
   "source": [
    "## Т-тест"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a120f",
   "metadata": {},
   "source": [
    "Средние сравнивают $t$-тестами [[TTest](https://en.wikipedia.org/wiki/Student%27s_t-test)]. Пусть есть выборки размера $N_A, N_B$ из двух случайных величин $A, B$. По выборочным средним $\\mu_A, \\mu_B$ и дисперсиям $s_A^2, s_B^2$ оценивают среднее и дисперсию разности $\\mu_{\\Delta} = \\mu_B - \\mu_A$, $s^2_{\\Delta} = s_A^2/N_A + s_B^2/N_B$. Считают отношение $x_0 = \\mu_{\\Delta}/s_{\\Delta}$. Предполагают, что средние в группах одинаковы. Тогда для отношения $\\mu_{\\Delta}/s_{\\Delta}$ ожидают $t$-распределение [[WelchT](https://en.wikipedia.org/wiki/Welch%27s_t-test)]. При достаточно большом количестве данных оно близко стандартному нормальному $\\text{Norm}(0, 1)$ [[TDist](https://en.wikipedia.org/wiki/Student%27s_t-distribution)]. Вычисляют вероятность получить фактическое $x_0$ или более экстремальное отношение - $p$-значение $P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)$. Если оно \"достаточно мало\", считают средние в группах неравными.\n",
    "\n",
    "$$\n",
    "x_0 = \\frac{\\mu_{\\Delta}}{s_{\\Delta}},\n",
    "\\quad\n",
    "\\mu_{\\Delta} = \\mu_B - \\mu_A,\n",
    "\\quad\n",
    "s^2_{\\Delta} = \\frac{s_A^2}{N_A} + \\frac{s_B^2}{N_B}\n",
    "\\\\\n",
    "P_{\\mu_{\\Delta}/s_{\\Delta}}(x | \\mu_A = \\mu_B) \\approx \\text{Norm}(x; 0, 1)\n",
    "\\\\\n",
    "p = P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e3130",
   "metadata": {},
   "source": [
    "В А/Б-тесте нужно выбрать группу с большим средним. Поэтому вместо $p$-значения $P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)$ интересна вероятность среднего $B$ больше $A$ при условии собранных данных $P(\\mu_B > \\mu_A | x_0 )$. Эту вероятность можно оценить байесовским моделированием. В пренебрежении априорными значениями $\\mu_B - \\mu_A \\sim \\text{Norm}(\\mu_{\\Delta}, s^2_{\\Delta})$. Поэтому $P(\\mu_B > \\mu_A | x_0 ) = P(\\mu_{\\Delta} > 0 | x_0 )  \\approx 1 - P(\\text{Norm}(x < 0 | x_0, 1))$. В общем случае связь $p$-значения с этой вероятностью не очевидна. Для $t$-тестов по симметрии нормального распределения $P(\\text{Norm}(x > x_0 | 0, 1)) =  P(\\text{Norm}(x < 0 | x_0, 1))$. Поэтому $p$-значение одностороннего $t$-теста близко вероятности среднего одной группы больше другой.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "p = P_{\\mu_{\\Delta}/s_{\\Delta}}(x > x_0 | \\mu_A = \\mu_B)\n",
    "& = P(\\text{Norm}(x > x_0 | 0, 1)) \n",
    "\\\\\n",
    "& =  P(\\text{Norm}(x < 0 | x_0, 1)) \n",
    "\\approx 1 - P(\\mu_B > \\mu_A | x_0 )\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5614ef",
   "metadata": {},
   "source": [
    "На графике ниже 2 нормальных распределения. Одно с центром в точке 0, другое в точке $x_0 = 2$. Вероятность \n",
    "$p = P(x > x_0 | \\mu_A = \\mu_B)$ закрашена темным, $P(\\text{Norm}(x < 0 | x_0, 1)) \\approx 1 - P(\\mu_B > \\mu_A | x_0 )$ закрашена светлым. По свойствам нормального распределения площади этих областей совпадают. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: norm(0, 1); use x0 = mud/s\n",
    "mud = 2\n",
    "s = 1\n",
    "\n",
    "xaxis_min = -7\n",
    "xaxis_max = 7\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name=f'$Norm(0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[mud, mud], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$x_0$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>mud], y=stats.norm.pdf(x[x>mud], loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name=f'$P(x > x_0 | \\Delta \\mu=0)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mud, scale=s), \n",
    "                         line_color='black', line_dash='solid', opacity=0.2, name=f'$Norm(x_0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '0'], textposition=\"top center\", \n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=stats.norm.pdf(x[x<0], loc=mud, scale=s), \n",
    "                         line_color=\"rgba(128, 128, 128, 0.2)\", name=f'$P(x < 0 | \\Delta \\mu / s_\\Delta = x_0)$', fill=\"tozeroy\", fillcolor=\"rgba(128, 128, 128, 0.2)\"))\n",
    "fig.update_layout(title='P-значение и вероятность среднего одной группы больше другой',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d8603",
   "metadata": {},
   "source": [
    "Таким образом $p$-значение одностороннего $t$-теста близко байесовской оценке вероятности среднего одной группы больше другой. Для демонстрации ниже заданы два распределения Бернулли с разными конверсиями. По выборке байесовская оценка вероятности $P(p_B > p_A)$ сравнивается с $p$-значением $t$-теста. Используется односторонний $t$-тест с разными дисперсиями групп (`equal_var=False`, `alternative`) [[ScipyTTestInd](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)]. Видно, что $p$-значение численно близко байесовской оценке вероятности. Стоит помнить, что они не эквивалентны - у них разные определения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "pA = 0.1\n",
    "pB = pA * 1.05\n",
    "\n",
    "exactA = stats.bernoulli(pA)\n",
    "exactB = stats.bernoulli(pB)\n",
    "\n",
    "N = 30000\n",
    "sampA = exactA.rvs(size=N)\n",
    "sampB = exactB.rvs(size=N)\n",
    "\n",
    "post_dist_A = posterior_dist_binom(ns=np.sum(sampA), ntotal=N)\n",
    "post_dist_B = posterior_dist_binom(ns=np.sum(sampB), ntotal=N)\n",
    "pb_gt_pa = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "\n",
    "a = 'greater' if np.mean(sampA) > np.mean(sampB) else 'less'\n",
    "t_stat, p_value = stats.ttest_ind(sampA, sampB, equal_var=False, alternative=a)\n",
    "\n",
    "print(f'p-value P(x>x0 | pa=pb): {p_value}')\n",
    "print(f'1 - p: {1 - p_value}')\n",
    "print(f'Bayes P(pb > pa): {pb_gt_pa}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c419d18",
   "metadata": {},
   "source": [
    "Численную близость $p$-значения вероятности среднего одной группы больше другой можно проверить по количеству правильно угаданных вариантов с большим значением конверсии в серии экспериментов. В группе А задается фиксированная конверсия `p=0.1`, в Б - случайная в диапазоне $\\pm 5\\%$ от `p`. В группах генерируются данные с шагом `n_samp_step`. На каждом шаге считается $t$-тест. Эксперимент останавливается, если  $p$ или $1-p$ достигает `prob_stop=0.95` или сгенерировано максимальное количество точек `n_samp_max`. Длительность эксперимента не фиксируется заранее. При остановке эксперимента для сравнения с $p$-значением считаются байесовские апострериорные распределения и вероятность $P(p_B > p_A)$. Процедура повторяется `nexps` раз, считается доля правильно угаданных групп во всех экспериментах. Байесовские вероятности близки $p$-значениям. В `nexps = 1000` правильно угадано 927 вариантов. Точность 0.927 близка `prob_stop = 0.95`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p-val'])\n",
    "\n",
    "p = 0.1\n",
    "nexps = 100\n",
    "cmp['A'] = [p] * nexps\n",
    "cmp['B'] = p * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 3_000_000\n",
    "n_samp_step = 10_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    pA = cmp.at[i, 'A']\n",
    "    pB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.bernoulli(p=pA)\n",
    "    exact_dist_B = stats.bernoulli(p=pB)\n",
    "    n_samp_total = 0\n",
    "    ns_A = 0\n",
    "    ns_B = 0\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA = exact_dist_A.rvs(n_samp_step)\n",
    "        dB = exact_dist_B.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        ns_A = ns_A + np.sum(dA)\n",
    "        ns_B = ns_B + np.sum(dB)\n",
    "        T_A = np.zeros(n_samp_total)\n",
    "        T_A[:ns_A] = 1\n",
    "        T_B = np.zeros(n_samp_total)\n",
    "        T_B[:ns_B] = 1\n",
    "        a = 'greater' if np.mean(sampA) > np.mean(sampB) else 'less'\n",
    "        t_stat, p_value = stats.ttest_ind(T_A, T_B, equal_var=False, alternative=a)\n",
    "        p_best_t = 1 - p_value\n",
    "        best_gr = 'B' if p_best_t >= prob_stop else 'A' if (1 - p_best_t) >= prob_stop else None\n",
    "        if best_gr:\n",
    "            post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "            post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "            pb_gt_pa_bayes = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "            cmp.at[i, 'A_exp'] = ns_A / n_samp_total\n",
    "            cmp.at[i, 'B_exp'] = ns_B / n_samp_total\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p-val'] = max(p_value, 1 - p_value)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, Bayes P(b>a) {pb_gt_pa_bayes:.4f}, T-test p-val {p_value:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3ec00",
   "metadata": {},
   "source": [
    "## Тест $\\chi^2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06de92d",
   "metadata": {},
   "source": [
    "Конверсии могут сравнивать $\\chi^2$-тестом [[Chi2Test](https://en.wikipedia.org/wiki/Chi-squared_test)]. Статистика $\\chi^2$ Пирсона [[Chi2Pearson](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)] для мультиномиальных распределений определена $\\chi^2 = \\sum_{i=1}^k (S_i - Np_i)^2/(Np_i)$, где $N$ - общее количество наблюдений, $S_i$ - фактическое количество наблюдений $i$-категории,  $N p_i$ - ожидаемое при доле $i$-категории $p_i$. Для биномиального распределения $\\chi^2=(S - Np)^2/N p (1-p)$. По центральной предельной теореме $(S - Np)/\\sqrt{N p (1-p)}$ стремится к стандартному нормальному распределению. Распределение суммы квадратов $k$ нормальных случайных величин называют $\\chi^2$-распределением с $k$ степенями свободы $\\chi^2_k = \\sum_{i=1}^{k} X_i^2,\\, X_i \\sim \\text{Norm}(0,1)$ [[Chi2Dist](https://en.wikipedia.org/wiki/Chi-squared_distribution)]. Статистика $\\chi^2$ стремится к $\\chi_1^2$-распределению.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\chi^2 & = \n",
    "\\sum_{i=1}^k \\frac{(S_i - Np_i)^2}{N p_i}\n",
    "\\\\\n",
    "& =\n",
    "\\frac{(S - N p)^2}{N p}\n",
    "+\n",
    "\\frac{((N - S) - N (1-p))^2}{N (1-p)}\n",
    "\\\\\n",
    "& =\n",
    "\\frac{(S - Np)^2}{N p (1-p)} \n",
    "\\to \\chi_1^2, \\quad n \\to \\infty\n",
    "\\\\\n",
    "\\chi^2_k & = \\sum_{i=1}^{k} X_i^2,\\, X_i \\sim \\text{Norm}(0,1)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b9d00",
   "metadata": {},
   "source": [
    "Для А/Б-теста конверсий с двумя группами в предположении одинаковых конверсий $p=(S_A + S_B)/(N_A + N_B)$ тестовая статистика $\\chi^2=(S_A - N_A p)^2/N_A p (1-p) + (S_B - N_B p)^2/N_B p (1-p)$. Ее можно привести к виду $\\chi^2 = (p_A - p_B)^2/(s^2 / N_A + s^2 / N_B)$, $s^2 = p (1 - p)$, $p_A = S_A / N_A$, $p_B = S_B / N_B$. При большом количестве точек распределение $\\chi^2$ можно ожидать близим $\\chi_1^2$. $p$-значение $p=P_{\\chi_1^2}(x > \\chi^2)$. Распределение $\\chi^2_1$ получается при возведении в квадрат стандартного нормального распределения. Область $P_{\\chi_1^2}(x > \\chi^2)$ соответствует областям $P_{Norm(0,1)}(x > \\chi \\cup x < -\\chi)$. По симметрии нормального распределения площади $x > \\chi$ и $x < -\\chi$ одинаковы $P_{Norm(0,1)}(x > \\chi \\cup x < -\\chi) = 2 P_{Norm(0,1)}(x > \\chi)$. Байесовская оценка вероятности конверсии одной группы больше другой с учетом собранных данных при использовании априорного бета-распределения $P(\\mu_B > \\mu_A | S_A, S_B, N_A, N_B) \\approx P_{Norm(p_{\\Delta}, s_{\\Delta}^2)}(x > 0)$, $p_{\\Delta} = p_B - p_A$,  $s_{\\Delta} = s_A^2/N_A + s_B^2/N_B$. В пренебрежении априорным распределением $P(\\mu_B > \\mu_A | S_A, S_B) \\approx 1 - P_{Norm(\\chi, 1)}(x < 0)$. По симметрии $P_{Norm(\\chi, 1)}(x < 0) = P_{Norm(0, 1)}(x > \\chi)$ Поэтому $p$-значение $p \\approx 2( 1 - P(\\mu_B > \\mu_A | S_A, S_B))$. Отсюда $P(p_B > p_A | S_A, S_B) \\approx 1 - p/2$.\n",
    "\n",
    "$$\n",
    "p_A = \\frac{S_A}{N_A}, \\quad \n",
    "p_B = \\frac{S_B}{N_B}, \\quad \n",
    "p = \\frac{S_A + S_B}{N_A + N_B},\n",
    "\\quad\n",
    "s^2 = p (1 - p)\n",
    "\\\\\n",
    "\\begin{split}\n",
    "\\chi^2 & = \\frac{(S_A - N_A p)^2}{N_A p (1-p)} + \\frac{(S_B - N_B p)^2}{N_B p (1-p)} \n",
    "\\\\\n",
    "& = \\frac{N_A N_B (p_A - p_B)^2}{(N_A + N_B) p (1-p)}\n",
    "\\\\\n",
    "& = \\frac{(p_A - p_B)^2}{s^2 / N_A + s^2 / N_B}\n",
    "\\\\\n",
    "\\end{split}\n",
    "\\\\\n",
    "p_A = p_B: \\chi^2 \\to \\chi_1^2, \\, n \\to \\infty\n",
    "\\\\\n",
    "\\begin{split}\n",
    "\\text{p-val} & = P_{\\chi_1^2}(x > \\chi^2 | p_A = p_B)\n",
    "\\\\\n",
    "& = P_{Norm(0,1)}(x > \\chi \\cup x < -\\chi | p_A = p_B) \n",
    "\\\\\n",
    "& = 2 P_{Norm(0,1)}(x > \\chi | p_A = p_B)\n",
    "\\\\\n",
    "& \\approx 2 \\left( 1 - P(p_B > p_A | S_A, S_B) \\right)\n",
    "\\end{split}\n",
    "\\\\\n",
    "P(p_B > p_A | S_A, S_B) \\approx 1 - \\text{p-val}/2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8e2b6",
   "metadata": {},
   "source": [
    "Распределение $\\chi^2_1$ на первом графике ниже. Закрашенная область соответствует $p$-значению $p = P_{\\chi_1^2}(x > \\chi^2)$. На втором графике - стандартное нормальное распределение. Закрашенные темные области $x > \\chi$ и $x < - \\chi$ соответствуют $P_{\\chi_1^2}(x > \\chi^2)$ при возведении в квадрат. Серый график - нормальное распределение $Norm(\\chi, 1)$. Закрашенная область серого графика приближенно равна $1 - P(p_B > p_A | S_A, S_B)$. Площади закрашенной серой и каждой из темных областей совпадают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.3\n",
    "#s = p * (1 - p)\n",
    "#todo: N = 10000\n",
    "#s = p * (1 - p) / N\n",
    "s = 1\n",
    "x0 = p / (p * (1 - p))\n",
    "\n",
    "xaxis_min = 0\n",
    "xaxis_max = 5\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.chi.pdf(x, df=1), \n",
    "                         line_color='black', opacity=0.8, name=f'$\\chi^2_1$'))\n",
    "fig.add_trace(go.Scatter(x=[x0**2, x0**2], y=[0, max(stats.chi.pdf(x, df=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$\\chi^2$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>x0**2], y=stats.chi.pdf(x[x>x0**2], df=1), \n",
    "                         line_color='black', opacity=0.8, name='$P_{\\chi_1^2}(x > \\chi^2)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.update_layout(title='Хи-квадрат',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "xaxis_min = -5\n",
    "xaxis_max = 5\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name=f'$Norm(0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '0'], textposition=\"top center\", \n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=[x0, x0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$\\chi$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=[-x0, -x0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$-\\chi$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>x0], y=stats.norm.pdf(x[x>x0], loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name='$P_{Norm(0,1)}(x > \\chi \\cup x < -\\chi | p_A = p_B)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x[x<-x0], y=stats.norm.pdf(x[x<-x0], loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name='$P_{Norm(0,1)}(x > \\chi | p_A = p_B)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\",\n",
    "                         showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=x0, scale=s), \n",
    "                         line_color='black', opacity=0.2, name='$Norm(\\chi, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0], y=stats.norm.pdf(x[x<0], loc=x0, scale=s), \n",
    "                         line_color=\"rgba(128, 128, 128, 0.2)\", name='$P_{Norm(\\chi,1)}(x < 0)$', fill=\"tozeroy\", fillcolor=\"rgba(128, 128, 128, 0.2)\"))\n",
    "fig.update_layout(title='Нормальные распределения',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[xaxis_min, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  template=\"plotly_white\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6110e2",
   "metadata": {},
   "source": [
    "Соотношение $P(p_B > p_A | S_A, S_B) \\approx 1 - p/2$ проверяется по выборке из двух распределений Бернулли с конверсиями $p_A = 0.1$ и $p_B = 0.105$. Данные для $\\chi^2$-теста задаются в виде таблицы со строками $S_A, N_A-S_A$ и $S_B, N_B - S_B$ [[ScipyChi2Con](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html)]. Только $p$-значение не позволяет выбрать между $p_A > p_B$ и $p_B > p_A$, поэтому дополнительно сравниваются конверсии $p_A$, $p_B$. Видно, что связь $p$-значения и байесовской оценки вероятности численно выполняется. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + ntotal - ns \n",
    "    return stats.beta(a=a, b=b)\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "pA = 0.1\n",
    "pB = pA * 1.05\n",
    "\n",
    "exactA = stats.bernoulli(pA)\n",
    "exactB = stats.bernoulli(pB)\n",
    "\n",
    "N = 30000\n",
    "sampA = exactA.rvs(size=N)\n",
    "sampB = exactB.rvs(size=N)\n",
    "SA = np.sum(sampA)\n",
    "SB = np.sum(sampB)\n",
    "\n",
    "post_dist_A = posterior_dist_binom(ns=SA, ntotal=N)\n",
    "post_dist_B = posterior_dist_binom(ns=SB, ntotal=N)\n",
    "pb_gt_pa_bayes = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "\n",
    "t = np.array([\n",
    "    [SA,     N - SA],\n",
    "    [SB,     N - SB]\n",
    "])\n",
    "chi2_stat, p_value_chi2, dof, expected = stats.chi2_contingency(t, correction=False)\n",
    "p_A_samp = SA / N\n",
    "p_B_samp = SB / N\n",
    "pb_gt_pa_chi = 1 - p_value_chi2 / 2\n",
    "pb_gt_pa_chi = pb_gt_pa_chi if p_B_samp > p_A_samp  else 1 - pb_gt_pa_chi\n",
    "\n",
    "print(f'Bayes P(pb > pa): {pb_gt_pa_bayes:.5g}')\n",
    "print(f\"Chi2: 1-pval/2:   {pb_gt_pa_chi:.5g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a081f",
   "metadata": {},
   "source": [
    "Ниже $p$-значение $\\chi^2$-теста используется для проверки количества правильно угаданных вариантов с большей конверсией в серии экспериментов. В каждом эксперименте 2 группы, конверсия $p_A=0.1$ фиксирована, $p_B$ выбирается случайно в диапазоне $\\pm5\\%$ от $p_A$. В каждой группе добавляются данные по 10000 точек за шаг. На каждом шаге вычисляется $p$-значение $\\chi^2$-теста и $P(p_B > p_A | S_A, S_B) \\approx 1 - p/2$ при $p_B > p_A$ или $P(p_B > p_A | S_A, S_B) \\approx p/2$ при $p_A > p_B$. Эксперимент останавливается, если оценка вероятности конверсии одной группы больше другой превышает `prop_stop` или набрано максимальное количество точек `n_samp_max`. Всего в `nexps=1000` верно угадано 932 варианта. Доля 0.932 близка `prob_stop = 0.95`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a849f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_chi'])\n",
    "\n",
    "p = 0.1\n",
    "nexps = 1000\n",
    "cmp['A'] = [p] * nexps\n",
    "cmp['B'] = p * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 5_000_000\n",
    "n_samp_step = 10_000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    pA = cmp.at[i, 'A']\n",
    "    pB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.bernoulli(p=pA)\n",
    "    exact_dist_B = stats.bernoulli(p=pB)\n",
    "    n_samp_total = 0\n",
    "    ns_A = 0\n",
    "    ns_B = 0\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA = exact_dist_A.rvs(n_samp_step)\n",
    "        dB = exact_dist_B.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        ns_A = ns_A + np.sum(dA)\n",
    "        ns_B = ns_B + np.sum(dB)\n",
    "        p_A_samp = ns_A / n_samp_total\n",
    "        p_B_samp = ns_B / n_samp_total\n",
    "        t = np.array([\n",
    "            [ns_A,     n_samp_total - ns_A],\n",
    "            [ns_B,     n_samp_total - ns_B]\n",
    "        ])\n",
    "        chi2_stat, p_value_chi, dof, expected = stats.chi2_contingency(t, correction=False)\n",
    "        #chi2_stat, p_value_chi, dof, expected = stats.chi2_contingency(t, correction=True)\n",
    "        pb_gt_pa_chi = 1 - p_value_chi / 2\n",
    "        pb_gt_pa_chi = pb_gt_pa_chi if p_B_samp > p_A_samp  else 1 - pb_gt_pa_chi\n",
    "        best_gr = 'B' if pb_gt_pa_chi >= prob_stop else 'A' if 1 - pb_gt_pa_chi >= prob_stop else None\n",
    "        if best_gr:\n",
    "            post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "            post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "            pb_gt_pa_bayes = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "            cmp.at[i, 'A_exp'] = p_A_samp\n",
    "            cmp.at[i, 'B_exp'] = p_B_samp\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p_best_chi'] = max(pb_gt_pa_chi, 1 - pb_gt_pa_chi)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P_best Bayes {max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes):.4f}, Chi (1-pval/2): {1 - p_value_chi/2:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f9f73",
   "metadata": {},
   "source": [
    "## U-критерий Манна-Уитни"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607868a8",
   "metadata": {},
   "source": [
    "Для выборок размера $N_A, N_B$ из двух случайных величин $A, B$ статистика Манна-Уитни [[MannWhitneyU](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)] определена через попарное сравнение элементов. Для непрерывных распределений вероятность совпадения элементов в выборках нулевая. В этом случае $U$-статистика определена как количество пар $(A_i, B_j)$, где элемент $A_i$ больше $B_j$: $U_A = \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(A_i > B_j)$. Cтатистику также можно записать в виде $U_A = R_A - N_A (N_A + 1)/2$, где $R_A$ - сумма рангов элементов $А$ в объединенной выборке. Эквивалентность определений можно увидеть следующим образом: слагаемое $N_A (N_A + 1)/2$ соответствует минимальной сумме рангов если все элементы $A$ меньше $B$ и считается как сумма арифметической прогрессии. Если наибольший элемент $A$ больше $n$ элементов $B$, то $U_A = n$ и $R_A = N_A (N_A + 1)/2 + n$, аналогично для других элементов. При большом количестве точек отношение $U_A / N_A N_B$ будет стремиться к вероятности элемента выборки $A$ больше $B$ ($U_A$ - число пар $A$ больше $B$, $N_A N_B$ - общее количество пар)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcceca1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "A, B & - \\text{непрерывные распределения}\n",
    "\\\\\n",
    "U_A & = \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(A_i > B_j),\n",
    "\\quad\n",
    "I(\\cdot) = 1 \\text{ если условие выполнено, иначе } 0 \n",
    "\\\\\n",
    "U_A & = R_A - N_A (N_A + 1)/2, \\quad R_A \\text{- сумма рангов элементов А в объединенной выборке}\n",
    "\\\\\n",
    "\\frac{U_A}{N_A N_B} & \\to P(A > B),\n",
    "\\quad\n",
    "N_A, N_B \\to \\infty\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6f75f",
   "metadata": {},
   "source": [
    "Нулевая гипотеза - распределения $A$ и $B$ одинаковы. Для выборок $N_A, N_B$ из одного распределения можно посчитать среднее $E[U]$ и дисперсию $\\text{Var}(U)$ $U$-статистики. Величина $(U - E[U])/\\sqrt{Var(U)}$ будет стремиться к нормальному распределению [нужна ссылка]. $p$-значение определено как вероятность получить более экстремальное значение $p = P_{Norm(0,1)}(x > u_0)$, $u_0 = (U - E[U])/\\sqrt{\\text{Var}(U)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c54ba2",
   "metadata": {},
   "source": [
    "$$\n",
    "A = B: \n",
    "\\quad\n",
    "E[U] = \\frac{N_A N_B}{2}, \\quad\n",
    "\\text{Var}(U) = \\frac{N_A N_B (N_A + N_B + 1)}{12}\n",
    "\\\\\n",
    "\\frac{U - E[U]}{\\sqrt{\\text{Var}(U)}} \\to Norm(0,1), \\quad N_A, N_B \\to \\infty\n",
    "\\\\\n",
    "p = P_{Norm(0,1)}(x > u_0), \n",
    "\\quad\n",
    "u_0 = \\frac{U - E[U]}{\\sqrt{\\text{Var}(U)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a827a",
   "metadata": {},
   "source": [
    "В байесовском подходе вероятность $P(B>A)$ можно оценить сравнением апостериорных предиктивных распределений. Т.е. нужно предположить модели распределений, построить апостериорные распределения параметров, построть апостериорные предиктивные распределения. По построенным апостериорным предиктивным распределениям можно оценить $P(B>A)$. Это будет точечная оценка, а не распеделение. Такой подход требует предположения распределений.\n",
    "\n",
    "Другой вариант - моделировать вероятность $\\theta = P(B > A)$. Сравнение каждой пары $X_{ij} = I(B_i > A_j)$ - точка. Сумма будет $U$-статистикой. Для правдоподобия можно выбрать биномиальное распределение $P(U | \\theta) = \\text{Binom}(U | \\theta, N_A N_B)$. При сравнении каждой точки $A$ с каждой точкой $B$ результаты в парах с одинаковыми $A_i$ или $B_j$ не будут независимы. Будет использоваться упрощенная модель, в которой каждая точка из $A$ сравнивается только с одной точкой $B$. Можно ожидать более широкой дисперсии, чем в $U$. Тогда пары будут независимы. Как в конверсиях априорное распределение удобно задать бета-распределением. Апостериорное также будет бета-распределением. \n",
    "\n",
    "$$\n",
    "\\theta = P(A > B)\n",
    "\\\\\n",
    "X_{ij} = I(A_i > B_j)\n",
    "\\\\\n",
    "U = \\sum X_{ij}\n",
    "\\\\\n",
    "P(X | \\theta) = \\text{Bernoulli}(\\theta)\n",
    "\\\\\n",
    "P(U | \\theta) = \\text{Binom}(U | \\theta, \\min(N_A, N_B))\n",
    "\\\\\n",
    "P(\\theta) = \\text{Beta}(\\alpha_0, \\beta_0)\n",
    "\\\\\n",
    "P(\\theta | U) = \\text{Beta}(U + \\alpha_0, \\min(N_A, N_B) - U + \\beta_0)\n",
    "\\approx \\text{Norm}(\\mu, s)\n",
    "\\\\\n",
    "\\begin{split}\n",
    "P(A > B) = P(\\theta  > 0.5 | U) & = P(\\text{Norm}(x > 0.5; \\mu, s))\n",
    "\\end{split}\n",
    "\\\\\n",
    "P(B > A) = 1 - P(\\theta  > 0.5 | U)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d74d305",
   "metadata": {},
   "source": [
    "На графике ниже два нормальных распределения. На втором графике - распределение $U$-статистики в предположении эквивалентности распределений и фактическое значение. Закрашенная область соответствует $p$-значению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "mu1, sigma1 = 0, 1\n",
    "mu2, sigma2 = -0.1, 1\n",
    "exactA = stats.norm(loc=mu1, scale=sigma1)\n",
    "exactB = stats.norm(loc=mu2, scale=sigma2)\n",
    "\n",
    "p_b_gt_a_norm = 1 - stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "p_a_gt_b_norm = stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "\n",
    "#U\n",
    "nA = nB = 1500\n",
    "sampA = exactA.rvs(nA)\n",
    "sampB = exactB.rvs(nB)\n",
    "U, p = mannwhitneyu(sampA, sampB, alternative='greater')\n",
    "eu = nA * nB / 2\n",
    "varu = nA * nB * (nA + nB + 1) / 12\n",
    "u0 = (U - eu) / np.sqrt(varu)\n",
    "p_b_gt_a_u = 1 - U / (nA*nB)\n",
    "\n",
    "# Ua = sum(np.sum(a > sampB) for a in sampA)\n",
    "# print(f'Ua:{Ua}, U:{U}')\n",
    "\n",
    "\n",
    "#P(a>b)\n",
    "p_u = stats.norm(loc=eu/(nA*nB), scale=np.sqrt(varu/(nA*nA*nB*nB)))\n",
    "u0_p = U / (nA*nB)\n",
    "print(f'p: {p}, cdf(u0): {stats.norm.cdf(u0)}, cdf(u0p): {p_u.cdf(u0_p)}')\n",
    "\n",
    "\n",
    "#elementwise\n",
    "a0 = 1\n",
    "b0 = 1\n",
    "Ua = np.sum(sampA > sampB)\n",
    "post_u_ewise = stats.beta(a0 + Ua, b0 + nA - Ua)\n",
    "\n",
    "\n",
    "x = np.linspace(-7, 7, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactA.pdf(x),\n",
    "    mode='lines', name='A', line_color='black'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactB.pdf(x),\n",
    "    mode='lines', name='B', line_color='blue', opacity=0.7))\n",
    "fig.update_layout(\n",
    "    title=\"A, B\",\n",
    "    template=\"plotly_white\",\n",
    "    #yaxis_range=[0,1.1]\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "xaxis_min = 0.4\n",
    "xaxis_max = 0.6\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=p_u.pdf(x), \n",
    "                         line_color='black', opacity=0.8, name=f'$U/N_A N_B$'))\n",
    "fig.add_trace(go.Scatter(x=[u0_p, u0_p], y=[0, max(p_u.pdf(x))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$u_0$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "# fig.add_trace(go.Scatter(x=[p_a_gt_b_norm, p_a_gt_b_norm], y=[0, max(p_u.pdf(x))*1.1], \n",
    "#                          line_color='black', \n",
    "#                          mode='lines+text', \n",
    "#                          text=['', '$P(A>B)$'], textposition=\"top center\",\n",
    "#                          line_dash='solid', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>u0_p], y=p_u.pdf(x[x>u0_p]), \n",
    "                         line_color='black', opacity=0.8, name='$P(x > u_0)$', \n",
    "                         fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_u_ewise.pdf(x),\n",
    "                         line_color='black', opacity=0.3, name=f'PostUElementwise'))\n",
    "fig.add_trace(go.Scatter(x=x[x<0.5], y=post_u_ewise.pdf(x[x<0.5]), \n",
    "                         line_color='black', opacity=0.3, name='$P(x < 0.5)$', \n",
    "                         fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.3)\"))\n",
    "fig.update_layout(\n",
    "    title='P(B>A)',\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef141e",
   "metadata": {},
   "source": [
    "Для нормальных распределений [[NormalSum](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables)]\n",
    "\n",
    "$$\n",
    "A \\sim \\text{Norm}(\\mu_A, \\sigma_A^2),\n",
    "\\quad\n",
    "B \\sim \\text{Norm}(\\mu_B, \\sigma_B^2)\n",
    "\\\\\n",
    "B - A \\sim \\text{Norm}(\\mu_B - \\mu_A, \\sigma_A^2 + \\sigma_B^2)\n",
    "\\\\\n",
    "P(B > A) = P_{B - A}(x > 0) = 1 - F_{B-A}(0) \n",
    "$$\n",
    "\n",
    "Сравниваются не средние, а все распределение. Вероятность $U/N_A N_B$ может не доходить до 1. \n",
    "[[ScipyMannWhitneyU](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'pval: {stats.norm.cdf(u0)}')\n",
    "print(f'scipy pval: {p}')\n",
    "print(f'Bayes P(A>B) {1 - post_u_ewise.cdf(0.5)}')\n",
    "print()\n",
    "print(f'P(B>A) exact: {p_b_gt_a_norm}')\n",
    "print(f'P(B>A) U: {p_b_gt_a_u}')\n",
    "print(f'Bayes Mean P(B>A) {1 - post_u_ewise.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bc75e",
   "metadata": {},
   "source": [
    "Проверка количества правильно угаданных вариантов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9388cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_u'])\n",
    "\n",
    "mua = 0.1\n",
    "nexps = 100\n",
    "cmp['A'] = [mua] * nexps\n",
    "cmp['B'] = mua * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 1_000_000\n",
    "n_samp_step = 10000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    mua = cmp.at[i, 'A']\n",
    "    mub = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.norm(loc=mua)\n",
    "    exact_dist_B = stats.norm(loc=mub)\n",
    "    n_samp_total = 0\n",
    "    sampA = exact_dist_A.rvs(n_samp_max)\n",
    "    sampB = exact_dist_B.rvs(n_samp_max)\n",
    "    while n_samp_total < n_samp_max:\n",
    "        n_samp_total += n_samp_step\n",
    "        U, p = mannwhitneyu(sampA[:n_samp_total], sampB[:n_samp_total], alternative='greater')\n",
    "        pb_gt_pa_u = 1 - U / n_samp_total / n_samp_total\n",
    "        best_gr = 'B' if p >= prob_stop else 'A' if 1 - p >= prob_stop else None\n",
    "        if best_gr:\n",
    "            #post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "            #post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "            pb_gt_pa_bayes = None #prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "            cmp.at[i, 'A_exp'] = sampA[:n_samp_total].mean()\n",
    "            cmp.at[i, 'B_exp'] = sampB[:n_samp_total].mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = None #max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p_best_u'] = max(pb_gt_pa_u, 1 - pb_gt_pa_u)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P_best Bayes {None}, U P(B>A): {pb_gt_pa_u:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_u'])\n",
    "\n",
    "mua = 0.1\n",
    "nexps = 1000\n",
    "cmp['A'] = [mua] * nexps\n",
    "cmp['B'] = mua * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "#cmp['B'] = mua * (1 + np.random.choice([-1,1], size=nexps) * stats.uniform.rvs(loc=0.01, scale=0.04, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 5_000_000\n",
    "n_samp_step = 10000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    mua = cmp.at[i, 'A']\n",
    "    mub = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.norm(loc=mua)\n",
    "    exact_dist_B = stats.norm(loc=mub)\n",
    "    n_samp_total = 0\n",
    "    sampA = exact_dist_A.rvs(n_samp_max)\n",
    "    sampB = exact_dist_B.rvs(n_samp_max)\n",
    "    while n_samp_total < n_samp_max:\n",
    "        n_samp_total += n_samp_step\n",
    "        #U, p = mannwhitneyu(sampA[:n_samp_total], sampB[:n_samp_total], alternative='greater')\n",
    "        #pb_gt_pa_u = 1 - U / n_samp_total / n_samp_total\n",
    "        #best_gr = 'B' if p >= prob_stop else 'A' if 1 - p >= prob_stop else None\n",
    "        a0 = 100000\n",
    "        b0 = 100000\n",
    "        Ub = np.sum(sampB[:n_samp_total] > sampA[:n_samp_total])\n",
    "        post_u_ewise = stats.beta(a0 + Ub, b0 + n_samp_total - Ub)\n",
    "        pb_gt_pa_bayes = 1 - post_u_ewise.cdf(0.5)\n",
    "        best_gr = 'B' if pb_gt_pa_bayes >= prob_stop else 'A' if 1 - pb_gt_pa_bayes >= prob_stop else None\n",
    "        if best_gr:\n",
    "            #post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "            #post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "            cmp.at[i, 'A_exp'] = sampA[:n_samp_total].mean()\n",
    "            cmp.at[i, 'B_exp'] = sampB[:n_samp_total].mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best_bayes'] = max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "            cmp.at[i, 'p_best_u'] = None #max(pb_gt_pa_u, 1 - pb_gt_pa_u)\n",
    "            break\n",
    "    print(f'done {i}: nsamp {n_samp_total}, best_gr {best_gr}, P_best Bayes {pb_gt_pa_bayes:.4f}, U P(B>A): {None}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")\n",
    "finished = np.sum(cmp['best_exp'].notna())\n",
    "cor_guess_finished = np.sum(cmp.loc[cmp['best_exp'].notna(), 'correct'])\n",
    "print(f\"NexpFinished: {finished}, Correct Guesses: {cor_guess_finished}, Accuracy: {cor_guess_finished / finished}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd26fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\n",
    "    'display.max_rows', None,\n",
    "    'display.max_columns', None,\n",
    "    'display.width', None,\n",
    "    'display.max_colwidth', None\n",
    "):\n",
    "    display(cmp.head(130))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08921f6",
   "metadata": {},
   "source": [
    "Модели не всегда ошибаются согласованно. В отдельных ошибках байсовская модель показывает больше 95% уверенности, U-статистика меньше 95, и для некоторых ошибок U-теста байесовская модель не показывае недостаточную уверенность для остановки. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be6378",
   "metadata": {},
   "source": [
    "Для $p$-значений $t$-теста, $\\chi^2$-теста и $U$-критерия Манна-Уитни показана связь с байесовскими вероятностями параметров одной группы больше другой. $P$-значения численно близки байесовским вероятностям несмотря на различия в определениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247790d6",
   "metadata": {},
   "source": [
    "## Ссылки\n",
    "\n",
    "[Chi2Dist] - [Chi-squared Distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution), *Wikipedia.*  \n",
    "[Chi2Pearson] - [Pearson’s Chi-squared Test](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test), *Wikipedia.*  \n",
    "[Chi2Test] - [Chi-squared Test](https://en.wikipedia.org/wiki/Chi-squared_test), *Wikipedia.*  \n",
    "[MannWhitneyU] - [Mann–Whitney U Test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test), *Wikipedia.*  \n",
    "[NormalSum] - [Sum of Normally Distributed Random Variables](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables), *Wikipedia.*  \n",
    "[PVal] - [P-value](https://en.wikipedia.org/wiki/P-value), *Wikipedia.*  \n",
    "[ScipyChi2Con] - [scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html), *SciPy Reference.*  \n",
    "[ScipyMannWhitneyU] - [scipy.stats.mannwhitneyu](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html), *SciPy Reference.*  \n",
    "[ScipyTTestInd] - [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html), *SciPy Reference.*  \n",
    "[TailedTests] - [One- and Two-tailed Tests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests), *Wikipedia.*  \n",
    "[TDist] - [Student’s t-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution), *Wikipedia.*  \n",
    "[TestStat] - [Test Statistic](https://en.wikipedia.org/wiki/Test_statistic), *Wikipedia.*  \n",
    "[TTest] - [Student’s t-test](https://en.wikipedia.org/wiki/Student%27s_t-test), *Wikipedia.*  \n",
    "[WelchT] - [Welch’s t-test](https://en.wikipedia.org/wiki/Welch%27s_t-test), *Wikipedia.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf3ef93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9892213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305aaace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6565a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fd44f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc09f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c76b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best_bayes', 'p_best_u'])\n",
    "\n",
    "mua = 0.1\n",
    "nexps = 1000\n",
    "cmp['A'] = [mua] * nexps\n",
    "cmp['B'] = mua * (1 + np.random.choice([-1, 1], size=nexps) * stats.uniform.rvs(loc=0.02, scale=0.05, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "n_samp_max = 200_000\n",
    "n_samp_step = 10000\n",
    "prob_stop = 0.95\n",
    "\n",
    "for i in range(nexps):\n",
    "    mua = cmp.at[i, 'A']\n",
    "    mub = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.norm(loc=mua)\n",
    "    exact_dist_B = stats.norm(loc=mub)\n",
    "    n_samp_total = 0\n",
    "    sampA = exact_dist_A.rvs(n_samp_max)\n",
    "    sampB = exact_dist_B.rvs(n_samp_max)\n",
    "    U, p = mannwhitneyu(sampA, sampB, alternative='less')\n",
    "    pb_gt_pa_u = 1 - U / n_samp_max**2\n",
    "    best_gr = 'B' if 1 - p >= prob_stop else 'A' if p >= prob_stop else None\n",
    "    if best_gr:\n",
    "        #post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "        #post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "        pb_gt_pa_bayes = None #prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "        cmp.at[i, 'A_exp'] = sampA.mean()\n",
    "        cmp.at[i, 'B_exp'] = sampB.mean()\n",
    "        cmp.at[i, 'exp_samp_size'] = n_samp_max\n",
    "        cmp.at[i, 'best_exp'] = best_gr\n",
    "        cmp.at[i, 'p_best_bayes'] = None #max(pb_gt_pa_bayes, 1 - pb_gt_pa_bayes)\n",
    "        cmp.at[i, 'p_best_u'] = max(pb_gt_pa_u, 1 - pb_gt_pa_u)\n",
    "    print(f'done {i}: nsamp {n_samp_max}, best_gr {best_gr}, P_best Bayes {None}, U P(B>A): {pb_gt_pa_u:.4f}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(30))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")\n",
    "\n",
    "cmpfinished = cmp[cmp['exp_samp_size'].notna()]\n",
    "cor_guess = np.sum(cmpfinished['correct'])\n",
    "print(f\"Finished: {cmpfinished.shape[0]}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / cmpfinished.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd28d39",
   "metadata": {},
   "source": [
    "Аналитическое значение P(X > Y): интеграл по всем x от плотности вероятности f_X(x) * функцию распределения F_Y(x) * dx (конкретное x * вероятность выпадения в X * вероятность выпадения такого или меньшего значения в Y).\n",
    "\n",
    "Для нормальных A, B аналитически: $P(B>A) = F_{B-A}(0) = \\Phi(0, \\mu_B - \\mu_A, s_A^2 + s_B^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6701a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "mu1, sigma1 = 0, 1\n",
    "mu2, sigma2 = 0.005, 1\n",
    "exactA = stats.norm(loc=mu1, scale=sigma1)\n",
    "exactB = stats.norm(loc=mu2, scale=sigma2)\n",
    "\n",
    "p_b_gt_a_norm = stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "\n",
    "nstep = 1000\n",
    "nmax = 100000\n",
    "u_norm_values = []\n",
    "p_values = []\n",
    "n = []\n",
    "sampA = np.array([])\n",
    "sampB = np.array([])\n",
    "\n",
    "for ntotal in range(nstep, nmax, nstep):\n",
    "    dA = exactA.rvs(nstep)\n",
    "    dB = exactB.rvs(nstep)\n",
    "    sampA = np.concatenate([sampA, dA])\n",
    "    sampB = np.concatenate([sampB, dB])\n",
    "    U, p = mannwhitneyu(sampA, sampB, alternative='less')\n",
    "    n.append(ntotal)\n",
    "    u_norm_values.append(U / (ntotal * ntotal))\n",
    "    p_values.append(p)\n",
    "\n",
    "    \n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactA.pdf(x),\n",
    "    mode='lines', name='A'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactB.pdf(x),\n",
    "    mode='lines', name='B'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"A, B\",\n",
    "    template=\"plotly_white\",\n",
    "    yaxis_range=[0,1.1]\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n, y=u_norm_values,\n",
    "    mode='lines+markers',\n",
    "    name='Normalized U (U / n^2)'\n",
    "))\n",
    "fig.add_trace(go.Scatter(x=[n[0], n[-1]], y=[p_b_gt_a_norm, p_b_gt_a_norm], name='P(B>A) exact'))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n, y=p_values,\n",
    "    mode='lines+markers',\n",
    "    name='p-values'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"Mann-Whitney U Statistic vs Sample Size\",\n",
    "    xaxis_title=\"Sample size (n_A = n_B)\",\n",
    "    yaxis_title=\"Normalized U\",\n",
    "    legend_title=\"Metric\",\n",
    "    template=\"plotly_white\",\n",
    "    yaxis_range=[0,1.1]\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "eu = ntotal * ntotal / 2\n",
    "varu = ntotal * ntotal * (ntotal + ntotal +1) / 12\n",
    "u0 = (U - eu) / np.sqrt(varu)\n",
    "      \n",
    "xaxis_min = -7\n",
    "xaxis_max = 7\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=1), \n",
    "                         line_color='black', opacity=0.8, name=f'$Norm(0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[u0, u0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$u_0$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>u0], y=stats.norm.pdf(x[x>u0], loc=0, scale=s), \n",
    "                         line_color='black', opacity=0.8, name='$P(x > u_0)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.show()\n",
    "\n",
    "print(f'pval: {stats.norm.cdf(u0)}')\n",
    "print(f'scipy pval: {p_values[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925367c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c3e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8c30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bayesian_bootstrap_p_ab(sampA, sampB, S=5000):\n",
    "    nA = len(sampA)\n",
    "    nB = len(sampB)\n",
    "\n",
    "    # Pairwise comparison matrix\n",
    "    M = (sampA[:, None] > sampB[None, :]).astype(float)\n",
    "\n",
    "    p_samples = np.empty(S)\n",
    "\n",
    "    for s in range(S):\n",
    "        wA = np.random.dirichlet(np.ones(nA))\n",
    "        wB = np.random.dirichlet(np.ones(nB))\n",
    "        p_samples[s] = wA @ M @ wB\n",
    "\n",
    "    return p_samples\n",
    "\n",
    "\n",
    "bayesian_bootstrap_p_ab(sampA, sampB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21f042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406bf01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04814ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91822f2b",
   "metadata": {},
   "source": [
    "В байесовском подходе оценка $P(B>A)$ строится по апостериорным предиктивным распределениям. Для нормального распределения при использовании модели с фиксированной дисперсией апостериорное предиктивное распределение $P(x | \\mathcal{D})$ будет нормальным."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d0edc9",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "\\text{Правдоподобие: } P(\\mathcal{D} | \\mathcal{H}) & = \\text{Norm}(x | \\mu, \\sigma_x^2) = \n",
    "\\frac{1}{\\sqrt{2 \\pi \\sigma_x^2}} e^{-\\tfrac{(x - \\mu)^2}{2 \\sigma_x^2}}\n",
    "\\\\\n",
    "\\text{Априорное: } P(\\mathcal{H}) & = \\text{Norm}(\\mu | \\mu_0, \\sigma_0^2) = \n",
    "\\frac{1}{\\sqrt{2 \\pi \\sigma_{0}^2}} e^{-\\tfrac{(\\mu-\\mu_0)^2}{2 \\sigma_{0}^2}} \n",
    "\\\\\n",
    "\\text{Апостериорное: } P(\\mathcal{H} | \\mathcal{D}) & = \\text{Norm}(\\mu | \\mu_N, \\sigma_N^2),\n",
    "\\quad\n",
    "\\sigma_N^2 = \\frac{\\sigma_0^2 \\sigma_x^2}{\\sigma_x^2 + N \\sigma_0^2},\n",
    "\\quad\n",
    "\\mu_N = \\mu_0 \\frac{\\sigma_N^2}{\\sigma_0^2} + \\frac{\\sigma_N^2}{\\sigma_x^2} \\sum_i^N x_i\n",
    "\\\\\n",
    "\\text{Апостериорное предиктивное: } \n",
    "P(x | \\mathcal{D}) & = \n",
    "\\int \\text{Norm}(x | \\mu, \\sigma_x^2) \\text{Norm}(\\mu | \\mu_N, \\sigma_N^2) d\\mu\n",
    "= \\text{Norm}(x | \\mu_N, \\sigma_x^2 + \\sigma_N^2)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f67ad42",
   "metadata": {},
   "source": [
    "По выборкам в группах можно построить два апостериорных предиктивных распределения. По ним посчитать вероятность $P(B > A | \\mathcal{D}) = P(B - A | \\mathcal{D} > 0)$. Для нормальных распределений распределение разности также будет нормальным распределением $B - A | \\mathcal{D} \\sim Norm(\\mu_D, \\sigma_D)$.\n",
    "\n",
    "$$\n",
    "B - A | \\mathcal{D} \\sim \\text{Norm}(\\mu_D, \\sigma_D), \\quad\n",
    "\\mu_D = \\mu_{N_B} - \\mu_{N_A}, \\quad\n",
    "\\sigma_D^2 = \\sigma_{N_A}^2 + \\sigma_{x_A}^2 + \\sigma_{N_B}^2 + \\sigma_{x_B}^2\n",
    "\\\\\n",
    "P(B - A | \\mathcal{D} > 0) = 1 - F_{B-A|\\mathcal{D}}(0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4858b8f9",
   "metadata": {},
   "source": [
    "Аналогом $p$-значения $U$-теста в байесовском подходе будет расчет $U$-статистики по выборкам из апостериорных предиктивных распределений того же размера, что и исходные данные. В этом нет необходимости, т.к. есть полные оценки  предиктивных распределений и по ним можно посчитать $P(B > A | \\mathcal{D})$. Остается вопрос точности этой оценки. По мере роста $N$ слагаемые $\\sigma_{N_A}$ и $\\sigma_{N_B}$ стремятся к 0. Поэтому $\\sigma_D^2$ стремится к точной дисперсии $B-A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd12e4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79009cad",
   "metadata": {},
   "source": [
    "[[UStat](https://en.wikipedia.org/wiki/U-statistic)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6919dd",
   "metadata": {},
   "source": [
    "Можно записать через сумму рангов\n",
    "\n",
    "$$\n",
    "U_A = R_A - \\frac{n_A (n_A + 1)}{2}\n",
    "\\\\\n",
    "\\text{where } \n",
    "R_A = \\sum_{i=1}^{n_A} \\text{rank}(X_i)\n",
    "\\text{ is the sum of ranks of group A in the combined dataset.}\n",
    "$$\n",
    "\n",
    "$n_A (n_A + 1)/2$ - минимальный ранг если все элементы A меньше B, считается как арифметическая прогрессия.\n",
    "Если наибольший элемент A больше $n$ элементов B, то $U_A = n$ и $R_A = n_A (n_A + 1)/2 + n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22595f2e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Let } n = n_1 + n_2,\\ \\{R_1,\\dots,R_{n_1}\\} \\text{ be a simple random sample without replacement from } \\{1,\\dots,n\\}\n",
    "\\\\\n",
    "S = \\sum_{i=1}^{n_1} R_i\n",
    "\\\\\n",
    "\\operatorname{Var}(S)\n",
    "= \\sum_{i=1}^{n_1} \\operatorname{Var}(R_i)\n",
    "+ 2 \\sum_{i<j} \\operatorname{Cov}(R_i,R_j)\n",
    "\\\\\n",
    "\\mathbb{E}[R_i] = \\frac{n+1}{2}\n",
    "\\\\\n",
    "\\operatorname{Var}(R_i) = \\frac{1}{n}\\sum_{k=1}^n \\left(k-\\frac{n+1}{2}\\right)^2 = \\frac{n^2-1}{12}\n",
    "\\\\\n",
    "\\operatorname{Cov}(R_i,R_j)\n",
    "= -\\frac{\\operatorname{Var}(1,\\dots,n)}{n-1}\n",
    "= -\\frac{n^2-1}{12(n-1)}\n",
    "\\\\\n",
    "\\operatorname{Var}(S)\n",
    "= n_1\\frac{n^2-1}{12}\n",
    "+ 2\\binom{n_1}{2}\\left(-\\frac{n^2-1}{12(n-1)}\\right)\n",
    "\\\\\n",
    "= \\frac{n^2-1}{12}\\left[n_1-\\frac{n_1(n_1-1)}{n-1}\\right]\n",
    "\\\\\n",
    "= \\frac{n^2-1}{12}\\cdot\\frac{n_1(n-n_1)}{n-1}\n",
    "\\\\\n",
    "= \\frac{n^2-1}{12}\\cdot\\frac{n_1 n_2}{n-1}\n",
    "\\\\\n",
    "= \\frac{n_1 n_2 (n+1)}{12}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009025d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e8e7c33",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Let A_1,...,A_{n_1} and B_1,...,B_{n_2} be two independent samples\n",
    "from the same continuous distribution (H_0).}\n",
    "\\\\\n",
    "\\text{Define the Mann–Whitney U statistic as}\n",
    "U = \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_2} I_{ij},\n",
    "\\text{where }\n",
    "I_{ij} =\n",
    "\\begin{cases}\n",
    "1, & A_i > B_j \\\\\n",
    "0, & A_i < B_j\n",
    "\\end{cases}\n",
    "\\\\\n",
    "% Mean\n",
    "\\text{Under H_0: }\n",
    "P(A_i > B_j) = 1/2\n",
    "\\\\\n",
    "E[I_{ij}] = 1/2\n",
    "\\\\\n",
    "E[U]\n",
    "= \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_2} E[I_{ij}]\n",
    "= n_1 n_2 \\cdot \\frac{1}{2}\n",
    "= \\frac{n_1 n_2}{2}\n",
    "\\\\\n",
    "% Variance\n",
    "Var(U)\n",
    "= Var\\left( \\sum_{i,j} I_{ij} \\right)\n",
    "= \\sum_{i,j} Var(I_{ij})\n",
    "  + 2 \\sum_{(i,j)<(k,l)} Cov(I_{ij}, I_{kl})\n",
    "\\\\\n",
    "% Single indicator variance\n",
    "Var(I_{ij}) = \\frac{1}{2}\\left(1-\\frac{1}{2}\\right) = \\frac{1}{4}\n",
    "\\\\\n",
    "\\sum Var(I_{ij}) = \\frac{n_1 n_2}{4}\n",
    "\\\\\n",
    "% Covariance terms\n",
    "Cov(I_{ij}, I_{kl}) \\neq 0\n",
    "\\iff (i=k, j\\neq l) \\text{ or } (i\\neq k, j=l)\n",
    "\\\\\n",
    "% Example: same A_i, different B_j, B_k\n",
    "Cov(I_{ij}, I_{ik})\n",
    "= E[I_{ij} I_{ik}] - E[I_{ij}]E[I_{ik}]\n",
    "\\\\\n",
    "E[I_{ij} I_{ik}]\n",
    "= P(A_i > B_j \\cap A_i > B_k)\n",
    "= \\frac{1}{3}\n",
    "\\\\\n",
    "Cov(I_{ij}, I_{ik})\n",
    "= \\frac{1}{3} - \\left(\\frac{1}{2}\\right)^2\n",
    "= \\frac{1}{12}\n",
    "\\\\\n",
    "% Counting covariance terms\n",
    "\\text{Number of (i=j shared) terms:}\n",
    "n_1 \\binom{n_2}{2}\n",
    "\\\\\n",
    "\\text{Number of (j shared) terms:}\n",
    "n_2 \\binom{n_1}{2}\n",
    "\\\\\n",
    "% Total variance\n",
    "Var(U)\n",
    "= \\frac{n_1 n_2}{4}\n",
    "  + 2 \\cdot \\frac{1}{12}\n",
    "    \\left[\n",
    "      n_1 \\binom{n_2}{2}\n",
    "      + n_2 \\binom{n_1}{2}\n",
    "    \\right]\n",
    "= \\frac{n_1 n_2 (n_1 + n_2 + 1)}{12}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03826810",
   "metadata": {},
   "source": [
    "Для выборок размера $N_A, N_B$ из двух случайных величин $A, B$ статистика Манна-Уитни [[MannWhitneyU](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)] определена через попарное сравнение элементов $U_A = \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(A_i > B_j) + \\frac{1}{2} \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(A_i = B_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8438689",
   "metadata": {},
   "source": [
    "Пусть есть 2 случайных величины $A$ и $B$ и выборки размера $N_A, N_B$. $U$- статистика Манна-Уитни [[MannWhitneyU](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)] определена через попарное сравнение элементов в выборках $U_A = \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(X_i > Y_j) \n",
    "      + \\frac{1}{2} \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(X_i = Y_j)$ \n",
    "\n",
    "Для непрерывных распределений в выборках нет одинаковых элементов и статистику можно записать в виде $U_A = R_A - N_A (N_A + 1)/2$, где $R_A$ - сумма рангов элементов А в объединенной выборке. Слагаемое $N_A (N_A + 1)/2$ соответствует минимальнорму рангу если все элементы A меньше B и считается как сумма арифметической прогрессии. Эквивалентность определений можно увидеть следующим образом: если наибольший элемент A больше $n$ элементов B, то $U_A = n$ и $R_A = N_A (N_A + 1)/2 + n$, аналогично для других элементов. Для $U_B = N_A N_B - U_A = N_A N_B + N_A (N_A + 1) / 2 - R_A$.\n",
    "\n",
    "Интерпретация $U$-статистики: $U_A / n_A n_B$ - вероятность элемента выборки A больше B. $U_A$ - число элементов A больше B, $n_A n_B$ - общее количество пар. $U/n_A n_B$ интерпретируется как вероятность элемента A больше B. Сравниваются не средние, а все распределение. Вероятность $U/n_A n_B$ может не доходить до 1. \n",
    "\n",
    "$$\n",
    "U_A = \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(X_i > Y_j) \n",
    "      + \\frac{1}{2} \\sum_{i=1}^{N_A} \\sum_{j=1}^{N_B} I(X_i = Y_j),\n",
    "\\quad\n",
    "I(\\cdot) = 1 \\text{ если условие выполнено, иначе } 0 \n",
    "\\\\\n",
    "\\frac{U_A}{N_A N_B} \\to P(X > Y) + \\frac{1}{2} P(X = Y),\n",
    "\\quad\n",
    "N_A, N_B \\to \\infty\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1c0e6",
   "metadata": {},
   "source": [
    "Для $U_B = N_A N_B - U_A = N_A N_B + N_A (N_A + 1) / 2 - R_A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013bfdea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "019a82ed",
   "metadata": {},
   "source": [
    "Апостериорное предиктивное:  \n",
    "https://en.wikipedia.org/wiki/Conjugate_prior   \n",
    "https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf    \n",
    "вычисление интеграла:  \n",
    "https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables  \n",
    "\n",
    "\n",
    "$$\n",
    "P(x | \\mathcal{D}) = Norm(x | \\mu_N, \\sigma_N^2 + \\sigma_x^2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(x | \\mathcal{D}) & = \n",
    "\\int Norm(x | \\mu, \\sigma_x^2) Norm(\\mu | \\mu_N, \\sigma_N^2) d\\mu\n",
    "\\\\\n",
    "& = \\int Norm(x - \\mu | 0, \\sigma_x^2) Norm(\\mu | \\mu_N, \\sigma_N^2) d\\mu\n",
    "\\\\\n",
    "& = Norm(x | \\mu_N, \\sigma_x^2 + \\sigma_N^2)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee48ba2",
   "metadata": {},
   "source": [
    "Прямого аналога $p$-значения похоже нет. \n",
    "В $\\sigma_D$ слагаемые $\\sigma_{N_A}^2, \\sigma_{N_B}^2$ убывают с ростом $N$.   \n",
    "Можно попытаться придумать критерий остановки.   \n",
    "Если $N$ достаточно велико, то $\\sigma_D$ сильно меняться не будет.    \n",
    "Поэтому $F_{A-B}(0)$ тоже близко окончательному.   \n",
    "Все равно же будет из-за новых точек.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa81a1",
   "metadata": {},
   "source": [
    "Другой вариант - не моделировать распределения. Моделировать $U$-распределение.\n",
    "\n",
    "В этом случае можно моделировать вероятность $\\theta = P(A > B)$. Сравнение каждой пары $X_{ij} = I(A_i > B_j)$ - точка. Сумма будет $U$-статистикой. Для правдоподобия можно выбрать биномиальное распределение $P(U | \\theta) = \\text{Binom}(U | \\theta, N_A N_B)$. Общее количество пар $N_A N_B$. Как в конверсиях априорное удобно задать бета-распределением. Апостериорное также будет бета-распределением.\n",
    "\n",
    "$$\n",
    "\\theta = P(A > B)\n",
    "\\\\\n",
    "X_{ij} = I(A_i > B_j)\n",
    "\\\\\n",
    "U = \\sum X_{ij}\n",
    "\\\\\n",
    "P(X | \\theta) = \\text{Bernoulli}(\\theta)\n",
    "\\\\\n",
    "P(U | \\theta) = \\text{Binom}(U | \\theta, N_A N_B)\n",
    "\\\\\n",
    "P(\\theta) = \\text{Beta}(\\alpha_0, \\beta_0)\n",
    "\\\\\n",
    "P(\\theta | U) = \\text{Beta}(U + \\alpha_0, N_A N_B - U + \\beta_0)\n",
    "\\approx \\text{Norm}(U/N_A N_B, t (1 - t) / N_A N_B)\n",
    "\\\\\n",
    "\\begin{split}\n",
    "P(A > B) = P(\\theta  > 0.5 | U) & = P(\\text{Norm}(x > 0.5; U/N_A N_B, s^2))\n",
    "\\\\\n",
    "& = 1/s^2 P(\\text{Norm}(x > 0.5; U/N_A N_B, 1))\n",
    "\\\\\n",
    "& = 1/s^2 P(\\text{Norm}(x > 0; U/N_A N_B - 0.5, 1))\n",
    "\\end{split}\n",
    "\\\\\n",
    "P(B > A) = 1 - P(\\theta  > 0.5 | U)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752eff9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff08bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "mu1, sigma1 = 0, 1\n",
    "mu2, sigma2 = -0.08, 1\n",
    "exactA = stats.norm(loc=mu1, scale=sigma1)\n",
    "exactB = stats.norm(loc=mu2, scale=sigma2)\n",
    "\n",
    "p_b_gt_a_norm = 1 - stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "\n",
    "\n",
    "#U (штуки)\n",
    "nA = nB = ntotal = 100000\n",
    "sampA = exactA.rvs(nA)\n",
    "sampB = exactB.rvs(nB)\n",
    "U, p = mannwhitneyu(sampA, sampB, alternative='less')\n",
    "eu = nA * nB / 2\n",
    "varu = nA * nB * (nA + nB + 1) / 12\n",
    "u0 = (U - eu) / np.sqrt(varu)\n",
    "p_b_gt_a_u = 1 - U / ntotal**2\n",
    "\n",
    "Ua = sum(np.sum(a > sampB) for a in sampA)\n",
    "print(f'Ua:{Ua}, U:{U}')\n",
    "\n",
    "\n",
    "#P(a>b)\n",
    "p_u = stats.norm(loc=eu/nA*nB, scale=np.sqrt(varu/nA**2 * nB**2))\n",
    "u0_p = U / ntotal**2\n",
    "print(f'p: {p}, cdf(u0): {stats.norm.cdf(u0)}, cdf(u0p): {p_u.cdf(u0_p)}')\n",
    "\n",
    "\n",
    "#elementwise\n",
    "a0 = 1\n",
    "b0 = 1\n",
    "Ua = np.sum(sampA > sampB)\n",
    "post_u_ewise = stats.beta(a0 + Ua, b0 + nA - Ua)\n",
    "\n",
    "\n",
    "# #independent\n",
    "# a0 = 1\n",
    "# b0 = 1\n",
    "# Ua = sum(np.sum(a > sampB) for a in sampA)\n",
    "# post_u = stats.beta(a0 + Ua, b0 + nA*nB - Ua)\n",
    "\n",
    "\n",
    "# #covariance\n",
    "# a0 = 1\n",
    "# b0 = 1\n",
    "# post_u_m = 0\n",
    "# post_u_var = 0\n",
    "# for a in sampA:\n",
    "#     Ua = np.sum(a > sampB)\n",
    "#     d = stats.beta(a0 + Ua, b0 + nB - Ua)\n",
    "#     post_u_m += d.mean()\n",
    "#     post_u_var += d.var()\n",
    "# post_u_m = post_u_m / nA \n",
    "# post_u_s = np.sqrt(post_u_var) / nA #1/na or sqrt(1/na) ?\n",
    "# post_u_ind = stats.norm(loc=post_u_m, scale=post_u_s)\n",
    "\n",
    "\n",
    "# #cov corr, total variance\n",
    "# a0 = 1\n",
    "# b0 = 1\n",
    "# post_u_m = []\n",
    "# post_u_var = []\n",
    "# for a in sampA:\n",
    "#     Ua = np.sum(a > sampB)\n",
    "#     d = stats.beta(a0 + Ua, b0 + nB - Ua)\n",
    "#     post_u_m.append(d.mean())\n",
    "#     post_u_var.append(d.var())\n",
    "# # post_u_tv_mean = np.mean(post_u_m) \n",
    "# # post_u_s = np.sqrt(np.mean(post_u_var) + np.var(post_u_m))\n",
    "# # print('total var:', np.mean(post_u_var), np.var(post_u_m))\n",
    "# # post_u_tv = stats.norm(loc=post_u_tv_mean, scale=post_u_s)\n",
    "# mean_of_vars = np.mean(post_u_var)\n",
    "# var_of_means = np.var(post_u_m)\n",
    "# total_post_var = (mean_of_vars + var_of_means) / nA\n",
    "# post_u_tv_mean = np.mean(post_u_m)\n",
    "# post_u_tv_std = np.sqrt(total_post_var)\n",
    "# post_u_tv = stats.norm(loc=post_u_tv_mean, scale=post_u_tv_std)\n",
    "\n",
    "\n",
    "#GM\n",
    "# a0 = 1\n",
    "# b0 = 1\n",
    "# post_mix = []\n",
    "# for a in sampA:\n",
    "#     Ua = np.sum(a > sampB)\n",
    "#     post_mix.append(stats.beta(a0 + Ua, b0 + nB - Ua))\n",
    "# post_mix_pdf = lambda x: sum(d.pdf(x) for d in post_mix)/nA\n",
    "# print('post_mix_mean:', sum(d.mean() for d in post_mix)/nA)\n",
    "\n",
    "\n",
    "#GM\n",
    "a0 = 1\n",
    "b0 = 1\n",
    "post_a = []\n",
    "post_b = []\n",
    "for a in sampA:\n",
    "    Ua = np.sum(a > sampB)\n",
    "    post_a.append(a0 + Ua)\n",
    "    post_b.append(b0 + nB - Ua)\n",
    "post_mix_pdf = lambda x: sum(stats.beta.pdf(x, a, b) for a, b in zip(post_a, post_b))/nA\n",
    "print('post_mix_mean:', sum(stats.beta.mean(a, b) for a, b in zip(post_a, post_b))/nA/nA)\n",
    "\n",
    "# #post predictive\n",
    "# alpha_beta_sum = (post_u_ind.mean() * (1 - post_u_ind.mean())) / post_u_ind.std()**2 - 1\n",
    "# alpha = post_u_ind.mean() * alpha_beta_sum\n",
    "# beta = (1 - post_u_ind.mean()) * alpha_beta_sum\n",
    "# mean_bb = ntotal**2 * post_u_ind.mean()\n",
    "# var_bb = ntotal**2 * post_u_ind.mean() * (1 - post_u_ind.mean()) * ( (ntotal**2 + alpha + beta) / (1 + alpha + beta) )\n",
    "# post_pred_ind = stats.norm(loc=mean_bb, scale=np.sqrt(var_bb))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = np.linspace(-7, 7, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactA.pdf(x),\n",
    "    mode='lines', name='A'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactB.pdf(x),\n",
    "    mode='lines', name='B'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"A, B\",\n",
    "    template=\"plotly_white\",\n",
    "    #yaxis_range=[0,1.1]\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "xaxis_min = 0.3\n",
    "xaxis_max = 0.7\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=1), \n",
    "#                          line_color='black', opacity=0.8, name=f'$Norm(0, 1)$'))\n",
    "# fig.add_trace(go.Scatter(x=[u0, u0], y=[0, max(stats.norm.pdf(x, loc=0, scale=1))*1.1], \n",
    "#                          line_color='black', \n",
    "#                          mode='lines+text', text=['', '$u_0$'], textposition=\"top center\",\n",
    "#                          line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x, y=p_u.pdf(x), \n",
    "                         line_color='black', opacity=0.8, name=f'$U/na nb$'))\n",
    "fig.add_trace(go.Scatter(x=[u0_p, u0_p], y=[0, max(p_u.pdf(x))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$u_0$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x<u0_p], y=p_u.pdf(x[x<u0_p]), \n",
    "                         line_color='black', opacity=0.8, name='$P(x < u_0)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=post_u_ewise.mean(), scale=post_u_ewise.std()),\n",
    "                         line_color='red', opacity=0.3, name=f'PostUElementwise'))\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x,loc=post_u.mean(), scale=post_u.std()),\n",
    "#                          line_color='red', opacity=0.8, name=f'$PostU$'))\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=post_u_ind.mean(), scale=post_u_ind.std()),\n",
    "#                          line_color='green', opacity=0.3, name=f'$PostUInd$'))\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=post_u_ind.mean(), scale=post_u_ind.std()*np.sqrt(ntotal)),\n",
    "#                          line_color='blue', opacity=0.3, name=f'$PostUIndCorrected$'))\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=post_u_tv.mean(), scale=post_u_tv.std()),\n",
    "#                          line_color='green', opacity=0.3, name=f'$PostUTV$'))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_mix_pdf(x),\n",
    "                         line_color='purple', opacity=0.3, name=f'$PostGMM$'))\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x,loc=(post_pred_ind.mean() - 0.5)/post_pred_ind.std(), scale=1),\n",
    "#                          line_color='blue', opacity=0.3, name=f'$PostPredInd$'))\n",
    "fig.update_layout(\n",
    "    title='U',\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# xaxis_min = 0.3\n",
    "# xaxis_max = 0.7\n",
    "# x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "# fig = go.Figure()\n",
    "# # fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=1), \n",
    "# #                          line_color='black', opacity=0.8, name=f'$Norm(0, 1)$'))\n",
    "# # fig.add_trace(go.Scatter(x=[u0, u0], y=[0, max(stats.norm.pdf(x, loc=0, scale=s))*1.1], \n",
    "# #                          line_color='black', \n",
    "# #                          mode='lines+text', text=['', '$u_0$'], textposition=\"top center\",\n",
    "# #                          line_dash='dash', showlegend=False))\n",
    "# # fig.add_trace(go.Scatter(x=x[x>u0], y=stats.norm.pdf(x[x>u0], loc=0, scale=s), \n",
    "# #                          line_color='black', opacity=0.8, name='$P(x > u_0)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "# # fig.add_trace(go.Scatter(x=x, y=post_u.pdf(x), \n",
    "# #                          line_color='red', opacity=0.8, name=f'$PostU$'))\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x,loc=post_u.mean(), scale=post_u.std()),\n",
    "#                          line_color='red', opacity=0.8, name=f'$PostU$'))\n",
    "# fig.add_trace(go.Scatter(x=x, y=post_u_ind.pdf(x),\n",
    "#                          line_color='green', opacity=0.8, name=f'$PostU Ind$'))\n",
    "# fig.update_layout(\n",
    "#     title='U',\n",
    "#     template=\"plotly_white\"\n",
    "# )\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# xaxis_min = eu - np.sqrt(varu) * 7\n",
    "# xaxis_max = eu + np.sqrt(varu) * 7\n",
    "# x = np.linspace(xaxis_min, xaxis_max, 5000)\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x,loc=eu, scale=np.sqrt(varu)),\n",
    "#                          line_color='red', opacity=0.8, name=f'$U$'))\n",
    "# fig.add_trace(go.Scatter(x=[U, U], y=[0, max(stats.norm.pdf(x,loc=eu, scale=np.sqrt(varu)))*1.1], \n",
    "#                          line_color='black', \n",
    "#                          mode='lines+text', text=['', '$u_0$'], textposition=\"top center\",\n",
    "#                          line_dash='dash', showlegend=False))\n",
    "# fig.add_trace(go.Scatter(x=x, y=post_pred_ind.pdf(x),\n",
    "#                         line_color='green', opacity=0.8, name=f'$PostPred$'))\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=post_pred_ind.mean(), scale=post_pred_ind.std()*np.sqrt(ntotal)),\n",
    "#                         line_color='blue', opacity=0.8, name=f'$PostPredCorrected$'))\n",
    "# fig.update_layout(\n",
    "#     title='U',\n",
    "#     template=\"plotly_white\"\n",
    "# )\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "print(f'pval: {stats.norm.cdf(u0)}')\n",
    "print(f'scipy pval: {p}')\n",
    "print(f'Bayes pval equiv P(A>B) {1 - stats.norm.cdf(0,loc=(post_u_ind.mean() - 0.5)/post_u_ind.std(), scale=1)}')\n",
    "print(f'Bayes pval post pred P(A>B) {1 - stats.norm.cdf(0,loc=(post_pred_ind.mean() - 0.5)/post_pred_ind.std(), scale=1)}')\n",
    "print()\n",
    "print(f'P(B>A) exact: {p_b_gt_a_norm}')\n",
    "print(f'P(B>A) U: {p_b_gt_a_u}')\n",
    "print(f'Bayes P(B>A) {1 - post_u_ind.mean()}')\n",
    "print()\n",
    "print(f'Var U: {varu}, PostU: {post_u.std()**2}, PostUInd: {post_u_ind.std()**2}')\n",
    "print(f'E[u]/Std[U]: {eu / np.sqrt(varu)}, PostU: {post_u.mean() / post_u.std()}, PostUInd: {post_u_ind.mean() / post_u_ind.std()}')\n",
    "print(f'E[u]/Std[U]: {eu / np.sqrt(varu)}, PostU: {post_u.mean() / post_u.std()}, PostUInd: {post_u_ind.mean() / post_u_ind.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "mu1, sigma1 = 0, 1\n",
    "mu2, sigma2 = -0.08, 1\n",
    "exactA = stats.norm(loc=mu1, scale=sigma1)\n",
    "exactB = stats.norm(loc=mu2, scale=sigma2)\n",
    "\n",
    "p_b_gt_a_norm = 1 - stats.norm.cdf(0, loc=mu2-mu1, scale=np.sqrt(sigma1**2 + sigma2**2))\n",
    "\n",
    "ntotal = 1000\n",
    "sampA = exactA.rvs(ntotal)\n",
    "sampB = exactB.rvs(ntotal)\n",
    "U, p = mannwhitneyu(sampA, sampB, alternative='less')\n",
    "eu = ntotal * ntotal / 2\n",
    "varu = ntotal * ntotal * (ntotal + ntotal + 1) / 12\n",
    "u0 = (U - eu) / np.sqrt(varu)\n",
    "p_b_gt_a_u = 1 - U / ntotal**2\n",
    "\n",
    "x = np.linspace(-7, 7, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactA.pdf(x),\n",
    "    mode='lines', name='A'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=exactB.pdf(x),\n",
    "    mode='lines', name='B'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"A, B\",\n",
    "    template=\"plotly_white\",\n",
    "    #yaxis_range=[0,1.1]\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "xaxis_min = -7\n",
    "xaxis_max = 7\n",
    "x = np.linspace(xaxis_min, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=0, scale=1), \n",
    "                         line_color='black', opacity=0.8, name=f'$Norm(0, 1)$'))\n",
    "fig.add_trace(go.Scatter(x=[u0, u0], y=[0, max(stats.norm.pdf(x, loc=0, scale=1))*1.1], \n",
    "                         line_color='black', \n",
    "                         mode='lines+text', text=['', '$u_0$'], textposition=\"top center\",\n",
    "                         line_dash='dash', showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=x[x>u0], y=stats.norm.pdf(x[x>u0], loc=0, scale=1), \n",
    "                         line_color='black', opacity=0.8, name='$P(x > u_0)$', fill=\"tozeroy\", fillcolor=\"rgba(0, 0, 0, 0.7)\"))\n",
    "fig.update_layout(\n",
    "    title='U',\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(f'pval: {stats.norm.cdf(u0)}')\n",
    "print(f'scipy pval: {p}')\n",
    "\n",
    "print(f'P(B>A) exact: {p_b_gt_a_norm}')\n",
    "print(f'P(B>A) U: {p_b_gt_a_u}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e6f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ae93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6674ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c46af69",
   "metadata": {},
   "source": [
    "Важна формулировка гипотезы. В качестве нулевой гипотезы $H_0$ часто предполагают равенство групп (нулевой эффект). В А/Б-тестах нужно проверить не равенство групп, а выбрать группу с большим значением целевой метрики. Поэтому вместо гипотез вида $H_0: p_A = p_B$ нужны $H: p_A > p_B$.\n",
    "\n",
    "В общем случае использовать $p$-значение для оценки гипотез некорректно. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1929a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "015cd718",
   "metadata": {},
   "source": [
    "В распространных применениях проверок нулевых гипотез к А/Б-тестам $p$-значение оказывается численно близко вероятности метрик одной группы больше другой. Ниже рассмотрены $t$-теста, $\\chi^2$-теста для двух пропорций и $U$-критерия Манна-Уитни."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1157cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fc37b5c",
   "metadata": {},
   "source": [
    "В проверках нулевых гипотез используют статистическую значимость $\\alpha$ и мощность $1-\\beta$. Они определяют вероятность P(Выбор !H0 \\cap H0) и P(Выбор H0 \\cap !H0). Их также называют ошибками первого и второго рода. Задание $\\alpha$ и $\\beta$ не достаточно для задания вероятности корректного определения гипотезы. Она также зависит от качества гипотезы $P(H_0)$. Также полезно подумать о дальнейших действиях: в А/Б - тесте оставляют вариант со значимой разницей. Т.е. нужно оставлять P(выбор !H0 \\cap H0) + P(выбор !H0 \\cap !H0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_ttest_conv_pval(sa, na, sb, nb):\n",
    "    pa = sa / na\n",
    "    pb = sb / nb\n",
    "    stderr_a = np.sqrt(pa * (1 - pa) / na)\n",
    "    stderr_b = np.sqrt(pb * (1 - pb) / nb)\n",
    "    diff = pb - pa\n",
    "    diff_stderr = np.sqrt(stderr_a**2 + stderr_b**2)\n",
    "    pval = stats.norm.cdf(0, diff, diff_stderr)\n",
    "    return pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0d80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e400f19e",
   "metadata": {},
   "source": [
    "Основная проблема метода - решение принимается по $p$-значению $p = P_{T}(x \\ge x_{0} | H_0)$, тогда как для оценки гипотезы нужна вероятность $P(H_0 | x_0)$. Ее можно получить по соотношению Байеса $P(H_0 | x_0) \\propto P_{T}(x = x_{0} | H_0) P(H_0)$. Т.е. посчитать вероятности получить данные в рамках конкурирующих гипотез и сравнить друг с другом с учетом априорных вероятностей. В общем случае $p$-значение не позволяет делать корректных выводов о рассматриваемой гипотезе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae5860",
   "metadata": {},
   "source": [
    "Если приходится иметь дело с проверками нулевых гипотез, важно обращать внимание на формулировку гипотезы. В качестве $H_0$ часто предполагают равенство групп (нулевой эффект). В А/Б-тестах нужно проверить не равенство групп, а выбрать группу с большим значением целевой метрики. Поэтому вместо гипотез вида $H_0: p_A = p_B$ нужны $H: p_A > p_B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866745b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8f5dc16",
   "metadata": {},
   "source": [
    "Для анализа А/Б-тестов используют метод проверки статистических гипотез [[StTest](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing)]. Чаще всего в таком подходе предполагают, что между вариантами нет разницы, после чего смотрят, насколько такое предположение объясняет экспериментальные данные. Если вероятность получить данные мала, считают, что предположение можно отвергнуть и между группами есть значимая разница.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634b22f1",
   "metadata": {},
   "source": [
    "Есть экспериментальные данные $\\mathcal{D}$ и гипотеза $H_0$ о данных. Выбирают «статистический тест» $T$ - случайную величину с известным распределением $P_{T}(x | H_0)$ в предположении $H_0$. По данным считают «тестовую статистику»  $x_{0}$ [[TestStat](https://en.wikipedia.org/wiki/Test_statistic)]. Вероятность получить «фактическое или более экстремальное» значение тестовой статистики называют «$p$-значением» [[PVal](https://en.wikipedia.org/wiki/P-value)]. В зависимости от контекста $p = P_{T}(x \\ge x_{0} | H_0)$, $p = P_{T}(x \\le x_{0} | H_0)$ или $p = P_{T}(|x - x_{0}| \\ge 0 | H_0)$ [[TailedTests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests)]. Если вероятность «достаточно мала», гипотезу $H_0$ «отвергают», если нет - «не отвергают»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a47e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080967d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d5fc315",
   "metadata": {},
   "source": [
    "Для сравнения конверсий могут применять $\\chi^2$-тест [[Chi2Test](https://en.wikipedia.org/wiki/Chi-squared_test)]. Статистика $\\chi^2$ Пирсона [[Chi2Pearson](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)] для мультиномиальных распределений $\\chi^2 = \\sum_{i=1}^k (S_i - Np_i)^2/(Np_i)$, где $N$ - общее количество наблюдений, $S_i$ - фактическое количество наблюдений $i$-категории,  $N p_i$ - ожидаемое при доле $i$-категории $p_i$. Для биномиального распределения\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\chi^2 & = \n",
    "\\frac{(S - N p)^2}{N p}\n",
    "+\n",
    "\\frac{((N - S) - N (1-p))^2}{N (1-p)}\n",
    "\\\\\n",
    "& = \n",
    "\\frac{(S - N p)^2}{N p}\n",
    "+\n",
    "\\frac{(S - Np)^2}{N (1-p)}\n",
    "\\\\\n",
    "& =\n",
    "\\frac{(S - Np)^2}{N p (1-p)}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "По теореме центральной предельной теореме $(S - Np)/\\sqrt{N p (1-p)}$ стремится к стандартному нормальному распределению. Распределение $\\chi^2$ возникает при суммировании квадратов нормальных случайных величин $\\chi^2_k = \\sum_{i=1}^{k} X_i^2,\\, X_i \\sim \\text{Norm}(0,1)$ [[Chi2Dist](https://en.wikipedia.org/wiki/Chi-squared_distribution)]. Поэтому $\\chi^2$-статистика стремится к $\\chi^2$-распределению с 1 степенью свободы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5a6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5f880aa",
   "metadata": {},
   "source": [
    "Для А/Б-теста конверсий с двумя группами в предположении $p_A = p_B = p$\n",
    "\n",
    "$$\n",
    "p = \\frac{S_A + S_B}{N_A + N_B}\n",
    "\\\\\n",
    "\\chi^2 = \\frac{(S_A - N_A p)^2}{N_A p (1-p)} + \\frac{(S_B - N_B p)^2}{N_B p (1-p)},\n",
    "\\\\\n",
    "=\n",
    "\\frac{N_A (p_A - p)^2 + N_B (p_B - p)^2}{p (1-p)}\n",
    "\\\\\n",
    "p_A - p = \\frac{S_A}{N_A} - \\frac{S_A + S_B}{N_A + N_B} = \\frac{S_A N_B - S_B N_A}{N_A (N_A + N_B)}\n",
    " = \\frac{N_B}{(N_A + N_B)}(p_A - p_B)\n",
    "\\\\\n",
    "p_B - p = \\frac{N_A}{(N_A + N_B)}(p_B - p_A)\n",
    "\\\\\n",
    "\\chi^2 = \\frac{N_A N_B^2 (p_A - p_B)^2 + N_B N_A^2 (p_A - p_B)^2}{(N_A + N_B)^2 p (1-p)}\n",
    "\\\\\n",
    "=\n",
    "\\frac{N_A N_B (p_A - p_B)^2}{(N_A + N_B) p (1-p)}\n",
    "\\\\\n",
    "\\frac{N_A N_B}{(N_A + N_B)} = \\frac{1}{N_A} + \\frac{1}{N_B}\n",
    "\\\\\n",
    "\\chi^2 = \\frac{(p_A - p_B)^2}{p (1-p) / N_A + p (1-p) / N_B} \n",
    "=\n",
    "\\frac{(p_A - p_B)^2}{s^2 / N_A + s^2 / N_B}\n",
    "$$\n",
    "В $t$-тесте считалось\n",
    "$$\n",
    "x_0 = \\frac{\\mu_{\\Delta}}{s_{\\Delta}},\n",
    "\\quad\n",
    "\\mu_{\\Delta} = \\mu_B - \\mu_A,\n",
    "\\quad\n",
    "s^2_{\\Delta} = \\frac{s_A^2}{N_A} + \\frac{s_B^2}{N_B}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f3825d",
   "metadata": {},
   "source": [
    "Данные представляют в таблице вида\n",
    "\n",
    "|            | Сконвертировались | Не сконвертировались    | Всего       |\n",
    "|------------|-------------------|-------------------------|-------------|\n",
    "| A          | $S_A$             | $N_A - S_A$             | $N_A$       |\n",
    "| B          | $S_B$             | $N_B - S_B$             | $N_B$       |\n",
    "| Всего      | $S_A + S_B$       | $N_A + N_B - S_A - S_B$ | N_A + N_B |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55050b30",
   "metadata": {},
   "source": [
    "Данные представляют в таблице вида\n",
    "\n",
    "|            | Сконвертировались | Не сконвертировались    |\n",
    "|------------|-------------------|-------------------------|\n",
    "| A          | $S_A$             | $N_A - S_A$             |\n",
    "| B          | $S_B$             | $N_B - S_B$             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed696f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "374f6559",
   "metadata": {},
   "source": [
    "|            | Converted | Not Converted | Total |\n",
    "|------------|-----------|---------------|-------|\n",
    "| Group A    | x_A       | n_A - x_A     | n_A   |\n",
    "| Group B    | x_B       | n_B - x_B     | n_B   |\n",
    "| Total      | x_A + x_B | n_A + n_B - x_A - x_B | n_A + n_B |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0aacff",
   "metadata": {},
   "source": [
    "Статистика $\\chi^2$ Пирсона [[Chi2Pearson](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)] вычисляется для мультиномиальных распределений $\\chi^2 = \\sum_{i=1}^k (O_i - E_i)^2/E_i$, где $O_i$ - фактическое количество наблюдений $i$-категории, $E_i = N p_i$ - ожидаемое при доле $i$-категории $p_i$, $N$ - общее количество наблюдений. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad30ce",
   "metadata": {},
   "source": [
    "$$\n",
    "X \\sim \\text{Binomial}(n,p), \\quad O = x, \\quad E = np\n",
    "\\\\\n",
    "\\chi^2\n",
    "=\n",
    "\\frac{(x - np)^2}{np}\n",
    "+\n",
    "\\frac{((n - x) - n(1-p))^2}{n(1-p)}\n",
    "=\n",
    "\\frac{(x - np)^2}{np(1-p)}\n",
    "\\\\\n",
    "Z = \\frac{x - np}{\\sqrt{np(1-p)}}, \\quad \\chi^2 = Z^2, \\quad \\chi^2 \\sim \\chi^2_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f30f9f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Group A: } S_A \\sim \\mathrm{Binomial}(N_A, p_A), \\quad\n",
    "\\text{Group B: } S_B \\sim \\mathrm{Binomial}(N_B, p_B)\n",
    "\\\\\n",
    "\\hat p_A = \\frac{S_A}{N_A}, \\qquad\n",
    "\\hat p_B = \\frac{S_B}{N_B}\n",
    "\\\\\n",
    "H_0: p_A = p_B\n",
    "\\\\\n",
    "\\hat p = \\frac{S_A + S_B}{N_A + N_B}\n",
    "\\\\\n",
    "\\chi^2\n",
    "=\n",
    "\\frac{(\\hat p_A - \\hat p_B)^2}\n",
    "{\\hat p(1-\\hat p)\\left(\\frac{1}{N_A} + \\frac{1}{N_B}\\right)}\n",
    "\\\\\n",
    "\\chi^2 \\xrightarrow{d} \\chi^2_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a25300",
   "metadata": {},
   "source": [
    "$$\n",
    "\\chi^2\n",
    "=\n",
    "\\sum_{i=1}^k\n",
    "\\frac{(O_i - E_i)^2}{E_i}\n",
    "\\\\\n",
    "\\chi^2\n",
    "=\n",
    "\\frac{(S_A - N_A \\hat p)^2}{N_A \\hat p}\n",
    "+\n",
    "\\frac{((N_A - S_A) - N_A(1-\\hat p))^2}{N_A(1-\\hat p)}\n",
    "+\n",
    "\\frac{(S_B - N_B \\hat p)^2}{N_B \\hat p}\n",
    "+\n",
    "\\frac{((N_B - S_B) - N_B(1-\\hat p))^2}{N_B(1-\\hat p)}\n",
    "\\\\\n",
    "\\hat p = \\frac{S_A + S_B}{N_A + N_B}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29fe68",
   "metadata": {},
   "source": [
    "$$\n",
    "\\chi^2\n",
    "=\n",
    "\\frac{(S_A - N_A \\hat p)^2}{N_A \\hat p}\n",
    "+\n",
    "\\frac{((N_A - S_A) - N_A(1-\\hat p))^2}{N_A(1-\\hat p)}\n",
    "+\n",
    "\\frac{(S_B - N_B \\hat p)^2}{N_B \\hat p}\n",
    "+\n",
    "\\frac{((N_B - S_B) - N_B(1-\\hat p))^2}{N_B(1-\\hat p)}\n",
    "= \\frac{(S_A - N_A \\hat p)^2}{N_A \\hat p(1-\\hat p)}\n",
    "  + \\frac{(S_B - N_B \\hat p)^2}{N_B \\hat p(1-\\hat p)}\n",
    "= \\frac{1}{\\hat p(1-\\hat p)}\n",
    "  \\left[\n",
    "    \\frac{(S_A - N_A \\hat p)^2}{N_A}\n",
    "    + \\frac{(S_B - N_B \\hat p)^2}{N_B}\n",
    "  \\right]\n",
    "= \\frac{1}{\\hat p(1-\\hat p)}\n",
    "  \\left[\n",
    "    N_A(\\hat p_A - \\hat p)^2\n",
    "    + N_B(\\hat p_B - \\hat p)^2\n",
    "  \\right]\n",
    "= \\frac{(\\hat p_A - \\hat p_B)^2}\n",
    "       {\\hat p(1-\\hat p)\\left(\\frac{1}{N_A} + \\frac{1}{N_B}\\right)}\n",
    "\\\\\n",
    "\\hat p_A = \\frac{S_A}{N_A}, \\quad\n",
    "\\hat p_B = \\frac{S_B}{N_B}, \\quad\n",
    "\\hat p = \\frac{S_A + S_B}{N_A + N_B}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ee6e9",
   "metadata": {},
   "source": [
    "Для конверсий 2 групп эквивалентен расчету разности средних.  \n",
    "В итоге $p$-значение близко вероятности одной группы больше другой.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01240b3",
   "metadata": {},
   "source": [
    "$$\n",
    "% Step 0: Setup\n",
    "% Two groups, A and B\n",
    "S_A, S_B = observed successes\n",
    "N_A, N_B = total trials\n",
    "\\hat p_A = S_A / N_A, \\quad \\hat p_B = S_B / N_B\n",
    "\\hat p = (S_A + S_B) / (N_A + N_B)  % pooled proportion\n",
    "\\\\\n",
    "% Step 1: Pearson chi-square as sum of (O - E)^2 / E\n",
    "\\chi^2\n",
    "=\n",
    "\\frac{(S_A - N_A \\hat p)^2}{N_A \\hat p}\n",
    "+\n",
    "\\frac{((N_A - S_A) - N_A (1-\\hat p))^2}{N_A (1-\\hat p)}\n",
    "+\n",
    "\\frac{(S_B - N_B \\hat p)^2}{N_B \\hat p}\n",
    "+\n",
    "\\frac{((N_B - S_B) - N_B (1-\\hat p))^2}{N_B (1-\\hat p)}\n",
    "\\\\\n",
    "% Step 2: Simplify each group\n",
    "% (S_A - N_A \\hat p)^2 / (N_A \\hat p) + ((N_A - S_A) - N_A (1-\\hat p))^2 / (N_A (1-\\hat p))\n",
    "= (S_A - N_A \\hat p)^2 / (N_A \\hat p (1-\\hat p))\n",
    "\\\\\n",
    "% Similarly for group B\n",
    "= (S_B - N_B \\hat p)^2 / (N_B \\hat p (1-\\hat p))\n",
    "\\\\\n",
    "% Step 3: Factor out 1 / (\\hat p (1-\\hat p))\n",
    "\\chi^2\n",
    "= \\frac{1}{\\hat p (1-\\hat p)} \\left[ \\frac{(S_A - N_A \\hat p)^2}{N_A} + \\frac{(S_B - N_B \\hat p)^2}{N_B} \\right]\n",
    "\\\\\n",
    "% Step 4: Express in terms of sample proportions\n",
    "(S_A - N_A \\hat p) = N_A (\\hat p_A - \\hat p), \\quad\n",
    "(S_B - N_B \\hat p) = N_B (\\hat p_B - \\hat p)\n",
    "\\\\\n",
    "\\chi^2\n",
    "= \\frac{N_A (\\hat p_A - \\hat p)^2 + N_B (\\hat p_B - \\hat p)^2}{\\hat p (1-\\hat p)}\n",
    "\\\\\n",
    "% Step 5: Express in terms of difference in proportions\n",
    "\\hat p_A - \\hat p = \\frac{N_B}{N_A + N_B} (\\hat p_A - \\hat p_B), \\quad\n",
    "\\hat p_B - \\hat p = - \\frac{N_A}{N_A + N_B} (\\hat p_A - \\hat p_B)\n",
    "\\\\\n",
    "% Substitute into numerator\n",
    "N_A (\\hat p_A - \\hat p)^2 + N_B (\\hat p_B - \\hat p)^2\n",
    "= \\frac{N_A N_B}{N_A + N_B} (\\hat p_A - \\hat p_B)^2\n",
    "\\\\\n",
    "% Step 6: Final simplified chi-square\n",
    "\\chi^2\n",
    "= \\frac{(\\hat p_A - \\hat p_B)^2}{\\hat p (1-\\hat p) \\left( \\frac{1}{N_A} + \\frac{1}{N_B} \\right)}\n",
    "\\\\\n",
    "% This shows the equivalence to the \"pooled difference squared over variance\" form.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1b6b4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\chi^2 = \\frac{(S_A - N_A p)^2}{N_A p (1-p)} + \\frac{(S_B - N_B p)^2}{N_B p (1-p)} =\n",
    "\\frac{N_A N_B (p_A - p_B)^2}{(N_A + N_B) p (1-p)}\n",
    "=\n",
    "\\frac{(p_A - p_B)^2}{s^2 / N_A + s^2 / N_B}\n",
    "\\\\\n",
    "p_A = \\frac{S_A}{N_A}, \\quad \n",
    "p_B = \\frac{S_B}{N_B}, \\quad \n",
    "p = \\frac{S_A + S_B}{N_A + N_B},\n",
    "\\quad\n",
    "s^2 = p (1 - p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5d27b",
   "metadata": {},
   "source": [
    "# Нулевые гипотезы, статистические тесты, $p$-значения"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
