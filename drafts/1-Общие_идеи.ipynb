{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Байесовский подход к оценке А/Б тестов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*При проведении А/Б-тестов в мобильных приложениях и веб-сервисах требуется ответить на вопросы \"Какой вариант лучше и насколько?\", \"Каковы оценки целевой метрики в каждом варианте?\", \"Насколько уверены в оценке?\", \"Сколько должен продолжаться эксперимент?\".\n",
    "На примере двух случайных процессов с бинарными исходами показано, как в рамках байесовского подхода ответить на вопросы выше и выбрать процесс с большей вероятностью успеха.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Содержание:**\n",
    "* [Введение](#Введение)  \n",
    "* [Общая идея байесовского подхода](#Общая-идея-байесовского-подхода)\n",
    "* [Оценка вероятности в эксперименте с двумя исходами](#Оценка-вероятности-в-эксперименте-с-двумя-исходами)\n",
    "* &nbsp; &nbsp; [Аналитический расчет апостериорного распределения](#Аналитический-расчет-апостериорного-распределения)\n",
    "* [Сравнение конверсий в А/Б тесте](#Сравнение-конверсий-в-А/Б-тесте)\n",
    "* &nbsp; &nbsp; [Оценка величины параметра в группах и область наиболее вероятных значений](#Оценка-величины-параметра-в-группах-и-область-наиболее-вероятных-значений)\n",
    "* &nbsp; &nbsp; [Какая группа лучше и насколько?](#Какая-группа-лучше-и-насколько?)\n",
    "* &nbsp; &nbsp; [Зависимость точности оценки параметров от размера выборки](#Зависимость-точности-оценки-параметров-от-размера-выборки)\n",
    "* &nbsp; &nbsp; [Сколько должен продолжаться эксперимент?](#Сколько-должен-продолжаться-эксперимент?)\n",
    "* [Дополнение: динамика по дням](#Дополнение:-динамика-по-дням)\n",
    "* [Приложение: сопряженное априорное распределение к биномиальному](#Приложение:-сопряженное-априорное-распределение-к-биномиальному)\n",
    "* [Заключение](#Заключение)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dJJnGsHhb1o"
   },
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1WPbT1s1Ylr"
   },
   "source": [
    "При развитии мобильных приложений и веб-сервисов часто возникает идея внести в них те или иные изменения. Ожидается, что это улучшит ключевые метрики сервиса - финансовые, аудиторные, конверсии, вовлеченность и др. Возможный пример - изменение цен или тарифной линейки. Хотя при повышении цен конверсия в покупку скорее всего снизится, итоговая прибыль может вырасти.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../figs/experiment_versions.png\" alt=\"experiment_versions\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точный эффект от изменений непредсказуем. Более того, может оказаться, что функциональность ухудшает продукт. По оценкам, только около трети реализованных изменений приводят к положительным результатам [[MicroExp](https://www.microsoft.com/en-us/research/publication/online-experimentation-at-microsoft/)]. Поэтому необходимо измерять эффект от новой функциональности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После запуска эффект не всегда может быть виден сразу (см. график ниже). Если функциональность не вызвала резких изменений, ее влияние может быть незаметно на фоне случайных колебаний метрик. Кроме того, могут произойти изменения в других частях продукта, привлекаемом трафике или общей активности аудитории, которые также повлияют на целевую метрику. Например, запуск рекламной акции. Поэтому изменения метрик после релиза не всегда можно объяснять именно новой функциональностью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике ниже показаны варианты влияния изменений на некую условную конверсию.  \n",
    "Original - исходный вариант, Original + 10% - улучшение на 10%, но на глаз эффект не ясен, \n",
    "Original - 50% - заметное ухудшение.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../figs/feature_effects.png\" alt=\"feature_effects\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из способов оценки новой функциональности является проведение А/Б-теста.\n",
    "В этом подходе запускают версию без изменений и измененные варианты сервиса параллельно, распределяют пользователей между этими вариантами и сравнивают интересующие метрики. Параллельный запуск версий позволяет снизить различия из-за факторов, не связанных с тестируемыми изменениями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В проведении АБ-тестов есть много нюансов [[TrustworthyAB]((https://www.amazon.com/gp/product/B0845Y3DJV)].\n",
    "Но общая схема примерно следующая (см. рисунок). При попадании на сайт или в приложение пользователь случайным образом определяется в одну из экспериментальных групп. В каждой группе собираются данные и вычисляются интересующие метрики.\n",
    "Полученные значения сравниваются между собой. Эксперимент прекращается, если становится понятно, что одна из групп лидирует (иногда - при прохождении определенного количества пользователей, по истечении определенного времени или нецелесообразности дальнейшего проведения). Принимается решение о дальнейших действиях - как правило, о выборе одного из вариантов для всех пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_tests](../figs/ab_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y82Z6D3FnZ5B"
   },
   "source": [
    "В результате эксперимента нужно получить ответ на несколько вопросов, чтобы определиться с дальнейшими решениями по тестируемой функциональности. \n",
    "\n",
    "В конечном счете нужно сказать, какая группа лучше и насколько.       \n",
    "Для этого понадобится посчитать оценки целевой метрики в каждой группе.  \n",
    "\n",
    "Значения метрик нужны для сравнения с ценой поддержки.  \n",
    "Также может понадобиться оценить различие между вариантами, которое накопится, например, за год.\n",
    "\n",
    "При сравнении вариантов остается неопределенность.\n",
    "Поэтому добавляется вопрос \"насколько уверены в оценке\"?\n",
    "\n",
    "Как правило по мере увеличения количества данных - т.е. по мере роста количества пользователей, принявших участие в эксперименте - неопределенность в оценках снижается. Поэтому еще один вопрос - сколько должен продолжаться эксперимент, чтобы можно было выбрать один из вариантов с определенной степенью уверенности?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 20px\">  \n",
    "\n",
    "Основные вопросы при А/Б-тестировании:\n",
    "\n",
    "<ul>\n",
    "<li>Каковы оценки целевой метрики в каждом варианте?</li> \n",
    "<li>Какой вариант лучше? Насколько лучше?</li>\n",
    "<li>Насколько уверены в оценке?</li>\n",
    "<li>Сколько должен продолжаться эксперимент?</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, в имеющейся выборке среднее значение метрики в группе A равно a_mean, а в группе B - b_mean. При выборе варианта A для всех пользователей среднее значение метрики с вероятностью 90% будет находится в диапазоне (a_min, a_max), при выборе варианта B - с вероятностью 90% в диапазоне (b_min, b_max). По имеющимся данным группа B окажется лучше группы A с вероятностью 70%. Ожидаемое значение B/A = 1.05. Чтобы говорить о p(B) > p(A) с уверенностью 90% нужно еще около N пользователей, что займет d дней.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятность здесь и далее понимается в субъективном смысле - как мера уверенности в том или ином исходе процесса с несколькими возможными исходами [[SubjProb](https://en.wikipedia.org/wiki/Probability_interpretations#Subjectivism), [UU](https://www.amazon.co.uk/Understanding-Uncertainty-Wiley-Probability-Statistics-ebook/dp/B00GYVM33Q)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHd80oGGIzvr"
   },
   "source": [
    "Существуют различные подходы к оценке А/Б-тестов. Один из наиболее популярных - аппарат проверки статистических гипотез. \n",
    "Общая идея - предположить, что разницы между вариантами нет и проверить, насколько такое предположение объясняет фактически полученные данные.\n",
    "Обсуждение особенностей этого и других методов - отдельная тема. \n",
    "Ниже речь пойдет только о байесовском подходе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Содержание следующее:\n",
    "- кратко обсуждены основные идеи байесовского подхода\n",
    "- на примере случайного процесса с двумя возможными исходами проводится построение модели процесса и оценка параметров модели\n",
    "- на примере двух случайных процессов обсуждается сравнение моделей и способ ответа на вопросы для А/Б-теста\n",
    "\n",
    "В дополнениях обсуждаются вспомогательные вопросы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-j8V2H-K8aj"
   },
   "source": [
    "# Общая идея байесовского подхода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В байесовском подходе [[SGBS](https://www.amazon.co.uk/Students-Guide-Bayesian-Statistics/dp/1473916364), [SR](https://www.amazon.co.uk/Statistical-Rethinking-Bayesian-Examples-Chapman/dp/036713991X/ref=sr_1_1)] строят математическую модель, объясняющую фактические данные.   \n",
    "Далее проводится сравнение моделей.  \n",
    "Это более общая задача, чем сравнение распределений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные можно объяснить несколькими различными моделями.  \n",
    "Вместо выбора только одной модели используют группу моделей, но для каждой модели считают \"вес\" относительно других.  \n",
    "Роль \"веса\" играет вероятность $P(model|data)$ - уверенность в модели $model$ при условии, что наблюдаются фактические данные $data$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для расчета $P(model|data)$ используется связь с $P(data|model)$ - вероятностью наблюдения данных $data$ в рамках выбранной модели $model$. Связь выражается соотношением Байеса:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(model | data) = \\frac{ P(data | model) P(model) }{P(data)} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используется следующая терминология:  \n",
    "$P(model | data)$ - апостериорное распределение вероятности,  \n",
    "$P(data | model)$ - функция правдоподобия,  \n",
    "$P(model)$ - априорное распределение вероятности,  \n",
    "$P(data)$ не имеет специального названия.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно форму модели фиксируют. Меняют только параметры.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательность действий при использовании байесовского подхода следующая (см. также рис. ниже).  \n",
    "Выбирается набор возможных моделей $model$ (или форма модели и область параметров для нее).  \n",
    "Для каждого набора параметров задается априорная вероятность $P(model)$.  \n",
    "Вычисляется функция правдоподобия $P(data|model)$ - вероятность получить данные в рамках выбранной модели.    \n",
    "Вычисляется апостериорная вероятность $P(model|data)$.  \n",
    "Анализируются свойства моделей и постериорных распределений.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../figs/bayes_scheme.png\" alt=\"bayes_scheme\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важным этапом является проверка модели.  \n",
    "Можно промахнуться с формой модели (пытаться аппроксимировать синусоиду прямой линией).  \n",
    "Кажется, в общем случае решения нет.  \n",
    "В \"простых\" случаях есть теорема полноты (теорема Де-Финетти).  \n",
    "На практике модель собирают из изученного набора аналитических распределений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка вероятности в эксперименте с двумя исходами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера байесовского моделирования можно рассмотреть оценку \n",
    "вероятностей в эксперименте с двумя исходами.\n",
    "\n",
    "Такой эксперимент может служить моделью конверсии пользователей в целевое действие.\n",
    "Каждый пользователь сервиса может выполнить или не выполнить целевое действие.\n",
    "Предполагается, что вероятность одинакова и не зависит от других пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "\n",
    "import scipy.stats as stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Проводится серия $N$ экспериментов с 2 возможными исходами (схема Бернулли [[BernoulliProcess](https://en.wikipedia.org/wiki/Bernoulli_process)]).  \n",
    "Условно каждый эксперимент можно называть \"броском монеты\".  \n",
    "Пусть вероятность одного исхода в каждом \"броске\" $p = 0.7$, второго $(1-p) = 0.3$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outcomes = ['heads', 'tails']\n",
    "n_trials = 1000\n",
    "p_heads = 0.7\n",
    "probs = [p_heads, 1 - p_heads]\n",
    "\n",
    "results = np.random.choice(outcomes, size=n_trials, p=probs)\n",
    "print(results[:7], '...')\n",
    "print()\n",
    "\n",
    "n_heads = np.sum(results == 'heads')\n",
    "print(f'n_heads: {n_heads}, n_tails: {n_trials-n_heads}')\n",
    "print(f'exact p_heads: {p_heads}')\n",
    "print(f'avg p_heads: {n_heads / n_trials}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В n_trials экспериментах получилось n_heads выпадений орла.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что точное значение $p$ неизвестно и его нужно оценить по $n_{heads}$ и $n_{trials}$.  \n",
    "Для общего числа бросков $n_{trials}$ количество успехов $n_{heads}$ могло получиться при различных значениях параметра $p$.  \n",
    "Один из способов оценить вероятные значения $p$ - перебор возможных значений и расчет вероятности для каждого.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для упрощения вместо непрерывного набора значений параметра $p$ на интервале от 0 до 1 можно ограничиться перебором дискретного набора возможных значений на равномерной сетке. Пусть в сетке M узлов, тогда\n",
    "\n",
    "$$\n",
    "p \\in \\left\\{ 0, \\frac{1}{M-1}, \\frac{2}{M-1}, \\dots, 1 \\right\\} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью байесовского метода можно оценить вероятности различных значений параметра $p$, т.е. $P(p | data)$:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(p | data) = \\frac{ P(data | p) P(p) }{P(data)} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно задать функцию правдоподобия $P(data | p)$ и априорное распределение вероятности $P(p)$ параметра $p$. Знаменатель $P(data)$ играет роль нормировки и при заданных $P(data | p)$ и $P(p)$ может быть вычислен как $P(data) = \\sum_p P(data|p) P(p)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве функции правдоподобия $P(data | p)$ можно выбрать биномиальное распределение [[BinomDist](https://en.wikipedia.org/wiki/Binomial_distribution), [SciPyBinom](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html)].  \n",
    "Оно моделирует вероятность получить $k$ \"успехов\" в серии из $N$ экспериментов с двумя возможными исходами при вероятности \"успеха\" $p$. В данном случае $k=n_{heads}, N=N_{trials}$.\n",
    "\n",
    "$$\n",
    "P(data| p) = \\mbox{Binomial}(p ; k=n_{heads}, N=N_{trials}),\n",
    "\\\\ \n",
    "\\mbox{Binomial}(p ; k, N)= {N \\choose k} p^{k} (1-p)^{N-k} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все $p$ будем считать равновероятными. Всего перебирается $M$ значений $p$, поэтому\n",
    "\n",
    "$$\n",
    "P(p) = \\frac{1}{M} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p \\in \\left\\{ 0, \\frac{1}{M-1}, \\frac{2}{M-1}, \\dots, 1 \\right\\} ,\n",
    "\\\\\n",
    "P(p) = \\frac{1}{M} ,\n",
    "\\\\\n",
    "P(data | p) = \\mbox{Binomial}(p ; n_{heads}, N_{trials}) ,\n",
    "\\\\\n",
    "\\mbox{Binomial}(p ; k, N)= {N \\choose k} p^{k} (1-p)^{N-k} ,\n",
    "\\\\\n",
    "P(data) = \\sum_p P(data | p) P(p) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_points = 1001\n",
    "p_grid = np.linspace(0, 1, grid_points)\n",
    "p_grid_prior = [ 1.0 / grid_points for x in p_grid]\n",
    "#print(p_grid)\n",
    "#print(p_grid_prior)\n",
    "\n",
    "likelihood = [stats.binom.pmf(n_heads, n_trials, p) for p in p_grid]\n",
    "p_posterior = [l * pr for (l, pr) in zip(likelihood, p_grid_prior)]\n",
    "p_posterior = p_posterior / sum(p_posterior)\n",
    "#print(likelihood)\n",
    "#print(p_posterior)\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=p_grid, y=p_posterior, mode='lines+markers'))\n",
    "fig.update_layout(title='Posterior',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob',\n",
    "                  hovermode=\"x\")\n",
    "fig.show()\n",
    "\n",
    "print('exact p_heads:', p_heads)\n",
    "print('avg p_heads:', n_heads / n_trials)\n",
    "print('max p_heads estimate:', p_grid[np.argmax(p_posterior)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом можно получить оценку вероятностей различных значений параметра $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По-хорошему, выбранную модель нужно проверить.  \n",
    "Проверка моделей пока не обсуждается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аналитический расчет апостериорного распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отдельных случаях апостериорное распределение вероятности удается посчитать аналитически. Это удается сделать не всегда, но для определенных комбинаций функции правдоподобия и априорного распределения удается. Выражение для апостериорного распределения:\n",
    "\n",
    "$$\n",
    "P(p | data) = \\frac{ P(data | p) P(p) }{P(data)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть функция правдоподобия задается биномиальным распределением [[BinomDist](https://en.wikipedia.org/wiki/Binomial_distribution)]:\n",
    "\n",
    "$$\n",
    "P(data | p) = Binom(p, s, N) = {N \\choose s} p^s (1-p)^{N-s} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение параметра $p$ непрерывно, а априорная плотность вероятности равномерна:  \n",
    "\n",
    "$$\n",
    "p \\in [0, 1] ,\n",
    "\\\\\n",
    "P(p) = Uniform(0,1) = \\frac{1}{1 - 0} = 1 .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При непрерывном распределении параметров $P(data)$ может быть представлен в виде интеграла по всей области значений параметров:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(data) = \\int \\limits_0^1 P(data | p) P(p) dp .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При подстановке в соотношение Байеса\n",
    "\n",
    "$$\n",
    "P(p | data) = \\frac{ p^s (1-p)^{N-s} }{\\int_0^1 p^s (1-p)^{N-s} dp} .\n",
    "$$\n",
    "\n",
    "Это выражение по форме совпадает с т.н. бета-распределением [[BetaDist](https://en.wikipedia.org/wiki/Beta_distribution), [SciPyBeta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html)]\n",
    "\n",
    "$$\n",
    "Beta(x; \\alpha, \\beta) \n",
    "= \n",
    "\\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{\\int_0^1 u^{\\alpha-1} (1-u)^{\\beta-1} du}\n",
    "=\n",
    "\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)}\n",
    "x^{\\alpha-1}(1-x)^{\\beta-1} . \n",
    "$$\n",
    "\n",
    "Таким образом апостериорное распределение задается бета-распределением с параметрами $\\alpha = s + 1$, $\\beta = N - s + 1$:\n",
    "\n",
    "$$\n",
    "P(p | data) = Beta(p; \\alpha, \\beta) ,\n",
    "\\\\\n",
    "\\alpha = s + 1, \\quad \\beta = N - s + 1 .\n",
    "$$\n",
    "\n",
    "Вид бета-распределения при различных значениях параметров обсуждается в [приложении](#Приложение:-сопряженное-априорное-распределение-к-биномиальному)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сравнить аналитическую плотность распределения с посчитанной выше численной. Для этого нужно посчитать вероятность тех же значений параметра $p$, что и в сетке прошлой модели. Значения плотности вероятности в конкретной точке $p$ будут отличаться от дискретной вероятности выше. Формально для сравнения нужно приблизить непрерывную аналитическую плотность вероятности дискретным распределением вероятности. Практически при аналогичной нормировке значения совпадают.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_for_binom_and_uniform_prior(p, n_heads, n_trials):\n",
    "    alpha_prior = 1\n",
    "    beta_prior = 1\n",
    "    alpha_post = alpha_prior + n_heads\n",
    "    beta_post = beta_prior + (n_trials - n_heads)\n",
    "    return stats.beta.pdf(p, alpha_post, beta_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_points = 1001\n",
    "p_grid = np.linspace(0, 1, grid_points)\n",
    "\n",
    "p_an_posterior = [posterior_for_binom_and_uniform_prior(p, n_heads, n_trials) for p in p_grid]\n",
    "p_an_posterior = p_an_posterior / np.sum(p_an_posterior)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=p_grid, y=p_posterior, mode='lines+markers', name='num'))\n",
    "fig.add_trace(go.Scatter(x=p_grid, y=p_an_posterior, mode='lines', name='an'))\n",
    "fig.update_layout(title='Posterior',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob',\n",
    "                  hovermode=\"x\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно показать, что если функция правдоподобия задана биномиальным распределением, априорная вероятность - бета-распределением, то апостериорная вероятность также будет выражаться бета-распределением, но с другими значениями параметров:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(data | p) = Binom(p, s, N)\n",
    "\\\\\n",
    "P(p) = Beta(p; \\alpha, \\beta)\n",
    "\\end{aligned}\n",
    "\\longrightarrow\n",
    "\\begin{aligned}\n",
    "& P(p | data) = Beta(p; \\alpha', \\beta'),\n",
    "\\\\\n",
    "& \\alpha' = \\alpha + s, \\; \\beta' = \\beta + (N-s).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Говорят, что бета-распределение является сопряженным априорным распределением к биномиальному [[ConjPrior](https://en.wikipedia.org/wiki/Conjugate_prior)]. Это можно использовать для упрощения вычислений и задания неравномерных априорных распределений - см. [приложение](#Приложение:-сопряженное-априорное-распределение-к-биномиальному)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение конверсий в А/Б тесте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как модель АБ-теста можно использовать 2 схемы Бернулли с вероятностями $p_A$ и $p_B$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_info = pd.DataFrame([\n",
    "    {'group' :'A', 'p_exact': 0.03, 'N': 3000},\n",
    "    {'group': 'B', 'p_exact': 0.035, 'N': 3000}],\n",
    "    columns=['group', 'p_exact', 'N']\n",
    ").set_index('group')\n",
    "exp_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_outcomes = ['buy', 'leave']\n",
    "\n",
    "probs_a = [exp_info['p_exact']['A'], 1 - exp_info['p_exact']['A']]\n",
    "probs_b = [exp_info['p_exact']['B'], 1 - exp_info['p_exact']['B']]\n",
    "\n",
    "results_a = np.random.choice(ab_outcomes, size=exp_info['N']['A'], p=probs_a)\n",
    "results_b = np.random.choice(ab_outcomes, size=exp_info['N']['B'], p=probs_b)\n",
    "\n",
    "print('A: ', results_a[:7], '...')\n",
    "print('B: ', results_b[:7], '...')\n",
    "print()\n",
    "\n",
    "exp_info['N_buy'] = [np.sum(results_a == 'buy'), np.sum(results_b == 'buy')]\n",
    "exp_info['p_mean'] = exp_info['N_buy'] / exp_info['N']\n",
    "exp_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка величины параметра в группах и область наиболее вероятных значений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Байесовская оценка параметра в каждой группе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = np.linspace(start=0, stop=1, num=3001)\n",
    "\n",
    "p_posterior_a = np.array([posterior_for_binom_and_uniform_prior(p, exp_info['N_buy']['A'], exp_info['N']['A']) for p in p_grid])\n",
    "p_posterior_b = np.array([posterior_for_binom_and_uniform_prior(p, exp_info['N_buy']['B'], exp_info['N']['B']) for p in p_grid])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=p_grid, y=p_posterior_a, mode='lines', name='A', line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=p_grid, y=p_posterior_b, mode='lines', name='B', line_color='blue'))\n",
    "fig.update_layout(title='Posterior',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\")\n",
    "fig.update_layout(xaxis_range=[0, 0.1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы охарактеризовать значение параметра одним числом, можно использовать средние значения $p_{mean}$ из выборки.  \n",
    "Другой возможный вариант - использовать $p$ с максимальной апострериорной плотностью вероятности.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_info['max_p_estimate'] = [p_grid[np.argmax(p_posterior_a)], p_grid[np.argmax(p_posterior_b)]]\n",
    "exp_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы передать неопределенность, удобно использовать интервал значений.  \n",
    "Интервал может включать, например, 90% распределения.  \n",
    "Т.к. в распределении есть один пик, удобно чтобы центр интервала совпадал с областью с наибольшей плотности вероятности.  \n",
    "Интервал с наибольшей плотностью вероятности далее обозначается HPDI - Highest Posterior Density Interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpdi_for_binom_and_uniform_prior(hpdi, n_heads, n_trials):\n",
    "    p_grid = np.linspace(start=0, stop=1, num=3001)\n",
    "    p_posterior = np.array([posterior_for_binom_and_uniform_prior(p, n_heads, n_trials) for p in p_grid])\n",
    "        \n",
    "    norm = np.sum(p_posterior)\n",
    "    n_start = np.argmax(p_posterior)\n",
    "    n_left = n_start\n",
    "    n_right = n_start\n",
    "    s = p_posterior[n_start]\n",
    "\n",
    "    while s < hpdi * norm:\n",
    "        next_left = p_posterior[n_left - 1]\n",
    "        next_right = p_posterior[n_right + 1]\n",
    "        if next_left > next_right:\n",
    "            n_left = n_left - 1\n",
    "            s = s + next_left\n",
    "        elif next_left < next_right:\n",
    "            n_right = n_right + 1\n",
    "            s = s + next_right\n",
    "        else:\n",
    "            n_left = n_left - 1\n",
    "            n_right = n_right + 1\n",
    "            s = s + next_left + next_right\n",
    "    return(p_grid[n_left], p_grid[n_right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpdi_left_a, hpdi_right_a = hpdi_for_binom_and_uniform_prior(0.9, exp_info['N_buy']['A'], exp_info['N']['A'])\n",
    "hpdi_left_b, hpdi_right_b = hpdi_for_binom_and_uniform_prior(0.9, exp_info['N_buy']['B'], exp_info['N']['B'])\n",
    "\n",
    "exp_info['90% HPDI'] = [(hpdi_left_a, hpdi_right_a), (hpdi_left_b, hpdi_right_b)]\n",
    "exp_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_a = exp_info['90% HPDI']['A'][0]\n",
    "right_a = exp_info['90% HPDI']['A'][1]\n",
    "left_b = exp_info['90% HPDI']['B'][0]\n",
    "right_b = exp_info['90% HPDI']['B'][1]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=p_grid, y=p_posterior_a, mode='lines', name='A', line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=p_grid[(p_grid > left_a) & (p_grid < right_a)], \n",
    "                         y=p_posterior_a[(p_grid > left_a) & (p_grid < right_a)], \n",
    "                         mode='lines', fill='tozeroy', line_color='red',\n",
    "                         name='90% HPDI A'))\n",
    "fig.add_trace(go.Scatter(x=p_grid, y=p_posterior_b, mode='lines', name='B', line_color='blue'))\n",
    "fig.add_trace(go.Scatter(x=p_grid[(p_grid > left_b) & (p_grid < right_b)], \n",
    "                         y=p_posterior_b[(p_grid > left_b) & (p_grid < right_b)], \n",
    "                         mode='lines', fill='tozeroy', line_color='blue',\n",
    "                         name='90% HPDI B'))\n",
    "fig.update_layout(title='Posterior',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\")\n",
    "fig.update_layout(xaxis_range=[0, 0.1])\n",
    "fig.show()\n",
    "\n",
    "print(f\"\"\"\n",
    "    90% HPDI A: ({p_grid[p_grid > left_a][0]:.2%} - {p_grid[p_grid < right_a][-1]:.2%})\n",
    "    90% HPDI B: ({p_grid[p_grid > left_b][0]:.2%} - {p_grid[p_grid < right_b][-1]:.2%})   \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[exp_info['p_mean']['A']],\n",
    "                         y=['A'],\n",
    "                         customdata=[f'90%-HPDI: ({hpdi_left_a:.3f}, {hpdi_right_a:.3f})'],\n",
    "                         hovertemplate = 'Mean: %{x:.3f}<br> %{customdata}',\n",
    "                         error_x=dict(\n",
    "                             type='data',\n",
    "                             symmetric=False,\n",
    "                             arrayminus=[exp_info['p_mean']['A'] - p_grid[p_grid > hpdi_left_a][0]],\n",
    "                             array=[p_grid[p_grid < hpdi_right_a][-1] - exp_info['p_mean']['A']],\n",
    "                             visible=True),\n",
    "                        name='A', line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=[exp_info['p_mean']['B']],\n",
    "                         y=['B'],\n",
    "                         customdata=[f'90%-HPDI: ({hpdi_left_b:.3f}, {hpdi_right_b:.3f})'],\n",
    "                         hovertemplate = 'Mean: %{x:.3f}<br> %{customdata}',\n",
    "                         error_x=dict(\n",
    "                             type='data',\n",
    "                             symmetric=False,\n",
    "                             arrayminus=[exp_info['p_mean']['B'] - p_grid[p_grid > hpdi_left_b][0]],\n",
    "                             array=[p_grid[p_grid < hpdi_right_b][-1] - exp_info['p_mean']['B']],\n",
    "                             visible=True),\n",
    "                         name='B', line_color='blue'))\n",
    "#fig.update_layout(hovertemplate = 'Mean: %{x:$.2f}<br> 80-HPDI: %{customdata[0]}')\n",
    "fig.update_layout(title='Posterior',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"closest\")\n",
    "fig.update_layout(xaxis_range=[0, 0.1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение с максимальной апострериорной вероятностью и HPDI не используются для точного принятия решений.  \n",
    "Они нужны для быстрой характеристики распределения.\n",
    "Это бывает удобно, например, для динамики по дням (см. далее).  \n",
    "Выбор 90% в HPDI - условность.  \n",
    "Можно использовать другие значения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Какая группа лучше и насколько?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы понять, какой вариант лучше, нужно оценить вероятность $p_B > p_A$.  \n",
    "\n",
    "Для оценки \"насколько один вариант лучше другого\" можно использовать разность $p_B - p_A$, отношение $p_B/p_A$ или относительную разность $(p_B-p_A)/p_A$. Для этого определяется соответствующая случайная величина, например $p_Z = p_B - p_A$ или $p_Z=p_B/p_A$, и вычисляется ее распределение. \n",
    "\n",
    "Вероятность $P(p_B > p_A)$ будет совпадать с вероятностями $P(p_B - p_A > 0)$ и $P(p_B/p_A > 1)$. \n",
    "\n",
    "Также эти распределения можно использовать для ответа на вопросы об ожидаемом значении $E(p_B/p_A)$ или, например, вероятности того, что величина эффекта больше определенного значения $p_B/p_A > 1.05$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выражения для разности и отношения задаются свертками плотностей распределений [[ProbConv](https://en.wikipedia.org/wiki/Convolution_of_probability_distributions), [ProbRatio](https://en.wikipedia.org/wiki/Ratio_distribution)]. Вместо аналитического расчета распределения разности или отношения часто используют приближенный метод - сэмплируют апостериорные распределения и анализируют свойства полученных выборок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже построено распределение отношений $p_B / p_A $ в сэмплах.    \n",
    "При расчете отношений требуется аккуратность если в знаменателе значимая плотность вероятности вблизи 0.   \n",
    "Например, отношение нормальных распределений с центром в 0 не имеет определенного среднего и дисперсии (см. [[CauchyDist](https://en.wikipedia.org/wiki/Cauchy_distribution)]).  \n",
    "Если вероятность 0 не очень большая, то значения можно проигнорировать, хотя это может исказить распределение.    \n",
    "Поскольку в группе $A$ есть покупки, то точно $p_A=0$ выпадать не должно.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numpy.random import default_rng\n",
    "#rng = default_rng(17)\n",
    "\n",
    "def posterior_sample_for_binom_and_uniform_prior(ns, ntotal, n_sample):\n",
    "    alpha_prior = 1\n",
    "    beta_prior = 1\n",
    "    a = alpha_prior + ns\n",
    "    b = beta_prior + (ntotal - ns) \n",
    "    return np.random.beta(a, b, n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 100000\n",
    "\n",
    "post_sample_a = posterior_sample_for_binom_and_uniform_prior(exp_info['N_buy']['A'], exp_info['N']['A'], n_sample)\n",
    "post_sample_b = posterior_sample_for_binom_and_uniform_prior(exp_info['N_buy']['B'], exp_info['N']['B'], n_sample)\n",
    "\n",
    "post_sample_rel = post_sample_b / post_sample_a\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=post_sample_rel, histnorm='probability density', \n",
    "                           name='B/A', marker_color='red',\n",
    "                           opacity=0.6))\n",
    "fig.add_vline(x=1, line_dash=\"dash\")\n",
    "\n",
    "fig.update_layout(title='B/A',\n",
    "                  xaxis_title='B/A',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  barmode='overlay')\n",
    "fig.show()\n",
    "\n",
    "print(f\"Expected(B/A) = {np.mean(post_sample_rel):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить оценку вероятности $P(p_B/p_A > 1)$, нужно найти долю точек, попавшую в интересующий диапазон:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_gt_pa = len(post_sample_rel[post_sample_rel > 1]) / len(post_sample_rel)\n",
    "print(f'P(p_B/p_A > 1): {pb_gt_pa}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичным способом можно оценить вероятность, что эффект больше определенной величины.  \n",
    "Например, $P(p_B/p_A > 1.05)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'P(p_B/p_A > 1.05): {len(post_sample_rel[post_sample_rel > 1.05]) / len(post_sample_rel)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_gt_pa = len(post_sample_rel[post_sample_rel > 1]) / len(post_sample_rel)\n",
    "pa_gte_pb = len(post_sample_rel[post_sample_rel <= 1]) / len(post_sample_rel)\n",
    "\n",
    "x = ['p_B <= p_A', 'p_B > p_A', ]\n",
    "y = [pa_gte_pb, pb_gt_pa]\n",
    "colors = ['red', 'green']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=x, y=y, marker_color=colors, width=0.3))\n",
    "fig.update_layout(yaxis_range=[0,1])\n",
    "fig.update_layout(\n",
    "     autosize=False,\n",
    "     width=800,\n",
    "     height=500)\n",
    "fig.show()\n",
    "\n",
    "b_to_a_mean = np.mean(post_sample_rel)\n",
    "exp_info['Prob Optimal Variant'] = [pa_gte_pb, pb_gt_pa]\n",
    "exp_info['Expected Rel to A'] = [1, b_to_a_mean]\n",
    "exp_info.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зависимость точности оценки параметров от размера выборки\n",
    "\n",
    "Есть ожидание, что точность оценки параметров будет зависеть от размера выборки.  \n",
    "Чем больше данных - тем точнее оценка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике ниже показаны оценки апостериорного распределения для различного количества наблюдений. Видно, что с ростом числа наблюдений ширина пиков уменьшается - т.е. уменьшается неопределенность в оценке параметра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = ['heads', 'tails']\n",
    "p_heads = 0.7\n",
    "probs = [p_heads, 1 - p_heads]\n",
    "\n",
    "N = [30, 300, 500, 1000, 3000]\n",
    "hpdi = 0.9\n",
    "hpdis = []\n",
    "\n",
    "fig = go.Figure()\n",
    "grid_points = 1001\n",
    "p_grid = np.linspace(0, 1, grid_points)\n",
    "\n",
    "for n in N:\n",
    "    res = np.random.choice(outcomes, size=n, p=probs)\n",
    "    n_heads = np.sum(res == 'heads')\n",
    "    p_posterior = np.array([posterior_for_binom_and_uniform_prior(p, n_heads, n) for p in p_grid])\n",
    "    hpdi_left, hpdi_right = hpdi_for_binom_and_uniform_prior(hpdi, n_heads, n)\n",
    "    hpdi_width = np.abs(hpdi_right - hpdi_left)\n",
    "    hpdis = hpdis + [hpdi_width]\n",
    "    fig.add_trace(go.Scatter(x=p_grid, y=p_posterior, mode='lines', name=f\"n = {n}\"))    \n",
    "fig.update_layout(title='Posterior',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конечном счете интересует, как меняется вероятность $P(p_B > p_A)$ с ростом числа наблюдений?   \n",
    "Сколько нужно ждать, пока уверенность в одном из вариантов дойдет до приемлемого уровня?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале можно оценить зависимость ширины апостериорных распределений от $N$.  \n",
    "В рассматриваемой модели апостериорное распределение описывается бета-распределением.  \n",
    "Ширину распределения можно охарактиризовать дисперсией, которая для бета-распределения вычисляется аналитически [[BetaDist](https://en.wikipedia.org/wiki/Beta_distribution)]\n",
    "\n",
    "$$\n",
    "P(p | data) = Beta(p; \\alpha, \\beta)\n",
    "\\\\\n",
    "\\alpha = s + 1, \\quad \\beta = N - s + 1\n",
    "\\\\\n",
    "\\sigma^2=\\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С ростом числа наблюдений $N$ дисперсия убывает как $1/N$, стандартное отклонение - как $1/\\sqrt{N}$\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to \\infty} \\sigma = \\frac{1}{\\sqrt{N}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. дисперсия бета-распределения убывает как $1/\\sqrt{N}$, то можно ожидать, что ширина 90%-HPDI будет убывать примерно так же.  \n",
    "Это подтверждается расчетами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for n, hpdi in zip(N, hpdis):\n",
    "    fig.add_trace(go.Scatter(x=[n], y=[hpdi], mode='markers', name=f\"n = {n}\"))\n",
    "x_fit = np.arange(N[0], N[-1])\n",
    "c_fit = hpdis[-1] * np.sqrt(N[-1])\n",
    "y_fit = [c_fit / np.sqrt(n) for n in x_fit]\n",
    "fig.add_trace(go.Scatter(x=x_fit, y=y_fit, name='Fit C/sqrt(N)'))\n",
    "fig.update_layout(title='90% HPDI Width',\n",
    "                  xaxis_title='N',\n",
    "                  yaxis_title='90% HPDI Width',\n",
    "                  hovermode=\"x\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому чтобы \"сузить\" значение HPDI в 2 раза нужно в 4 раза больше наблюдений, чем на текущий момент.  \n",
    "Например, если HPDI = (2.0 - 4.0) при N=3000, то для HPDI примерно (2.5-3.5) нужно N около 12000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С ростом $N$ можно ожидать повышения уверенности в том, какая из групп лучше.  \n",
    "Зависимость $P(p_B / p_A > 1)$ и $P(p_B > p_A)$ от $N$ аналитически оценить сложнее.  \n",
    "Можно оценить численно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_pb_gt_pa(p_a, p_b, N_a, N_b = None):\n",
    "    N_b = N_a if N_b is None else N_b\n",
    "    n_sample = 100000\n",
    "    post_sample_a = posterior_sample_for_binom_and_uniform_prior(p_a * N_a, N_a, n_sample)\n",
    "    post_sample_b = posterior_sample_for_binom_and_uniform_prior(p_b * N_b, N_b, n_sample)\n",
    "    post_sample_diff = post_sample_b - post_sample_a\n",
    "    prob_b_gt_a = len(post_sample_diff[post_sample_diff > 0]) / len(post_sample_diff)\n",
    "    return prob_b_gt_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведена зависимость вероятности $P(p_B > p_A)$ от числа наблюдений для значений\n",
    "$p_A$ равных 1% и 10%. $p_B$ выбирается равным $1.1 p_A$, либо $1.3 p_A$.  \n",
    "C ростом числа наблюдений $P(p_B > p_A)$ в каждом случае стремится к единице.  \n",
    "Однако при малых N скорость роста отличается и зависит как от относительной разности, так и от абсолютных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papb = [(0.01, 0.011), (0.01, 0.013), (0.10, 0.11), (0.10, 0.13)]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for pa, pb in papb:\n",
    "    group_size = np.arange(100, 50000, 500)\n",
    "    probs = [prob_pb_gt_pa(pa,  pb, n) for n in group_size]\n",
    "    fig.add_trace(go.Scatter(x=group_size,\n",
    "                             y=probs,\n",
    "                             name=f'pa={pa:.1%}, pb={pb:.1%}'))\n",
    "    \n",
    "fig.update_layout(title='Probability B > A',\n",
    "                  xaxis_title='Group Size',\n",
    "                  yaxis_title='Prob')\n",
    "fig.update_layout(yaxis_range=[0, 1])\n",
    "fig.add_hline(y=0.5, line_dash=\"dash\")\n",
    "fig.add_hline(y=0.8, line_dash=\"dash\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Численно также можно оценить, сколько нужно измерений для достижения определенного уровня уверенности $P(p_B > p_A)$, например, 80% или 90%.  \n",
    "\n",
    "Для конкретной пары $p_A$ и $p_B$ для этого можно построить изменение вероятности $P(p_B > p_A)$ с ростом $N$.  \n",
    "\n",
    "Ниже - иллюстрация на основе средних значений в текущей выборке $p_A = s_A/N_A$, $p_B = s_B/N_B$:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = exp_info['p_mean']['A']\n",
    "pb = exp_info['p_mean']['B']\n",
    "\n",
    "group_size = np.arange(100, 100000, 500)\n",
    "probs = np.array([prob_pb_gt_pa(pa, pb, n) for n in group_size])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=group_size, y=probs, name=f'pa={pa:.2%}, pb={pb:.2%}'))\n",
    "fig.update_layout(title='Probability B > A',\n",
    "                  xaxis_title='Group Size',\n",
    "                  yaxis_title='Prob')\n",
    "fig.update_layout(yaxis_range=[0, 1])\n",
    "fig.add_hline(y=0.8, line_dash=\"dash\")\n",
    "fig.add_hline(y=0.95, line_dash=\"dash\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "msgs = []\n",
    "msgs.append(f\"N_a = {exp_info['N']['A']}, N_b = {exp_info['N']['B']}\")\n",
    "msgs.append(f\"Estimate pa = {pa:.2%}, pb = {pb:.2%}\")\n",
    "msgs.append(f\"Current Prob(p_B > p_A) = {exp_info['Prob Optimal Variant']['B']}\")\n",
    "msgs.append(f\"Estimate N to reach Prob(p_B > p_A) = 80%: {group_size[np.min(np.where(probs > 0.8))]}\")\n",
    "msgs.append(f\"Estimate N to reach Prob(p_B > p_A) = 95%: {group_size[np.min(np.where(probs > 0.95))]}\")\n",
    "\n",
    "for m in msgs:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для рассматриваемого примера текущая вероятность $P(p_B > p_A) = 78.7\\%$ при $N=3000$ в каждой группе.  \n",
    "Чтобы она достигла $95 \\%$, нужно $N \\sim 13000$ в каждой группе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для более точной оценки числа $N$ нужно проводить аналогичные вычисления с $p_A$ и $p_B$ из всех возможных значений апостериорного распределения.  \n",
    "Т.е. сэмплируются $p_A$ и $p_B$, для каждой пары проводится оценка $N$ для достижения заданного уровня уверенности, строится распределение $N$.  \n",
    "Для оценки длительности можно ориентироваться на среднее значение $E[N]$ в этом распределении.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 100\n",
    "post_sample_a = posterior_sample_for_binom_and_uniform_prior(exp_info['N_buy']['A'], exp_info['N']['A'], n_sample)\n",
    "post_sample_b = posterior_sample_for_binom_and_uniform_prior(exp_info['N_buy']['B'], exp_info['N']['B'], n_sample)\n",
    "\n",
    "N_95 = []\n",
    "\n",
    "group_size = np.arange(100, 100000, 5000)\n",
    "fig = go.Figure()\n",
    "#todo: separate plotting from computation?\n",
    "\n",
    "i = 0\n",
    "for pa, pb in zip(post_sample_a, post_sample_b):\n",
    "    probs = np.array([prob_pb_gt_pa(pa, pb, n) for n in group_size])\n",
    "    Nreached = group_size[(probs > 0.95) | (probs < 0.05)]\n",
    "    Nmin = np.min(Nreached) if Nreached.size > 0 else np.max(group_size)\n",
    "    fig.add_trace(go.Scatter(x=group_size, y=probs, line_color='red', opacity=0.2, \n",
    "                             hovertemplate=f\"pa={pa:.3f}, pb={pb:.3f}, N95={Nmin}\"))\n",
    "    N_95 = N_95 + [Nmin]\n",
    "    i = i + 1\n",
    "    if i % 10 == 0: print(f'finished {i}')\n",
    "\n",
    "pa = exp_info['p_mean']['A']\n",
    "pb = exp_info['p_mean']['B']\n",
    "probs = np.array([prob_pb_gt_pa(pa, pb, n) for n in group_size])\n",
    "Nreached = group_size[(probs > 0.95) | (probs < 0.05)]\n",
    "Nmin = np.min(Nreached) if Nreached.size > 0 else np.max(group_size)\n",
    "fig.add_trace(go.Scatter(x=group_size, y=probs, line_color='blue', opacity=0.6, \n",
    "                         hovertemplate=f\"pa={pa:.3f}, pb={pb:.3f}, N95={Nmin}\"))\n",
    "N_95 = N_95 + [Nmin]\n",
    "        \n",
    "fig.update_layout(title='N to 95% certainty Scenarios',\n",
    "                  xaxis_title='Group Size',\n",
    "                  yaxis_title='Prob')\n",
    "fig.update_layout(yaxis_range=[0, 1], showlegend=False)\n",
    "fig.add_hline(y=0.95, line_dash=\"dash\")\n",
    "fig.add_hline(y=0.05, line_dash=\"dash\")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=N_95, histnorm='probability', \n",
    "                           name='N to 95% certainty', marker_color='red',\n",
    "                           opacity=0.6))\n",
    "fig.update_layout(title='N to 95% certainty',\n",
    "                  xaxis_title='N',\n",
    "                  yaxis_title='% from total simulations',\n",
    "                  barmode='overlay')\n",
    "fig.show()\n",
    "\n",
    "print(f'Expected N to 95% certainty: {np.mean(N_95)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На первом графике каждая линия соответствует конкретной паре $p_A$, $p_B$.  \n",
    "Проводится симуляция эксперимента с такими значениями и строится верятность $P(p_B > p_A)$.   \n",
    "Синяя линия - со средними значениями $p_A$ и $p_B$, как на предыдущем графике.\n",
    "\n",
    "\n",
    "На гистрограмме - значение $N$ до достижения $P(p_B > p_A) = 95 \\%$.  \n",
    "В 60% случаев $N$ в пределах 20 тысяч.  \n",
    "Ожидаемое значение $E[N] \\sim 30k$. При оценке по средним $p_A$ и $p_B$ получалось $N \\sim 13k$.  \n",
    "Т.е. использование только одной пары $p_A$ и $p_B$ дает заниженную оценку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По мере набора данных апостериорные распределения могут меняться.   \n",
    "При необходимости можно сделать новую оценку, когда наберется больше данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сколько должен продолжаться эксперимент?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По мере набора данных точность оценок параметров в каждой группе и уверенность в \n",
    "том, какая группа лучше, обычно повышается.  \n",
    "До какого уровня уверенности нужно продолжать эксперимент - 60%, 80%, 90%?  \n",
    "\n",
    "Можно целиться в достижение определенного занчения уверенности $P(p_B > p_A)$ - например, 95%.   \n",
    "Но если $p_B > p_A$ с вероятностью 70%, есть ли смысл продолжать эксперимент дальше?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый день эксперимента - потери из-за невыбора лучшего варианта.  \n",
    "Неверный выбор - потери после эксперимента.  \n",
    "Поэтому чем более долгосрочными будут последствия, тем большая нужна уверенность в выборе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также есть цена поддержки и цена реализации; можно считать, что цена поддержки одинакова,\n",
    "цена реализации не учитывается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без эксперимента в среднем конвертировалось бы $p_A N$ пользователей.  \n",
    "Если бы была выбрана группа B без эксперимента, то конвертировалось бы $p_B N$ пользователей.  \n",
    "Если эксперимент запущен на 50% пользователей, то в среднем в день будет конвертироваться N (pa + pb)/2 пользователей.  \n",
    "Когда будет сделан выбор в пользу одного из вариантов, количество пользователей изменится с N (pa + pb)/2 на $N p_A$ или $N p_B$ (на рисунке выбран вариант B).\n",
    "\n",
    "На графике ниже - среднее количество успехов в группе B, среднее количество успехов в группе А и количество успехов в эксперименте. Трафик в эксперименте делится между двумя группами и в определенный момент принимается решение о выборе варианта B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[0, 20], y=[100, 100], \n",
    "                         line_dash=\"dash\", line_color=\"red\", name=\"Mean A\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 20], y=[130, 130], \n",
    "                         line_dash=\"dash\", line_color=\"blue\", name=\"Mean B\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 8, 8, 20], y=[115, 115, 130, 130], \n",
    "                         line_color=\"purple\", name=\"exp\"))\n",
    "fig.add_vline(x=8, line_dash=\"dash\", name=\"stop\")\n",
    "fig.update_layout(yaxis_range=[0, 200], xaxis_range=[0, 20])\n",
    "fig.update_layout(xaxis_title='Days',\n",
    "                  yaxis_title='Users',\n",
    "                  hovermode=\"x\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда деление трафика в эксперименте подстраивают пропорционально оценке \"лучшести\" каждой группы.\n",
    "В этом случае число сконвертировавшихся пользователей в эксперименте со временем будет приближаться к лучшей группе (возможно после начальных колебаний). Однако вопрос \"когда прекращать эксперимент\" все равно остается.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно получить максимальное количество пользователей за время эксперимента и после выбора одного из вариантов.  \n",
    "\n",
    "Если эксперимент еще не начался, то ожидаемое количество сконвертирующихся пользователей складывается из    \n",
    "ожидаемого значения сконвертирующихся за время проведения эксперимента и ожидаемого количества тех, кто сконвертируется после выбора одного из вариантов \n",
    "\n",
    "$$\n",
    "E[N_{s}] = E[N_{s-during-experiment}] + E[N_{s-after-choise}].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть суммарно в обеих группах в эксперименте примент участие $N_{exp}$ пользователей.  \n",
    "$B_{split}$ - доля трафика в группе $B$.  \n",
    "Тогда за время эксперимента\n",
    "\n",
    "$$\n",
    "E[N_{s-during-experiment}] = N_{exp} B_{split} p_B + N_{exp}(1 - B_{split}) p_A .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки сконвертировавшихся пользователей после эксперимента нужно сделать оценку количества пользователей, которых затронет выбор того или иного варианта. Например, фича будет существовать еще год и повторных экспериментов или существенных изменений не будет. Т.е. последствия выбора того или иного варианта будут ощущаться все это время.  \n",
    "\n",
    "Пусть за год всего будет $N$ пользователей, из которых $N_{exp}$ приняло участие в эксперименте.  \n",
    "Тогда ожимдаемое число конверсий после прекращения эксперимента будет складыватсья из числа пользователей, не прошедших через эксперимент $N - N_{exp}$, умноженного на вероятность, что будет выбран вариант B и на конверсию в варианте B плюс аналогичное слагаемое для варианта A\n",
    "\n",
    "$$\n",
    "E[N_{s-after-choise}] = (N - N_{exp}) \\big( p_{B} p_{B>A} + p_A (1 - p_{B>A}) \\big).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<После подстановки выражение для $E[N_{s}] = N p_A + N p_{B>A} \\big( p_{B} - p_A \\big) - N_{exp} (p_{B>A} - B_{split}) \\big( p_{B} - p_A \\big)$ >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_converted_users(pa, pb, p_b_gt_a, b_split_part, N_exp, N_total_affected):\n",
    "    n_during_exp_s = (p_a * (1 - b_split_part) + p_b * b_split_part) * N_exp\n",
    "    n_remaining_s = (N_total_affected - N_exp) * (p_b * p_b_gt_a + p_a * (1 - p_b_gt_a))\n",
    "    N_s = n_during_exp_s + n_remaining_s\n",
    "    return N_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведены оценки $E[N_s]$ и вероятности $P(p_B > p_A)$ с ростом $N_{exp}$ для нескольких значений $p_A$ и $p_B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total_affected = 1000000\n",
    "N_exp_vals = np.arange(0, N_total_affected, 10000)\n",
    "\n",
    "p_a = 0.01\n",
    "p_b = 1.05 * p_a\n",
    "b_split_part = 0.5\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "msgs = []\n",
    "\n",
    "p_b_gt_a = [prob_pb_gt_pa(p_a, p_b, N_exp * (1 - b_split_part), N_exp * b_split_part) for N_exp in N_exp_vals]\n",
    "N_s = [expected_converted_users(p_a, p_b, p_ba, b_split_part, N_exp, N_total_affected) for N_exp, p_ba in zip(N_exp_vals, p_b_gt_a)]\n",
    "\n",
    "msgs.append(f'For pa={p_a:.2%}, pb={p_b:.2%} max expected N_s is for N_exp = {N_exp_vals[np.argmax(N_s)]} (N_s = {np.max(N_s)}, pb > pa: {p_b_gt_a[np.argmax(N_s)]})')\n",
    "fig.add_trace(go.Scatter(x=N_exp_vals, y=N_s, mode='lines', line_color='red', name=f'pa={p_a:.2%}, pb={p_b:.2%}; Users'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=N_exp_vals, y=p_b_gt_a, mode='lines', line_dash='dash', line_color='red', name=f'pa={p_a:.2%}, pb={p_b:.2%}; P(pb > pa)'), secondary_y=True)\n",
    "\n",
    "p_a = 0.01\n",
    "p_b = 1.1 * p_a\n",
    "p_b_gt_a = [prob_pb_gt_pa(p_a, p_b, N_exp * (1 - b_split_part), N_exp * b_split_part) for N_exp in N_exp_vals]\n",
    "N_s = [expected_converted_users(p_a, p_b, p_ba, b_split_part, N_exp, N_total_affected) for N_exp, p_ba in zip(N_exp_vals, p_b_gt_a)]\n",
    "\n",
    "msgs.append(f'For pa={p_a:.2%}, pb={p_b:.2%} max expected N_s is for N_exp = {N_exp_vals[np.argmax(N_s)]} (N_s = {np.max(N_s)}, pb > pa: {p_b_gt_a[np.argmax(N_s)]})')\n",
    "fig.add_trace(go.Scatter(x=N_exp_vals, y=N_s, mode='lines', line_color='blue', name=f'pa={p_a:.2%}, pb={p_b:.2%}; Users'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=N_exp_vals, y=p_b_gt_a, mode='lines', line_dash='dash', line_color='blue', name=f'pa={p_a:.2%}, pb={p_b:.2%}; P(pb > pa)'), secondary_y=True)\n",
    "\n",
    "\n",
    "fig.update_yaxes(title_text=\"Expected N_s\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"P(B>A)\", secondary_y=True)\n",
    "fig.update_xaxes(title_text=\"Users in Experiment\")\n",
    "#fig.update_layout(yaxis_range=[10000, 11000], secondary_y=False)\n",
    "fig.update_layout(hovermode='x')\n",
    "fig.show()\n",
    "\n",
    "for m in msgs:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формально эксперимент стоит прекращать, когда достигнуто максимальное ожидаемое значение сконвертировавшихся пользователей.\n",
    "Для $p_A=1.00\\%, p_B=1.05\\%$ максимальное ожидаемое количество конвертирующихся пользователей $max(E[N_s]) = 10398$ ожидается при $N_{exp} = 220000$. При этом $P(p_B > p_A) = 0.88$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фактически ожидаемое значение с какого-то момента может начать меняться слабо.  \n",
    "Например, для $p_A=1\\%$, $p_B=1.05\\%$:  \n",
    "$$\n",
    "N_{exp} = 60k, \\quad E[N_s] = 10357, \\quad p(p_B > p_A) = 0.73;\n",
    "\\\\\n",
    "N_{exp} = 220k, \\quad E[N_s] = 10398, \\quad p(p_B > p_A) = 0.88;  \n",
    "$$\n",
    "Т.е. разница между ожидаемыми значениями $E[N_s]$ примерно 40 пользователей.  \n",
    "Но при этом эксперимент можно прекратить более чем в 3 раза быстрее ($N_{exp} = 60k$ вместо $N_{exp} = 220k$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затягивание одного эксперимента может повышать цену поддержки а также мешать проведению других экспериментов.  \n",
    "Это можно учесть, если при принятии решения сравнивать ценность сконвертировавшихся пользователей с ценой каждого дня эксперимента.\n",
    "В таком случае вместо $E[N_{s}]$ решение будет приниматься по функции $E[Gain]$ вида\n",
    "\n",
    "$$\n",
    "E[Gain] = E[N_{s}] \\cdot E[LTV] - Penalty(N_{exp}),\n",
    "$$\n",
    "\n",
    "где $E[LTV]$ - ценность сконвертировавшегося пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Можно предположить, что $N \\gg N_{exp}$. В этом случае ожидаемое значение сконвертировавшихся пользователей можно упростить до\n",
    "$E[N_{s}] = N p_A + N p_{B>A} \\big( p_{B} - p_A \\big)$. $E[N_{s}]$ растет с ростом $p_{B>A}$. Однако рост замедляется и в какой-то момент дальнейший рост $E[N_{s}]$ не оправдывается издержками на поддержание эксперимента.>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее такие варианты использоваться не будут - будет использоваться только максимальное количество сконвертировавшихся пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если эксперимент уже идет, то в ожидаемом значении нужно учесть фактически принявших участие пользователей $N_{fact}$ и фактически сконвертировавшихся $N_{s-fact}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E[N_{s}] = N_{s-fact} + E[N_{s-during-remaining-experiment}] + E[N_{s-after-choise}] \n",
    "\\\\\n",
    "E[N_{s-during-remaining-experiment}] = N_{further-exp} B_{split} p_B + N_{further-exp}(1 - B_{split}) p_A \n",
    "\\\\\n",
    "E[N_{s-after-choise}] = (N - N_{fact} - N_{further-exp}) \\big( p_{B} p_{B>A} + p_A (1 - p_{B>A}) \\big) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формально для принятия решения о прекращении:  \n",
    "* По текущим данным построить апостериорные распределения $p_A$, $p_B$.\n",
    "* Насэмплить несколько пар $p_A$, $p_B$.\n",
    "* Для каждой пары построисть зависимость $E[N_{s}]$ от $N_{further-exp}$.\n",
    "* Для каждой пары найти $N_{further-exp-max-s}$, соответствующее $N_{further-exp}$ при максимальном $E[N_{s}]$.\n",
    "* Построить распределение $N_{further-exp-max-s}$.\n",
    "\n",
    "Когда среднее по всем парам значение $N_{further-exp-max-s}$ будет меньше определенной величины - прекращать эксперимент.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведены оценки дополнительного числа пользователей в эксперименте для текущих данных и для случая, когда \n",
    "в эксперименте дополнительно поучаствовало 100000 тыс пользователей (\"предельный\" случай)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: If you have a procedure with 10 parameters ...\n",
    "\n",
    "def expected_converted_users_fact(pa, pb, p_b_gt_a, b_split, N_s_fact, N_fact, N_further_exp, N_total_affected):\n",
    "    n_s_during_exp = N_further_exp * (pa * (1 - b_split) + pb * b_split)\n",
    "    n_s_after_choise = (N_total_affected - N_fact - N_further_exp) * (pb * p_b_gt_a + pa * (1 - p_b_gt_a))\n",
    "    expected_n_s = N_s_fact + n_s_during_exp + n_s_after_choise\n",
    "    return expected_n_s\n",
    "\n",
    "def simulate_expected_ns(pa, pb, sa, sb, na, nb, b_split_part, N_total_affected):\n",
    "    N_fact = na + nb\n",
    "    N_s_fact = sa + sb\n",
    "    N_further_exp_vals = np.arange(0, N_total_affected - N_fact, 10000)\n",
    "    p_b_gt_a_sim = []\n",
    "    N_s_sim = []\n",
    "    for N_fe in N_further_exp_vals:\n",
    "        na_fe = na + N_fe * (1 - b_split_part)\n",
    "        nb_fe = nb + N_fe * b_split_part\n",
    "        p_b_gt_a = prob_pb_gt_pa(pa, pb, na_fe, nb_fe)\n",
    "        expected_n_s = expected_converted_users_fact(pa=pa, pb=pb, p_b_gt_a=p_b_gt_a,\n",
    "                                                     b_split=b_split_part,\n",
    "                                                     N_s_fact=N_s_fact, N_fact=N_fact,\n",
    "                                                     N_further_exp=N_fe, N_total_affected=N_total_affected)\n",
    "        p_b_gt_a_sim.append(p_b_gt_a)\n",
    "        N_s_sim.append(expected_n_s)\n",
    "    N_for_max_Ns = N_further_exp_vals[np.argmax(N_s_sim)]\n",
    "    sim = {\n",
    "        'pa': pa,\n",
    "        'pb': pb,\n",
    "        'N_exp': N_fact + N_further_exp_vals,\n",
    "        'p_b_gt_a': np.array(p_b_gt_a_sim),\n",
    "        'N_s': np.array(N_s_sim),\n",
    "        'N_for_max_Ns': N_for_max_Ns\n",
    "    }\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_exact = exp_info['p_exact']['A']\n",
    "pb_exact = exp_info['p_exact']['B']\n",
    "N_total_affected = 1000000\n",
    "b_split_part = 0.5\n",
    "n_sample = 50\n",
    "\n",
    "####### current data\n",
    "\n",
    "sims_current = []\n",
    "\n",
    "na = exp_info['N']['A']\n",
    "nb = exp_info['N']['B']\n",
    "sa = exp_info['N_buy']['A']\n",
    "sb = exp_info['N_buy']['B']\n",
    "    \n",
    "post_sample_a = posterior_sample_for_binom_and_uniform_prior(sa, na, n_sample)\n",
    "post_sample_b = posterior_sample_for_binom_and_uniform_prior(sb, nb, n_sample)\n",
    "    \n",
    "for i, (pa, pb) in enumerate(zip(post_sample_a, post_sample_b)):\n",
    "    sim = simulate_expected_ns(pa, pb, sa, sb, na, nb, b_split_part, N_total_affected)\n",
    "    sims_current.append(sim)\n",
    "    if (i + 1) % 10 == 0: print(f'finished {i + 1} simulations for current data')\n",
    "\n",
    "#print(sims_current[-1])\n",
    "\n",
    "####### additional data\n",
    "\n",
    "sims_additional = []\n",
    "\n",
    "additional_data = 100000\n",
    "na = exp_info['N']['A'] + int(additional_data * (1 - b_split_part))\n",
    "nb = exp_info['N']['B'] + int(additional_data * b_split_part)\n",
    "sa = exp_info['N_buy']['A'] + np.random.binomial(na, pa_exact)\n",
    "sb = exp_info['N_buy']['B'] + np.random.binomial(nb, pb_exact)\n",
    "    \n",
    "post_sample_a = posterior_sample_for_binom_and_uniform_prior(sa, na, n_sample)\n",
    "post_sample_b = posterior_sample_for_binom_and_uniform_prior(sb, nb, n_sample)\n",
    "    \n",
    "for i, (pa, pb) in enumerate(zip(post_sample_a, post_sample_b)):\n",
    "    sim = simulate_expected_ns(pa, pb, sa, sb, na, nb, b_split_part, N_total_affected)\n",
    "    sims_additional.append(sim)\n",
    "    if (i + 1) % 10 == 0: print(f'finished {i + 1} simulations for additional data')\n",
    "        \n",
    "#print(sims_additional[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=2)\n",
    "\n",
    "N_for_max_Ns_current = []\n",
    "for sim in sims_current:\n",
    "    fig.add_trace(go.Scatter(x=sim['N_exp'], y=sim['N_s'], line_color='red', opacity=0.2,\n",
    "                             hovertemplate=\"N_exp=%{x}, E[Ns]=%{y} <br>\" + f\"pa={sim['pa']:.3f}, pb={sim['pb']:.3f}, N_for_max_Ns={sim['N_for_max_Ns']}\"),\n",
    "                  row=1, col=1)\n",
    "    N_for_max_Ns_current.append(sim['N_for_max_Ns'])\n",
    "counts, edges = np.histogram(N_for_max_Ns_current, bins=20, range=(0, N_total_affected))\n",
    "fig.add_trace(go.Bar(x=edges, y=counts / np.sum(counts),\n",
    "                     name='N to max Ns', \n",
    "                     opacity=0.6, marker_color='red'),\n",
    "              row=2, col=1)\n",
    "\n",
    "N_for_max_Ns_additional_data = []\n",
    "for sim in sims_additional:\n",
    "    fig.add_trace(go.Scatter(x=sim['N_exp'], y=sim['N_s'], line_color='red', opacity=0.2,\n",
    "                             hovertemplate=\"N_exp=%{x}, E[Ns]=%{y} <br>\" + f\"pa={sim['pa']:.3f}, pb={sim['pb']:.3f}, N_for_max_Ns={sim['N_for_max_Ns']}\"),\n",
    "                  row=1, col=2)\n",
    "    N_for_max_Ns_additional_data.append(sim['N_for_max_Ns'])\n",
    "counts, edges = np.histogram(N_for_max_Ns_additional_data, bins=20, range=(0, N_total_affected))\n",
    "fig.add_trace(go.Bar(x=edges, y=counts / np.sum(counts),\n",
    "                     name='N to max Ns', \n",
    "                     opacity=0.6, marker_color='red'),\n",
    "              row=2, col=2)\n",
    "\n",
    "fig.update_layout(autosize=False, \n",
    "                  width=1000,\n",
    "                  height=700)\n",
    "fig.update_layout(title='Experiment Duration')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig['layout']['xaxis'].update(title_text='N exp', range=[0, N_total_affected])\n",
    "fig['layout']['xaxis2'].update(title_text='N exp', range=[-20000, N_total_affected])\n",
    "fig['layout']['xaxis3'].update(title_text='Additional N to max E[Ns]', range=[-20000, N_total_affected])\n",
    "fig['layout']['xaxis4'].update(title_text='Additional N to max E[Ns]', range=[-20000, N_total_affected])\n",
    "fig['layout']['yaxis'].update(title_text='E[Ns]')\n",
    "fig['layout']['yaxis2'].update(title_text='E[Ns]')\n",
    "fig['layout']['yaxis3'].update(title_text='Part of Simulations')\n",
    "fig['layout']['yaxis4'].update(title_text='Part of Simulations')\n",
    "fig.show()\n",
    "\n",
    "print(f'Expected N to max Ns for current data: {np.mean(N_for_max_Ns_current)}')\n",
    "print(f'Expected N to max Ns with additional data: {np.mean(N_for_max_Ns_additional_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При достаточно большом количестве пользователей в эксперименте во всех сценариях оценка дальнейшего числа конверсий только уменьшается. Поэтому проводить эксперимент дальше не целесообразно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При таком подходе все еще остается некоторая степень субъективности при выборе момента прекращения эксперимента.  \n",
    "Ожидаемое значение $N_{further-exp}$ до максимального $E[N_s]$ не всегда будет равно 0.  \n",
    "Поэтому нужно выбрать произвольное значение ниже которого продолжать эксперимент нет смысла.  \n",
    "Выбор становится более объективным, если есть цена каждого дня эксперимента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике эффекты меньше определенной величины - например, меньше 5% - могут быть не интересны.  \n",
    "Для предварительной оценки длительности эксперимента можно выбрать $p_A$ равным историческому значению конверсии и $p_B = 1.05 p_A$.    \n",
    "В последствии длительность можно будет уточнить по ходу проведения эксперимента. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Количество правильно принятых решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерировать pa, pb;  \n",
    "pa - [1% -- 20%]  \n",
    "pb - [0.8 -- 1.2] * pa  \n",
    "\n",
    "pa известно; pb - нет.  \n",
    "\n",
    "пытаться угадать, какой вариант лучше, за минимальное количество N_exp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_guess = 1000\n",
    "\n",
    "pa_guess = np.random.uniform(low=0.01, high=0.2, size=n_guess)\n",
    "ba = np.random.uniform(low=0.8, high=1.2, size=n_guess)\n",
    "pb_guess = ba * pa\n",
    "pa[:5], pb[:5], ba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_mean_further_n(sa, na, sb, nb, n_sample):\n",
    "    sims = []\n",
    "    N_for_max_Ns = []\n",
    "    N_total_affected = 1000000\n",
    "    b_split_part = nb / (na + nb)\n",
    "    post_sample_a = posterior_sample_for_binom_and_uniform_prior(sa, na, n_sample)\n",
    "    post_sample_b = posterior_sample_for_binom_and_uniform_prior(sb, nb, n_sample)\n",
    "    for i, (pa, pb) in enumerate(zip(post_sample_a, post_sample_b)):\n",
    "        sim = simulate_expected_ns(pa, pb, sa, sb, na, nb, b_split_part, N_total_affected)\n",
    "        sims.append(sim)\n",
    "        #if (i + 1) % 10 == 0: print(f'finished {i + 1} simulations for {i, pa_exact, pb_exact}')\n",
    "        N_for_max_Ns.append(sim['N_for_max_Ns'])\n",
    "    return np.mean(N_for_max_Ns_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for pa, pb in pa_guess, pb_guess:\n",
    "pa_exact = pa[0]\n",
    "pb_exact = pb[0]\n",
    "\n",
    "expected_n_for_max_nx = estimate_duration_for_papb(pa=pa_exact, pb=1.05*pa_exact)\n",
    "print(f\"Initial duration estimate: {expected_n_for_max_nx}\")\n",
    "\n",
    "na_daily = 5000\n",
    "nb_daily = 5000\n",
    "\n",
    "na_total = []\n",
    "nb_total = []\n",
    "\n",
    "na_s = []\n",
    "nb_s = []\n",
    "\n",
    "pa_est = []\n",
    "pb_est\n",
    "\n",
    "expected_n_for_max_ns = []\n",
    "\n",
    "#pandas:\n",
    "#pa_exact, pb_exact, iteration, na, na_s, nb_nb_s, pa, pb, pb/pa, pb>pa, further_n\n",
    "i = 0\n",
    "\n",
    "while expected_n_for_max_ns_i > 0:\n",
    "    i = i + 1\n",
    "    na_total = na_total + [na_daily]\n",
    "    nb_total = nb_total + [nb_daily]\n",
    "    na_s = na_s + [np.random.binomial(na_daily, pa_exact)]\n",
    "    nb_s = nb_s + [np.random.binomial(nb_daily, pb_exact)]\n",
    "    pa_est = pa_est + [np.sum(na_s) / np.sum(na_total)]\n",
    "    pb_est = pb_est + [np.sum(nb_s) / np.sum(nb_total)]\n",
    "    pb_gt_pa = prob_pb_gt_pa(na_accum_last, nas_accum_last, nb_accum_last, nbs_accum_last)\n",
    "    n_sample = 30\n",
    "    expected_n_for_max_ns_i = estimate_mean_further_nexp(nas_accum_last, na_accum_last, \n",
    "                                                         nbs_accum_last, nb_accum_last, \n",
    "                                                         n_sample)\n",
    "    expected_n_for_max_ns = expected_n_for_max_ns + [expected_n_for_max_ns_i]\n",
    "    print('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#guesses {}, #correct guesses: {}')\n",
    "print('Total Nexp: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Проверка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнение: динамика по дням"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тест часто идет несколько дней.  \n",
    "Удобно видеть динамику по дням."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть параметры теста следующие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_info = pd.DataFrame([\n",
    "    {'group' :'A', 'p_exact': 0.02, 'n_days': 30, 'N_daily': 1000},\n",
    "    {'group': 'B', 'p_exact': 0.022, 'n_days': 30, 'N_daily': 1000}],\n",
    "    columns=['group', 'p_exact', 'n_days', 'N_daily']\n",
    ").set_index('group')\n",
    "exp_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_a = np.random.binomial(n=exp_info['N_daily']['A'], p=exp_info['p_exact']['A'], size=exp_info['n_days']['A'])\n",
    "results_b = np.random.binomial(n=exp_info['N_daily']['B'], p=exp_info['p_exact']['B'], size=exp_info['n_days']['B'])\n",
    "\n",
    "df = pd.concat([\n",
    "    pd.DataFrame([('A', d, exp_info['N_daily']['A'], s) for d, s in enumerate(results_a)], \n",
    "                 columns=['group', 'day', 'n_users', 'buys']),\n",
    "    pd.DataFrame([('B', d, exp_info['N_daily']['B'], s) for d, s in enumerate(results_b)], \n",
    "                 columns=['group', 'day', 'n_users', 'buys'])\n",
    "])\n",
    "\n",
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конверсии по дням"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['p_daily'] = df['buys'] / df['n_users']\n",
    "display(df.head())\n",
    "\n",
    "fig = px.line(df, x='day', y='p_daily', color='group', markers=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конверсии по накопленным данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accum = df.groupby('group')['n_users', 'buys'].cumsum().rename(columns={'n_users': 'n_users_accum', 'buys':'buys_accum'})\n",
    "display(df_accum.head())\n",
    "\n",
    "df = pd.concat([df, df_accum], axis=1)\n",
    "df['p_accum'] = df['buys_accum'] / df['n_users_accum']\n",
    "display(df.head())\n",
    "\n",
    "fig = px.line(df, x='day', y='p_accum', color='group', markers=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPDI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpdi = 0.9\n",
    "df[['p_hpdi_lower','p_hpdi_higher']] = df.apply(lambda row: pd.Series(hpdi_for_binom_and_uniform_prior(hpdi, row['buys_accum'], row['n_users_accum'])), axis=1)\n",
    "df['error_lower'] = df['p_accum'] - df['p_hpdi_lower']\n",
    "df['error_higher'] = df['p_hpdi_higher'] - df['p_accum']\n",
    "display(df.head())\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df[df['group'] == 'A']['day'], \n",
    "                         y=df[df['group'] == 'A']['p_accum'],\n",
    "                         mode='lines+markers', name='A', line_color='blue'))\n",
    "fig.add_trace(go.Scatter(x=pd.concat([df[df['group'] == 'A']['day'], df[df['group'] == 'A']['day'][::-1], df[df['group'] == 'A']['day'][0:1]]), \n",
    "                         y=pd.concat([df[df['group'] == 'A']['p_hpdi_higher'], df[df['group'] == 'A']['p_hpdi_lower'][::-1], df[df['group'] == 'A']['p_hpdi_higher'][0:1]]),\n",
    "                         fill='toself', name=f'{hpdi:.0%} HPDI A',\n",
    "                         hoveron = 'points+fills',\n",
    "                         hoverinfo = 'text+x+y',\n",
    "                         line_color='blue', fillcolor='blue', opacity=0.4))\n",
    "fig.add_trace(go.Scatter(x=df[df['group'] == 'B']['day'], \n",
    "                         y=df[df['group'] == 'B']['p_accum'],\n",
    "                         mode='lines+markers', name='B', line_color='red'))\n",
    "fig.add_trace(go.Scatter(x=pd.concat([df[df['group'] == 'B']['day'], df[df['group'] == 'B']['day'][::-1], df[df['group'] == 'B']['day'][0:1]]), \n",
    "                         y=pd.concat([df[df['group'] == 'B']['p_hpdi_higher'], df[df['group'] == 'B']['p_hpdi_lower'][::-1], df[df['group'] == 'B']['p_hpdi_higher'][0:1]]),\n",
    "                         fill='toself', name=f'{hpdi:.0%} HPDI B',\n",
    "                         hoveron = 'points+fills',\n",
    "                         hoverinfo = 'text+x+y',\n",
    "                         line_color='red', fillcolor='red', opacity=0.4))\n",
    "fig.update_layout(xaxis_title='Days',\n",
    "                  yaxis_title='P',\n",
    "                  hovermode=\"x\")\n",
    "fig.update_layout(height=470)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([df[df['group'] == 'A']['day'],\n",
    "#            df[df['group'] == 'A']['day'][::-1],\n",
    "#            df[df['group'] == 'A']['day'][0:1]])\n",
    "# pd.concat([df[df['group'] == 'A']['p_hpdi_higher'],\n",
    "#            df[df['group'] == 'A']['p_hpdi_lower'][::-1],\n",
    "#            df[df['group'] == 'A']['p_hpdi_higher'][0:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob_pb_ge_pa_for_binom_and_uniform_prior(df[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятность $P(p_B > p_A)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widedf = df.set_index(['group', 'day']).unstack(level=0)\n",
    "#display(widedf.head())\n",
    "\n",
    "widedf['pb_gt_pa'] = widedf.apply(lambda row: prob_pb_gt_pa(\n",
    "    p_a=row['p_accum']['A'],\n",
    "    p_b=row['p_accum']['B'],\n",
    "    N_a=row['n_users_accum']['A'], \n",
    "    N_b=row['n_users_accum']['B']), axis=1)\n",
    "widedf = widedf.reset_index()\n",
    "#display(widedf.head())\n",
    "\n",
    "fig = px.line(widedf, x='day', y='pb_gt_pa', markers=True, title=\"$P_b >= P_a$\",\n",
    "             labels={\"day\": \"Day\", \"pb_gt_pa\": \"\"})\n",
    "fig.add_hline(y=0.5, line_dash=\"dash\")\n",
    "fig.update_layout(\n",
    "    yaxis_range=[0, 1],\n",
    "    yaxis_tickformat = ',.0%')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: ожидаемое количество сконвертировавшихся, прогноз pb>pa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приложение: сопряженное априорное распределение к биномиальному"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно показать, что если функция правдоподобия задана биномиальным распределением, априорная вероятность - бета-распределением, то апостериорная вероятность также будет выражаться бета-распределением, но с другими значениями параметров. Говорят, что бета-распределение является сопряженным априорным распределением к биномиальному [[ConjPrior](https://en.wikipedia.org/wiki/Conjugate_prior)]. Это позволяет упростить расчеты в некоторых случаях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(p | data) = \\frac{ P(data | p) P(p) }{P(data)}\n",
    "\\propto\n",
    "P(data | p) P(p)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(data | p) = Binom(p, s, N) \\propto p^s (1-p)^{N-s}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(p) = Beta(p; \\alpha, \\beta) \\propto p^{\\alpha-1}(1-p)^{\\beta-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(p | data) \n",
    "\\propto P(data | p) P(p) = Binom(p, s, N) Beta(p; \\alpha, \\beta) \n",
    "\\propto p^{s + \\alpha - 1} (1-p)^{N - s + \\beta - 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(p | data) = Beta(p; \\alpha', \\beta')\n",
    "\\\\\n",
    "\\alpha' = \\alpha + s, \\qquad \\beta' = \\beta + (N-s)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вид бета-распределения при различных значениях параметров приведен ниже.   \n",
    "При $\\alpha = 1, \\beta=1$ бета-распределение совпадает с равномерным.  \n",
    "По мере набора данных можно ожидать роста $s$ и $N$ при постоянном отношении $s/N \\approx p_{exact}$.  \n",
    "Бета-распределение будет локализовываться вокруг этого отношения.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 1000)\n",
    "\n",
    "fig = go.Figure()\n",
    "for a, b in [(1, 1), (2, 10), (10, 50), (20, 100)]:\n",
    "    fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a, b), mode='lines', name=f'a={a}, b={b}'))\n",
    "fig.update_layout(title='Posterior',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob',\n",
    "                  hovermode=\"x\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно задавать априорное распределение локализованным вокруг определенного значения вместо равномерного распределения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные шаги оценки эксперимента в байесовском подходе:\n",
    "\n",
    "* выбрать модель\n",
    "* по историческим данным проверить, что модель в состоянии описать данные\n",
    "* для оценки длительности эксперимента задаться априорными распределениями параметров в каждой группе;\n",
    "промоделировать различные сценарии; оценить ожидаемую длительность до наибольшей \"выгоды\" за время эксперимента.  \n",
    "Это предварительноая оценка - фиксировать это значение не обязательно.\n",
    "* по мере проведения эксперимента делать оценки параметров для экспериментальных групп и обновлять оценки длительности\n",
    "* прекратить эксперимент, когда когда ожидаемое значение \"выгоды\" начнет снижаться"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что не обсуждалось:\n",
    "\n",
    "* Оценка метрик, не являющихся конверсиями. Например, выручки на пользователя или среднего чека.    \n",
    "\n",
    "* Выбор более информативного априорного распределения, чем равномерное.\n",
    "Можно выбрать распределение с учетом исторического значения конверсии. Это позволит уменьшить размер выборки, требуемый для достижения значимого отличия.\n",
    "\n",
    "* Более сложные модели. Пользователей часто удобно объединить в сегменты по похожему поведению в сервисе или по различным рекламным каналам. Поэтому вместо биномиального распределения может быть удобнее использовать смесь биномиальных распределений с различными параметрами для каждого сегмента. \n",
    "\n",
    "* Модели с большим числом параметров; генерация сэмплов апостериорного распределения методами Монте-Карло с марковскими цепями.\n",
    "\n",
    "* Сравнение байесовского подхода с альтернативными методами оценки экспериментов. В том числе с методом проверки статистических гипотез."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Благодарности\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SyxF4D301GKx"
   },
   "source": [
    "## Ссылки\n",
    "[MicroExp] R. Kohavi et al, [Online Experimentation at Microsoft.](https://www.microsoft.com/en-us/research/publication/online-experimentation-at-microsoft/)  \n",
    "[TrustworthyAB] R. Kohavi, D. Tang, Y. Xu, [Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing.](https://www.amazon.com/gp/product/B0845Y3DJV/ref=dbs_a_def_rwt_hsch_vapi_tkin_p1_i0)  \n",
    "[SGBS] B. Lambert, A Student’s Guide to Bayesian Statistics ( [Textbook](https://www.amazon.co.uk/Students-Guide-Bayesian-Statistics/dp/1473916364), [Student Resources](https://study.sagepub.com/lambert) ).   \n",
    "[SR] R. McElreath, Statistical Rethinking: A Bayesian Course with Examples in R and STAN ( [Textbook](https://www.amazon.co.uk/Statistical-Rethinking-Bayesian-Examples-Chapman/dp/036713991X/ref=sr_1_1), [Video Lectures](https://www.youtube.com/playlist?list=PLDcUM9US4XdMROZ57-OIRtIK0aOynbgZN), [Course Materials](https://github.com/rmcelreath/stat_rethinking_2022) ).     \n",
    "[SubjProb] [Subjectivism](https://en.wikipedia.org/wiki/Probability_interpretations#Subjectivism), in *Probability Interpretations*, *Wikipedia.*   \n",
    "[UU] D.V. Lindley, [Understanding Uncertainty.](https://www.amazon.co.uk/Understanding-Uncertainty-Wiley-Probability-Statistics-ebook/dp/B00GYVM33Q)      \n",
    "[BernoulliProcess] [Bernoulli Process](https://en.wikipedia.org/wiki/Bernoulli_process), *Wikipedia.*     \n",
    "[BinomDist] [Binomial Distribution](https://en.wikipedia.org/wiki/Binomial_distribution), *Wikipedia.*  \n",
    "[SciPyBinom] [scipy.stats.binom](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html), *SciPy Reference.*   \n",
    "[BetaDist] [Beta Distribution](https://en.wikipedia.org/wiki/Beta_distribution), *Wikipedia.*     \n",
    "[SciPyBeta] [scipy.stats.beta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html), *SciPy Reference.*    \n",
    "[ConjPrior] [Conjugate Prior](https://en.wikipedia.org/wiki/Conjugate_prior), *Wikipedia.*   \n",
    "[ProbConv] [Convolution of Probability Distributions](https://en.wikipedia.org/wiki/Convolution_of_probability_distributions), *Wikipedia.*   \n",
    "[ProbRatio] [Ratio Distribution](https://en.wikipedia.org/wiki/Ratio_distribution), *Wikipedia.*  \n",
    "[CauchyDist] [Cauchy Distribution](https://en.wikipedia.org/wiki/Cauchy_distribution), *Wikipedia.*  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "DioEW-rWK_vU"
   ],
   "name": "Байесовский подход к оценке А/Б тестов.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
